"""
è¯­éŸ³æ¶ˆæ¯å¤„ç†æ¨¡å— - ä½¿ç”¨ Gemini åˆ†æè¯­éŸ³å†…å®¹
"""
import logging
import base64
from telegram import Update
from telegram.ext import ContextTypes
from telegram.error import BadRequest

from config import gemini_client, GEMINI_MODEL, is_user_allowed

logger = logging.getLogger(__name__)


async def handle_voice_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    å¤„ç†è¯­éŸ³æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI è½¬å†™å¹¶å›å¤
    """
    chat_id = update.message.chat_id
    user_id = update.message.from_user.id
    
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    if not await is_user_allowed(user_id):
        await update.message.reply_text(
            "â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚"
        )
        return
    
    # è·å–è¯­éŸ³æ¶ˆæ¯
    voice = update.message.voice
    if not voice:
        return
    
    # æ£€æŸ¥æ—¶é•¿ï¼ˆé™åˆ¶ 60 ç§’ï¼‰
    if voice.duration > 60:
        await update.message.reply_text(
            "âš ï¸ è¯­éŸ³æ¶ˆæ¯è¿‡é•¿ï¼ˆè¶…è¿‡ 60 ç§’ï¼‰ï¼Œè¯·å‘é€è¾ƒçŸ­çš„è¯­éŸ³ã€‚"
        )
        return
    
    # å‘é€å¤„ç†ä¸­æç¤º
    thinking_msg = await update.message.reply_text("ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³å†…å®¹...")
    
    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    
    try:
        # ä¸‹è½½è¯­éŸ³æ–‡ä»¶
        file = await context.bot.get_file(voice.file_id)
        voice_bytes = await file.download_as_bytearray()
        
        # è·å– MIME ç±»å‹
        mime_type = voice.mime_type or "audio/ogg"
        
        # æ„å»ºè¯·æ±‚å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": "è¯·å¬è¿™æ®µè¯­éŸ³ï¼Œè½¬å†™å…¶ä¸­çš„æ–‡å­—å†…å®¹ï¼Œç„¶åæ ¹æ®å†…å®¹è¿›è¡Œå›å¤ã€‚å¦‚æœæ— æ³•è¯†åˆ«ï¼Œè¯·è¯´æ˜åŸå› ã€‚"},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(voice_bytes)).decode("utf-8"),
                        }
                    },
                ]
            }
        ]
        
        # è°ƒç”¨ Gemini API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": (
                    "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå¯ä»¥ç†è§£è¯­éŸ³å†…å®¹å¹¶è¿›è¡Œå¯¹è¯ã€‚"
                    "è¯·å…ˆè½¬å†™è¯­éŸ³ä¸­çš„æ–‡å­—ï¼Œç„¶åé’ˆå¯¹å†…å®¹è¿›è¡Œå›å¤ã€‚"
                    "è¯·ç”¨ä¸­æ–‡å›å¤ã€‚"
                ),
            },
        )
        
        if response.text:
            await thinking_msg.edit_text(response.text)
            # è®°å½•ç»Ÿè®¡
            from stats import increment_stat
            await increment_stat(user_id, "voice_chats")
        else:
            await thinking_msg.edit_text("æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è¯†åˆ«è¿™æ®µè¯­éŸ³ã€‚è¯·ç¨åå†è¯•ã€‚")
        
    except Exception as e:
        logger.error(f"Voice processing error: {e}")
        try:
            await thinking_msg.edit_text(
                "âŒ è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n"
                "å¯èƒ½çš„åŸå› ï¼š\n"
                "â€¢ è¯­éŸ³æ ¼å¼ä¸æ”¯æŒ\n"
                "â€¢ è¯­éŸ³å†…å®¹æ— æ³•è¯†åˆ«\n"
                "â€¢ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
            )
        except BadRequest:
            pass
