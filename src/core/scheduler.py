"""
ä»»åŠ¡è°ƒåº¦æ¨¡å— - å¤„ç†å®šæ—¶æé†’
"""
import logging
import datetime
import dateutil.parser
import feedparser
from telegram.ext import ContextTypes, JobQueue

from repositories import (
    add_reminder, 
    delete_reminder, 
    get_pending_reminders,
    get_all_subscriptions, 
    update_subscription_status,
    get_user_watchlist,
    get_all_watchlist_users,
)
from repositories.chat_repo import save_message, get_latest_session_id

logger = logging.getLogger(__name__)

async def save_push_message_to_db(user_id: int, message: str):
    """Utility to save pushed messages to chat history"""
    try:
        session_id = await get_latest_session_id(user_id)
        await save_message(user_id, "model", message, session_id)
    except Exception as e:
        logger.error(f"Failed to save push message for {user_id}: {e}")


async def send_reminder_job(context: ContextTypes.DEFAULT_TYPE):
    """å‘é€æé†’çš„å·¥ä½œä»»åŠ¡"""
    job = context.job
    # job.data å­˜å‚¨äº† reminder_id, user_id, chat_id, message
    reminder_id = job.data["id"]
    chat_id = job.data["chat_id"]
    message = job.data["message"]
    
    logger.info(f"Triggering reminder {reminder_id} for chat {chat_id}")
    
    try:
        await context.bot.send_message(
            chat_id=chat_id,
            text=f"â° **æé†’**\n\n{message}",
            parse_mode="Markdown"
        )
    except Exception as e:
        logger.error(f"Failed to send reminder {reminder_id}: {e}")
    finally:
         # æ— è®ºå‘é€æˆåŠŸä¸å¦ï¼ˆå¯èƒ½æ˜¯ç”¨æˆ·å°é”äº†Botï¼‰ï¼Œéƒ½åˆ é™¤ä»»åŠ¡ï¼Œé¿å…é‡å¤æ‰§è¡Œ
         # æ”¹è¿›ç‚¹ï¼šå¦‚æœæ˜¯ç½‘ç»œé”™è¯¯ï¼Œå¯ä»¥é‡è¯•ï¼Œä½†è¿™é‡Œç®€åŒ–å¤„ç†
         await delete_reminder(reminder_id)


async def schedule_reminder(
    job_queue: JobQueue,
    user_id: int,
    chat_id: int,
    message: str,
    trigger_time: datetime.datetime
) -> bool:
    """å®‰æ’ä¸€ä¸ªæ–°çš„æé†’ä»»åŠ¡"""
    now = datetime.datetime.now().astimezone()
    delay = (trigger_time - now).total_seconds()
    
    if delay < 0:
        logger.warning("Trigger time is in the past, running immediately")
        delay = 0

    # å­˜å…¥æ•°æ®åº“
    # æ³¨æ„ï¼šsqlite å­˜ timestamp éœ€è¦è½¬å­—ç¬¦ä¸² (isoformat)
    # å¹¶ä¸”ä¿æŒæ—¶åŒºä¿¡æ¯å¾ˆé‡è¦
    reminder_id = await add_reminder(user_id, chat_id, message, trigger_time.isoformat())
    
    # åŠ å…¥ JobQueue
    job_queue.run_once(
        send_reminder_job,
        when=delay,
        data={
            "id": reminder_id,
            "user_id": user_id,
            "chat_id": chat_id,
            "message": message
        }
    )
    return True


async def load_jobs_from_db(job_queue: JobQueue):
    """ä»æ•°æ®åº“åŠ è½½æœªæ‰§è¡Œçš„æé†’ä»»åŠ¡ï¼ˆBot å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
    logger.info("Loading pending reminders from database...")
    reminders = await get_pending_reminders()
    
    count = 0
    now = datetime.datetime.now().astimezone()
    
    for row in reminders:
        reminder_id = row["id"]
        trigger_time_str = row["trigger_time"]
        
        try:
            # è§£ææ—¶é—´
            trigger_time = dateutil.parser.isoparse(trigger_time_str)
            
            # ç¡®ä¿æ­¤æ—¶åŒºæ„è¯†åˆ° (aware)ï¼Œå¦‚æœ db é‡Œå­˜çš„æ˜¯ naiveï¼Œé»˜è®¤è§†ä½œ local
            if trigger_time.tzinfo is None:
                 trigger_time = trigger_time.replace(tzinfo=now.tzinfo)

            delay = (trigger_time - now).total_seconds()
            
            # å¦‚æœé”™è¿‡äº†æ—¶é—´ï¼Œç¨å¾®å»¶è¿Ÿä¸€ç‚¹ç«‹å³æ‰§è¡Œ (e.g. 5s)
            if delay < 0:
                delay = 5 
                
            job_queue.run_once(
                send_reminder_job,
                when=delay,
                data={
                    "id": reminder_id,
                    "user_id": row["user_id"],
                    "chat_id": row["chat_id"],
                    "message": row["message"]
                }
            )
            count += 1
            
            logger.info(f"Loaded {count} pending reminders.")
            
        except Exception as e:
            logger.error(f"Failed to load reminder {reminder_id}: {e}")
            
    logger.info(f"Loaded {count} pending reminders.")


async def generate_entry_summary(title: str, content: str, link: str) -> str:
    """ä½¿ç”¨ AI ç”Ÿæˆ RSS æ¡ç›®æ‘˜è¦"""
    from core.config import gemini_client, GEMINI_MODEL
    
    # æˆªæ–­è¿‡é•¿å†…å®¹
    if len(content) > 2000:
        content = content[:2000] + "..."
    
    prompt = (
        "è¯·ä¸ºä»¥ä¸‹æ–°é—»/æ–‡ç« ç”Ÿæˆä¸€æ®µç®€æ´çš„ä¸­æ–‡æ‘˜è¦ï¼ˆ100-150å­—ï¼‰ï¼Œ"
        "çªå‡ºæ ¸å¿ƒä¿¡æ¯å’Œè¦ç‚¹ã€‚ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦åŠ ä»»ä½•å‰ç¼€ã€‚\n\n"
        f"**æ ‡é¢˜**ï¼š{title}\n\n"
        f"**å†…å®¹**ï¼š{content}"
    )
    
    try:
        response = await gemini_client.aio.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt,
        )
        return response.text.strip()
    except Exception as e:
        logger.error(f"AI summary generation failed: {e}")
        # å¤±è´¥æ—¶è¿”å›åŸå§‹å†…å®¹çš„æˆªæ–­ç‰ˆæœ¬
        return content[:200] + "..." if len(content) > 200 else content


import asyncio

# å…¨å±€é”ï¼Œé˜²æ­¢å®šæ—¶ä»»åŠ¡å’Œæ‰‹åŠ¨è§¦å‘æ’è½¦
_rss_check_lock = asyncio.Lock()


async def fetch_formatted_rss_updates(user_id: int = None, subscriptions: list = None) -> tuple[str, list, dict]:
    """
    è·å–å¹¶æ ¼å¼åŒ– RSS æ›´æ–°ï¼Œä½†ä¸å‘é€ã€‚
    è¿”å›: (formatted_message, pending_updates_list, user_updates_map)
    """
    # 1. è·å–è®¢é˜… (å¦‚æœæ²¡æœ‰ä¼ å…¥)
    if not subscriptions:
        if user_id:
            from repositories import get_user_subscriptions
            subscriptions = await get_user_subscriptions(user_id)
        else:
            subscriptions = await get_all_subscriptions()
            
    if not subscriptions:
        return "", [], {}

    # 2. æŒ‰ feed_url åˆ†ç»„
    feed_map = {}
    for sub in subscriptions:
        url = sub["feed_url"]
        if url not in feed_map:
            feed_map[url] = []
        feed_map[url].append(sub)
        
    user_updates = {} # user_id -> list of updates
    all_pending_updates = []

    # 3. æŠ“å–é€»è¾‘
    for url, subs in feed_map.items():
        try:
            feed = feedparser.parse(url)
            if feed.bozo and feed.bozo_exception:
                continue
            if not feed.entries:
                continue
            
            latest_entry = feed.entries[0]
            entry_id = getattr(latest_entry, "id", getattr(latest_entry, "link", None))
            if not entry_id:
                continue
                
            for sub in subs:
                last_hash = sub["last_entry_hash"]
                if entry_id != last_hash:
                    # Found new content
                    title = latest_entry.get("title", "æ— æ ‡é¢˜")
                    link = latest_entry.get("link", url)
                    feed_title = feed.feed.get("title", "RSS è®¢é˜…")
                    
                    # Content summary logic...
                    content = ""
                    if hasattr(latest_entry, "summary"):
                        content = latest_entry.summary
                    elif hasattr(latest_entry, "content") and latest_entry.content:
                        content = latest_entry.content[0].get("value", "")
                    elif hasattr(latest_entry, "description"):
                        content = latest_entry.description
                    
                    import re
                    content_clean = re.sub(r'<[^>]+>', '', content).strip()
                    
                    if content_clean:
                        summary = await generate_entry_summary(title, content_clean, link)
                    else:
                        summary = "æš‚æ— æ‘˜è¦"
                    
                    uid = sub["user_id"]
                    if uid not in user_updates:
                        user_updates[uid] = []
                    
                    update_item = {
                        "feed_title": feed_title,
                        "title": title,
                        "summary": summary,
                        "link": link,
                        "sub_id": sub["id"],
                        "entry_id": entry_id,
                        "etag": getattr(feed, "etag", None),
                        "modified": getattr(feed, "modified", None)
                    }
                    
                    user_updates[uid].append(update_item)
                    all_pending_updates.append(update_item)
                    
        except Exception as e:
            logger.error(f"Error checking feed {url}: {e}")

    # 4. æ ¼å¼åŒ–è¾“å‡º (æŒ‰ç”¨æˆ·æ±‡æ€»)
    final_output = ""
    # å¦‚æœæ˜¯æŒ‡å®šç”¨æˆ· (Tool åœºæ™¯)ï¼Œç”Ÿæˆä¸€ä¸ªå¤§çš„æ–‡æœ¬å—
    if user_id and user_id in user_updates:
        updates = user_updates[user_id]
        final_output = f"ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ ({len(updates)} æ¡æ›´æ–°)**\n\n"
        for update in updates:
            final_output += (
                f"ğŸ”¹ **{update['feed_title']}**\n"
                f"[{update['title']}]({update['link']})\n"
                f"ğŸ“ {update['summary']}\n\n"
            )

    return final_output, all_pending_updates, user_updates


async def mark_updates_as_read(pending_updates: list):
    """æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
    for update in pending_updates:
        try:
            await update_subscription_status(
                update["sub_id"], 
                update["entry_id"], 
                update["etag"], 
                update["modified"]
            )
        except Exception as e:
            logger.error(f"Failed to update subscription status for sub {update['sub_id']}: {e}")


async def check_and_send_rss_updates(context: ContextTypes.DEFAULT_TYPE, subscriptions: list):
    """
    [å®šæ—¶ä»»åŠ¡é€»è¾‘] æ£€æŸ¥å¹¶ç›´æ¥å‘é€ RSS æ›´æ–° (å¸¦é”)
    """
    if _rss_check_lock.locked():
        logger.info("RSS check already in progress, waiting for lock...")
    
    async with _rss_check_lock:
        try:
            _, _, user_updates_map = await fetch_formatted_rss_updates(subscriptions=subscriptions)
        except Exception as e:
             logger.error(f"Fetch updates failed: {e}")
             return 0
        
        if not user_updates_map:
            return 0
        
        sent_count = 0
        success_updates = []

        # æ‰¹é‡å‘é€æ¶ˆæ¯
        for uid, updates in user_updates_map.items():
            msg_header = f"ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ ({len(updates)} æ¡æ›´æ–°)**\n\n"
            msg_body = ""
            current_batch = []
            
            for update in updates:
                item_text = (
                    f"ğŸ”¹ **{update['feed_title']}**\n"
                    f"[{update['title']}]({update['link']})\n"
                    f"ğŸ“ {update['summary']}\n\n"
                )
                
                # é•¿åº¦æ£€æŸ¥ & åˆ†æ‰¹å‘é€
                if len(msg_header) + len(msg_body) + len(item_text) > 4000:
                    try:
                        await context.bot.send_message(chat_id=uid, text=msg_header + msg_body, parse_mode="Markdown")
                        # åœæ­¢ä¿å­˜æ¨é€æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡ï¼Œé˜²æ­¢ LLM åœ¨å›å¤æ—¶å—åˆ°æ±¡æŸ“ï¼ˆå¹»è§‰/æ¨¡ä»¿ï¼‰
                        # await save_push_message_to_db(uid, msg_header + msg_body)
                        success_updates.extend(current_batch)
                        sent_count += 1
                    except Exception as e:
                        logger.error(f"Failed to send batch to {uid}: {e}")
                    
                    msg_body = ""
                    msg_header = "ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ (ç»­)**\n\n"
                    current_batch = []
                
                msg_body += item_text
                current_batch.append(update)
                
            if msg_body:
                try:
                    await context.bot.send_message(chat_id=uid, text=msg_header + msg_body, parse_mode="Markdown")
                    # await save_push_message_to_db(uid, msg_header + msg_body)
                    success_updates.extend(current_batch)
                    sent_count += 1
                except Exception as e:
                    logger.error(f"Failed to send final batch to {uid}: {e}")

        # ç»Ÿä¸€æ›´æ–°æ•°æ®åº“
        await mark_updates_as_read(success_updates)
            
        return sent_count


async def check_rss_updates_job(context: ContextTypes.DEFAULT_TYPE):
    """æ£€æŸ¥ RSS æ›´æ–°çš„ä»»åŠ¡ (å®šæ—¶è°ƒç”¨)"""
    logger.info("Checking for RSS updates...")
    
    subscriptions = await get_all_subscriptions()
    if not subscriptions:
        logger.info("No subscriptions found.")
        return

    await check_and_send_rss_updates(context, subscriptions)


async def trigger_manual_rss_check(context: ContextTypes.DEFAULT_TYPE, user_id: int) -> str:
    """
    [Tool Logic] æ‰‹åŠ¨è§¦å‘ç‰¹å®šç”¨æˆ·çš„ RSS æ£€æŸ¥
    è¿”å›æ ¼å¼åŒ–åçš„æ›´æ–°å†…å®¹æ–‡æœ¬ï¼Œä¸ç›´æ¥å‘é€ã€‚
    """
    # è·å–é”
    if _rss_check_lock.locked():
        return "âš ï¸ æ­£åœ¨è¿›è¡Œå®šæ—¶æ›´æ–°æ£€æŸ¥ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
    async with _rss_check_lock:
        formatted_text, all_pending, _ = await fetch_formatted_rss_updates(user_id=user_id)
        
        if all_pending:
            # æ ‡è®°ä¸ºå·²è¯» (å› ä¸ºå³å°†è¿”å›ç»™ Agent å±•ç¤º)
            await mark_updates_as_read(all_pending)
            return formatted_text
        else:
            return ""


def start_rss_scheduler(job_queue: JobQueue):
    """å¯åŠ¨ RSS æ£€æŸ¥å®šæ—¶ä»»åŠ¡"""
    # æ¯ 30 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    # interval = 30 * 60
    # æµ‹è¯•æœŸé—´æ”¹ä¸º 5 åˆ†é’Ÿ
    interval = 30 * 60 
    
    job_queue.run_repeating(
        check_rss_updates_job,
        interval=interval,
        first=10, # å¯åŠ¨ 10 ç§’åç¬¬ä¸€æ¬¡è¿è¡Œ
        name="rss_check"
    )
    logger.info(f"RSS scheduler started, interval={interval}s")


# --- è‚¡ç¥¨ç›¯ç›˜æ¨é€ ---

def is_trading_time() -> bool:
    """
    åˆ¤æ–­å½“å‰æ˜¯å¦ä¸º A è‚¡äº¤æ˜“æ—¶æ®µ
    - å‘¨ä¸€è‡³å‘¨äº”
    - ä¸Šåˆ 9:30-11:30ï¼Œä¸‹åˆ 13:00-15:00
    """
    now = datetime.datetime.now()
    
    # å‘¨æœ«ä¸äº¤æ˜“ (0=å‘¨ä¸€, 6=å‘¨æ—¥)
    if now.weekday() >= 5:
        return False
    
    current_time = now.time()
    
    # ä¸Šåˆäº¤æ˜“æ—¶æ®µ: 9:30 - 11:30
    morning_start = datetime.time(9, 30)
    morning_end = datetime.time(11, 30)
    
    # ä¸‹åˆäº¤æ˜“æ—¶æ®µ: 13:00 - 15:00
    afternoon_start = datetime.time(13, 0)
    afternoon_end = datetime.time(15, 0)
    
    return (morning_start <= current_time <= morning_end or 
            afternoon_start <= current_time <= afternoon_end)


async def stock_push_job(context: ContextTypes.DEFAULT_TYPE):
    """æ¯ 10 åˆ†é’Ÿæ¨é€è‚¡ç¥¨è¡Œæƒ…"""
    if not is_trading_time():
        logger.debug("Not trading time, skipping stock push")
        return
    
    logger.info("Starting stock push job...")
    
    # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¼•ç”¨
    from services.stock_service import fetch_stock_quotes, format_stock_message
    
    try:
        # è·å–æ‰€æœ‰æœ‰è‡ªé€‰è‚¡çš„ç”¨æˆ·
        user_ids = await get_all_watchlist_users()
        
        if not user_ids:
            logger.info("No users with watchlist, skipping")
            return
        
        for user_id in user_ids:
            try:
                # è·å–ç”¨æˆ·è‡ªé€‰è‚¡
                watchlist = await get_user_watchlist(user_id)
                if not watchlist:
                    continue
                
                # æå–è‚¡ç¥¨ä»£ç 
                stock_codes = [item["stock_code"] for item in watchlist]
                
                # æ‰¹é‡è·å–è¡Œæƒ…
                quotes = await fetch_stock_quotes(stock_codes)
                
                if not quotes:
                    continue
                
                # æ ¼å¼åŒ–æ¶ˆæ¯
                message = format_stock_message(quotes)
                
                # æ¨é€ç»™ç”¨æˆ·
                await context.bot.send_message(
                    chat_id=user_id,
                    text=message,
                    parse_mode="Markdown"
                )
                # åœæ­¢ä¿å­˜æ¨é€æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
                # await save_push_message_to_db(user_id, message)
                logger.info(f"Sent stock quotes to user {user_id}")
                
            except Exception as e:
                logger.error(f"Failed to send stock quotes to {user_id}: {e}")
                
    except Exception as e:
        logger.error(f"Stock push job error: {e}")


async def trigger_manual_stock_check(context: ContextTypes.DEFAULT_TYPE, user_id: int) -> str:
    """
    [Tool Logic] æ‰‹åŠ¨è§¦å‘ç‰¹å®šç”¨æˆ·çš„è‡ªé€‰è‚¡è¡Œæƒ…åˆ·æ–°
    è¿”å›æ ¼å¼åŒ–åçš„è¡Œæƒ…æ–‡æœ¬
    """
    from services.stock_service import fetch_stock_quotes, format_stock_message
    
    try:
        # è·å–ç”¨æˆ·è‡ªé€‰è‚¡
        watchlist = await get_user_watchlist(user_id)
        if not watchlist:
            return "" # Empty watchlist
        
        # æå–è‚¡ç¥¨ä»£ç 
        stock_codes = [item["stock_code"] for item in watchlist]
        
        # æ‰¹é‡è·å–è¡Œæƒ…
        quotes = await fetch_stock_quotes(stock_codes)
        
        if not quotes:
            return "âŒ æ— æ³•è·å–è¡Œæƒ…æ•°æ®ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        
        # æ ¼å¼åŒ–æ¶ˆæ¯
        message = format_stock_message(quotes)
        return message
        
    except Exception as e:
        logger.error(f"Manual stock check error for {user_id}: {e}")
        return f"âŒ åˆ·æ–°å¤±è´¥: {str(e)}"



def start_stock_scheduler(job_queue: JobQueue):
    """å¯åŠ¨è‚¡ç¥¨æ¨é€å®šæ—¶ä»»åŠ¡"""
    interval = 10 * 60  # 10 åˆ†é’Ÿ
    
    job_queue.run_repeating(
        stock_push_job,
        interval=interval,
        first=30,  # å¯åŠ¨ 30 ç§’åç¬¬ä¸€æ¬¡è¿è¡Œ
        name="stock_push"
    )
    logger.info(f"Stock scheduler started, interval={interval}s")
