"""
ä»»åŠ¡è°ƒåº¦æ¨¡å— - å¤„ç†å®šæ—¶æé†’
"""

import asyncio
import logging
import datetime
import dateutil.parser
import feedparser
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from core.skill_loader import skill_loader
from core.platform.registry import adapter_manager
from core.platform.models import UnifiedContext

from repositories import (
    add_reminder,
    delete_reminder,
    get_pending_reminders,
    get_all_subscriptions,
    update_subscription_status,
    get_user_watchlist,
    get_all_watchlist_users,
)
from repositories.task_repo import get_all_active_tasks
from repositories.chat_repo import save_message, get_latest_session_id

logger = logging.getLogger(__name__)

# Global Scheduler Instance
scheduler = AsyncIOScheduler()


async def save_push_message_to_db(user_id: int, message: str):
    """Utility to save pushed messages to chat history"""
    try:
        session_id = await get_latest_session_id(user_id)
        await save_message(user_id, "model", message, session_id)
    except Exception as e:
        logger.error(f"Failed to save push message for {user_id}: {e}")


async def send_via_adapter(
    chat_id: int | str,
    text: str,
    platform: str = "telegram",
    parse_mode: str = "Markdown",
    **kwargs,
):
    """Helper to send message via available adapters"""

    # å°è¯•è·å–å¯¹åº”å¹³å°çš„ Adapter
    try:
        adapter = adapter_manager.get_adapter(platform)
    except Exception:
        adapter = None

    if adapter:
        try:
            # Universal way?
            if platform == "telegram":
                # Telegram adapter has .bot
                await adapter.bot.send_message(
                    chat_id=chat_id, text=text, parse_mode=parse_mode, **kwargs
                )
            elif platform == "discord":
                # Discord adapter usually takes send_message with just chat_id/text
                # Check if discord adapter has send_message method matching signature
                # Assuming DiscordAdapter.send_message(self, chat_id, text)
                await adapter.send_message(chat_id=chat_id, text=text)
            else:
                logger.warning(f"Unknown platform or no send method: {platform}")
            return
        except Exception as e:
            logger.error(f"{platform} send failed: {e}")
    else:
        logger.warning(f"No adapter found for platform: {platform}")


async def send_reminder_job(
    reminder_id: int,
    user_id: int,
    chat_id: int,
    message: str,
    platform: str = "telegram",
):
    """å‘é€æé†’çš„å·¥ä½œä»»åŠ¡"""
    logger.info(f"Triggering reminder {reminder_id} for chat {chat_id} on {platform}")

    try:
        await send_via_adapter(
            chat_id=chat_id, text=f"â° **æé†’**\n\n{message}", platform=platform
        )
    except Exception as e:
        logger.error(f"Failed to send reminder {reminder_id}: {e}")
    finally:
        await delete_reminder(reminder_id)


async def schedule_reminder(
    user_id: int,
    chat_id: int,
    message: str,
    trigger_time: datetime.datetime,
    platform: str = "telegram",
) -> bool:
    """å®‰æ’ä¸€ä¸ªæ–°çš„æé†’ä»»åŠ¡"""
    now = datetime.datetime.now().astimezone()

    # Update: If trigger_time is naiive, make it aware (local)
    if trigger_time.tzinfo is None:
        trigger_time = trigger_time.replace(tzinfo=now.tzinfo)

    # å­˜å…¥æ•°æ®åº“
    reminder_id = await add_reminder(
        user_id, chat_id, message, trigger_time.isoformat(), platform=platform
    )

    # åŠ å…¥ Scheduler
    scheduler.add_job(
        send_reminder_job,
        "date",
        run_date=trigger_time,
        args=[reminder_id, user_id, chat_id, message, platform],
        id=f"reminder_{reminder_id}",
        replace_existing=True,
    )
    return True


async def load_jobs_from_db():
    """ä»æ•°æ®åº“åŠ è½½æœªæ‰§è¡Œçš„æé†’ä»»åŠ¡ï¼ˆBot å¯åŠ¨æ—¶è°ƒç”¨ï¼‰"""
    logger.info("Loading pending reminders from database...")
    reminders = await get_pending_reminders()

    count = 0
    now = datetime.datetime.now().astimezone()

    for row in reminders:
        reminder_id = row["id"]
        trigger_time_str = row["trigger_time"]
        platform = row.get("platform", "telegram")

        try:
            # è§£ææ—¶é—´
            trigger_time = dateutil.parser.isoparse(trigger_time_str)

            # ç¡®ä¿æ­¤æ—¶åŒºæ„è¯†åˆ° (aware)
            if trigger_time.tzinfo is None:
                trigger_time = trigger_time.replace(tzinfo=now.tzinfo)

            # å¦‚æœé”™è¿‡äº†æ—¶é—´ï¼Œç¨å¾®å»¶è¿Ÿä¸€ç‚¹ç«‹å³æ‰§è¡Œ
            run_time = trigger_time
            delay = (trigger_time - now).total_seconds()
            if delay < 0:
                run_time = now + datetime.timedelta(seconds=5)

            scheduler.add_job(
                send_reminder_job,
                "date",
                run_date=run_time,
                args=[
                    reminder_id,
                    row["user_id"],
                    row["chat_id"],
                    row["message"],
                    platform,
                ],
                id=f"reminder_{reminder_id}",
                replace_existing=True,
            )
            count += 1

        except Exception as e:
            logger.error(f"Failed to load reminder {reminder_id}: {e}")

    logger.info(f"Loaded {count} pending reminders.")


async def generate_entry_summary(title: str, content: str, link: str) -> str:
    """ä½¿ç”¨ AI ç”Ÿæˆ RSS æ¡ç›®æ‘˜è¦"""
    from core.config import gemini_client, GEMINI_MODEL

    # æˆªæ–­è¿‡é•¿å†…å®¹
    if len(content) > 2000:
        content = content[:2000] + "..."

    prompt = (
        "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€æ®µç®€æ´çš„ä¸­æ–‡æ‘˜è¦ã€‚\n"
        "è§„åˆ™ï¼š\n"
        "1. å¦‚æœå†…å®¹ä¸°å¯Œï¼Œç”Ÿæˆ 100-150 å­—çš„æ‘˜è¦ï¼Œçªå‡ºæ ¸å¿ƒä¿¡æ¯ã€‚\n"
        "2. å¦‚æœå†…å®¹éå¸¸ç®€çŸ­ï¼ˆå¦‚ GitHub Commit ä¿¡æ¯ã€åªæœ‰ä¸€å¥è¯çš„åŠ¨æ€ï¼‰ï¼Œè¯·ç›´æ¥å¤è¿°æˆ–ç¿»è¯‘è¯¥å†…å®¹ï¼Œä¸è¦æŠ±æ€¨ä¿¡æ¯é‡ä¸è¶³ï¼Œä¹Ÿä¸è¦è¯•å›¾å¼ºè¡Œæ‰©å±•ã€‚\n"
        "3. ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦åŠ ä»»ä½•å‰ç¼€ã€‚\n\n"
        f"**æ ‡é¢˜**ï¼š{title}\n\n"
        f"**å†…å®¹**ï¼š{content}"
    )

    try:
        response = await gemini_client.aio.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt,
        )
        return response.text.strip()
    except Exception as e:
        logger.error(f"AI summary generation failed: {e}")
        # å¤±è´¥æ—¶è¿”å›åŸå§‹å†…å®¹çš„æˆªæ–­ç‰ˆæœ¬
        return content[:200] + "..." if len(content) > 200 else content


# å…¨å±€é”ï¼Œé˜²æ­¢å®šæ—¶ä»»åŠ¡å’Œæ‰‹åŠ¨è§¦å‘æ’è½¦
_rss_check_lock = asyncio.Lock()


async def fetch_formatted_rss_updates(
    user_id: int = None, subscriptions: list = None
) -> tuple[str, list, dict]:
    """
    è·å–å¹¶æ ¼å¼åŒ– RSS æ›´æ–°ï¼Œä½†ä¸å‘é€ã€‚
    è¿”å›: (formatted_message, pending_updates_list, user_updates_map)
    user_updates_map: dict[(platform, user_id)] -> list
    """
    # 1. è·å–è®¢é˜… (å¦‚æœæ²¡æœ‰ä¼ å…¥)
    if not subscriptions:
        if user_id:
            from repositories import get_user_subscriptions

            subscriptions = await get_user_subscriptions(user_id)
        else:
            subscriptions = await get_all_subscriptions()

    if not subscriptions:
        return "", [], {}

    # 2. æŒ‰ feed_url åˆ†ç»„
    feed_map = {}
    for sub in subscriptions:
        url = sub["feed_url"]
        if url not in feed_map:
            feed_map[url] = []
        feed_map[url].append(sub)

    user_updates = {}  # (platform, user_id) -> list of updates
    all_pending_updates = []

    # 3. æŠ“å–é€»è¾‘
    loop = asyncio.get_running_loop()
    for url, subs in feed_map.items():
        try:
            # Use run_in_executor to avoid blocking the event loop with synchronous feedparser
            feed = await loop.run_in_executor(None, feedparser.parse, url)
            if feed.bozo and feed.bozo_exception:
                continue
            if not feed.entries:
                continue

            latest_entry = feed.entries[0]
            entry_id = getattr(latest_entry, "id", getattr(latest_entry, "link", None))
            if not entry_id:
                continue

            for sub in subs:
                last_hash = sub["last_entry_hash"]
                if entry_id != last_hash:
                    # Found new content
                    title = latest_entry.get("title", "æ— æ ‡é¢˜")
                    link = latest_entry.get("link", url)
                    feed_title = feed.feed.get("title", "RSS è®¢é˜…")

                    # Content summary logic...
                    content = ""
                    if hasattr(latest_entry, "summary"):
                        content = latest_entry.summary
                    elif hasattr(latest_entry, "content") and latest_entry.content:
                        content = latest_entry.content[0].get("value", "")
                    elif hasattr(latest_entry, "description"):
                        content = latest_entry.description

                    import re

                    content_clean = re.sub(r"<[^>]+>", "", content).strip()

                    if content_clean:
                        summary = await generate_entry_summary(
                            title, content_clean, link
                        )
                    else:
                        summary = "æš‚æ— æ‘˜è¦"

                    uid = sub["user_id"]
                    plat = sub.get("platform", "telegram")
                    key = (plat, uid)

                    if key not in user_updates:
                        user_updates[key] = []

                    update_item = {
                        "feed_title": feed_title,
                        "title": title,
                        "summary": summary,
                        "link": link,
                        "sub_id": sub["id"],
                        "entry_id": entry_id,
                        "etag": getattr(feed, "etag", None),
                        "modified": getattr(feed, "modified", None),
                    }

                    user_updates[key].append(update_item)
                    all_pending_updates.append(update_item)

        except Exception as e:
            logger.error(f"Error checking feed {url}: {e}")

    # 4. æ ¼å¼åŒ–è¾“å‡º (æŒ‰ç”¨æˆ·æ±‡æ€»)
    final_output = ""
    # å¦‚æœæ˜¯æŒ‡å®šç”¨æˆ· (Tool åœºæ™¯)ï¼Œç”Ÿæˆä¸€ä¸ªå¤§çš„æ–‡æœ¬å—
    # æ³¨æ„ï¼šTool åœºæ™¯é€šå¸¸åªé’ˆå¯¹å•ä¸€å¹³å° (Telegram) æˆ–è€…éœ€è¦é€‚é…
    if user_id:
        for key, updates in user_updates.items():
            if key[1] == user_id:
                final_output += (
                    f"ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ ({len(updates)} æ¡æ›´æ–°) [via {key[0]}]**\n\n"
                )
                for update in updates:
                    final_output += (
                        f"ğŸ”¹ **{update['feed_title']}**\n"
                        f"[{update['title']}]({update['link']})\n"
                        f"ğŸ“ {update['summary']}\n\n"
                    )

    return final_output, all_pending_updates, user_updates


async def mark_updates_as_read(pending_updates: list):
    """æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
    for update in pending_updates:
        try:
            await update_subscription_status(
                update["sub_id"], update["entry_id"], update["etag"], update["modified"]
            )
        except Exception as e:
            logger.error(
                f"Failed to update subscription status for sub {update['sub_id']}: {e}"
            )


async def check_and_send_rss_updates(subscriptions: list):
    """
    [å®šæ—¶ä»»åŠ¡é€»è¾‘] æ£€æŸ¥å¹¶ç›´æ¥å‘é€ RSS æ›´æ–° (å¸¦é”)
    """
    if _rss_check_lock.locked():
        logger.info("RSS check already in progress, waiting for lock...")

    async with _rss_check_lock:
        try:
            _, _, user_updates_map = await fetch_formatted_rss_updates(
                subscriptions=subscriptions
            )
        except Exception as e:
            logger.error(f"Fetch updates failed: {e}")
            return 0

        if not user_updates_map:
            return 0

        sent_count = 0
        success_updates = []

        # æ‰¹é‡å‘é€æ¶ˆæ¯
        for (platform, uid), updates in user_updates_map.items():
            msg_header = f"ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ ({len(updates)} æ¡æ›´æ–°)**\n\n"
            msg_body = ""
            current_batch = []

            for update in updates:
                item_text = (
                    f"ğŸ”¹ **{update['feed_title']}**\n"
                    f"[{update['title']}]({update['link']})\n"
                    f"ğŸ“ {update['summary']}\n\n"
                )

                # é•¿åº¦æ£€æŸ¥ & åˆ†æ‰¹å‘é€
                if len(msg_header) + len(msg_body) + len(item_text) > 4000:
                    try:
                        await send_via_adapter(
                            chat_id=uid, text=msg_header + msg_body, platform=platform
                        )
                        success_updates.extend(current_batch)
                        sent_count += 1
                    except Exception as e:
                        logger.error(
                            f"Failed to send batch to {uid} on {platform}: {e}"
                        )

                    msg_body = ""
                    msg_header = "ğŸ“¢ **RSS è®¢é˜…æ—¥æŠ¥ (ç»­)**\n\n"
                    current_batch = []

                msg_body += item_text
                current_batch.append(update)

            if msg_body:
                try:
                    await send_via_adapter(
                        chat_id=uid, text=msg_header + msg_body, platform=platform
                    )
                    success_updates.extend(current_batch)
                    sent_count += 1
                except Exception as e:
                    logger.error(
                        f"Failed to send final batch to {uid} on {platform}: {e}"
                    )

        # ç»Ÿä¸€æ›´æ–°æ•°æ®åº“
        await mark_updates_as_read(success_updates)

        return sent_count


async def check_rss_updates_job():
    """æ£€æŸ¥ RSS æ›´æ–°çš„ä»»åŠ¡ (å®šæ—¶è°ƒç”¨)"""
    logger.info("Checking for RSS updates...")

    subscriptions = await get_all_subscriptions()
    if not subscriptions:
        logger.info("No subscriptions found.")
        return

    await check_and_send_rss_updates(subscriptions)


async def trigger_manual_rss_check(user_id: int) -> str:
    """
    [Tool Logic] æ‰‹åŠ¨è§¦å‘ç‰¹å®šç”¨æˆ·çš„ RSS æ£€æŸ¥
    è¿”å›æ ¼å¼åŒ–åçš„æ›´æ–°å†…å®¹æ–‡æœ¬ï¼Œä¸ç›´æ¥å‘é€ã€‚
    """
    # è·å–é”
    if _rss_check_lock.locked():
        return "âš ï¸ æ­£åœ¨è¿›è¡Œå®šæ—¶æ›´æ–°æ£€æŸ¥ï¼Œè¯·ç¨åå†è¯•ã€‚"

    async with _rss_check_lock:
        formatted_text, all_pending, _ = await fetch_formatted_rss_updates(
            user_id=user_id
        )

        if all_pending:
            # æ ‡è®°ä¸ºå·²è¯» (å› ä¸ºå³å°†è¿”å›ç»™ Agent å±•ç¤º)
            await mark_updates_as_read(all_pending)
            return formatted_text
        else:
            return ""


def start_rss_scheduler():
    """å¯åŠ¨ RSS æ£€æŸ¥å®šæ—¶ä»»åŠ¡"""
    # æµ‹è¯•æœŸé—´æ”¹ä¸º 1 åˆ†é’Ÿ
    interval = 60

    scheduler.add_job(
        check_rss_updates_job,
        "interval",
        seconds=interval,
        next_run_time=datetime.datetime.now() + datetime.timedelta(seconds=10),
        id="rss_check",
        replace_existing=True,
    )
    logger.info(f"RSS scheduler started, interval={interval}s")


# --- è‚¡ç¥¨ç›¯ç›˜æ¨é€ ---


def is_trading_time() -> bool:
    """
    åˆ¤æ–­å½“å‰æ˜¯å¦ä¸º A è‚¡äº¤æ˜“æ—¶æ®µ
    - å‘¨ä¸€è‡³å‘¨äº”
    - ä¸Šåˆ 9:30-11:30ï¼Œä¸‹åˆ 13:00-15:00
    """
    now = datetime.datetime.now()

    # å‘¨æœ«ä¸äº¤æ˜“ (0=å‘¨ä¸€, 6=å‘¨æ—¥)
    if now.weekday() >= 5:
        return False

    current_time = now.time()

    # ä¸Šåˆäº¤æ˜“æ—¶æ®µ: 9:30 - 11:30
    morning_start = datetime.time(9, 30)
    morning_end = datetime.time(11, 30)

    # ä¸‹åˆäº¤æ˜“æ—¶æ®µ: 13:00 - 15:00
    afternoon_start = datetime.time(13, 0)
    afternoon_end = datetime.time(15, 0)

    return (
        morning_start <= current_time <= morning_end
        or afternoon_start <= current_time <= afternoon_end
    )


async def stock_push_job():
    """æ¯ 10 åˆ†é’Ÿæ¨é€è‚¡ç¥¨è¡Œæƒ…"""
    if not is_trading_time():
        logger.debug("Not trading time, skipping stock push")
        return

    logger.info("Starting stock push job...")

    # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯å¼•ç”¨
    from services.stock_service import fetch_stock_quotes, format_stock_message

    try:
        # è·å–æ‰€æœ‰æœ‰è‡ªé€‰è‚¡çš„ç”¨æˆ· (returns list of (user_id, platform))
        users_with_platform = await get_all_watchlist_users()

        if not users_with_platform:
            logger.info("No users with watchlist, skipping")
            return

        for user_id, platform in users_with_platform:
            try:
                # è·å–ç”¨æˆ·è‡ªé€‰è‚¡ (filtered by platform)
                watchlist = await get_user_watchlist(user_id, platform=platform)
                if not watchlist:
                    continue

                # æå–è‚¡ç¥¨ä»£ç 
                stock_codes = [item["stock_code"] for item in watchlist]

                # æ‰¹é‡è·å–è¡Œæƒ…
                quotes = await fetch_stock_quotes(stock_codes)

                if not quotes:
                    continue

                # æ ¼å¼åŒ–æ¶ˆæ¯
                message = format_stock_message(quotes)

                # æ¨é€ç»™ç”¨æˆ· (via specific platform)
                await send_via_adapter(chat_id=user_id, text=message, platform=platform)
                logger.info(f"Sent stock quotes to user {user_id} on {platform}")

            except Exception as e:
                logger.error(
                    f"Failed to send stock quotes to {user_id} on {platform}: {e}"
                )

    except Exception as e:
        logger.error(f"Stock push job error: {e}")


async def trigger_manual_stock_check(user_id: int) -> str:
    """
    [Tool Logic] æ‰‹åŠ¨è§¦å‘ç‰¹å®šç”¨æˆ·çš„è‡ªé€‰è‚¡è¡Œæƒ…åˆ·æ–°
    è¿”å›æ ¼å¼åŒ–åçš„è¡Œæƒ…æ–‡æœ¬
    """
    from services.stock_service import fetch_stock_quotes, format_stock_message

    try:
        # è·å–ç”¨æˆ·è‡ªé€‰è‚¡
        watchlist = await get_user_watchlist(user_id)
        if not watchlist:
            return ""  # Empty watchlist

        # æå–è‚¡ç¥¨ä»£ç 
        stock_codes = [item["stock_code"] for item in watchlist]

        # æ‰¹é‡è·å–è¡Œæƒ…
        quotes = await fetch_stock_quotes(stock_codes)

        if not quotes:
            return "âŒ æ— æ³•è·å–è¡Œæƒ…æ•°æ®ï¼Œè¯·ç¨åé‡è¯•ã€‚"

        # æ ¼å¼åŒ–æ¶ˆæ¯
        message = format_stock_message(quotes)
        return message

    except Exception as e:
        logger.error(f"Manual stock check error for {user_id}: {e}")
        return f"âŒ åˆ·æ–°å¤±è´¥: {str(e)}"


def start_stock_scheduler():
    """å¯åŠ¨è‚¡ç¥¨æ¨é€å®šæ—¶ä»»åŠ¡"""
    interval = 10 * 60  # 10 åˆ†é’Ÿ

    scheduler.add_job(
        stock_push_job,
        "interval",
        seconds=interval,
        next_run_time=datetime.datetime.now() + datetime.timedelta(seconds=30),
        id="stock_push",
        replace_existing=True,
    )
    logger.info(f"Stock scheduler started, interval={interval}s")


# --- åŠ¨æ€ Skill è°ƒåº¦ ---


async def run_skill_cron_job(skill_name: str, instruction: str):
    """
    é€šç”¨ Skill å®šæ—¶ä»»åŠ¡æ‰§è¡Œå™¨
    """
    if not skill_name:
        return

    logger.info(f"[Cron] Executing scheduled skill: {skill_name}")

    try:
        from services.skill_executor import skill_executor

        # æ„é€ ç³»ç»Ÿä¸Šä¸‹æ–‡
        system_ctx = UnifiedContext(
            platform="system",
            message=None,  # System messages have no triggers
        )

        if not instruction:
            instruction = "Execute scheduled maintenance/run_cron task."

        async for chunk, files in skill_executor.execute_skill(
            skill_name, instruction, ctx=system_ctx
        ):
            if chunk and chunk.strip():
                logger.info(f"[Cron {skill_name}] Output: {chunk[:100]}...")

    except Exception as e:
        logger.error(f"[Cron] Failed to run skill {skill_name}: {e}")


def start_dynamic_skill_scheduler():
    """
    æ‰«ææ•°æ®åº“ä¸­çš„ä»»åŠ¡å¹¶æ³¨å†Œå®šæ—¶ä»»åŠ¡
    """
    logger.info("Scanning for dynamic skill jobs...")

    # 1. Load from DB (Primary Source)
    async def load_db_tasks():
        tasks = await get_all_active_tasks()
        count = 0
        for task in tasks:
            task_id = task["id"]
            skill_name = task["skill_name"]
            crontab = task["crontab"]
            instruction = task["instruction"]

            try:
                parts = crontab.split()
                if len(parts) == 5:
                    trigger = CronTrigger(
                        minute=parts[0],
                        hour=parts[1],
                        day=parts[2],
                        month=parts[3],
                        day_of_week=parts[4],
                    )

                    scheduler.add_job(
                        run_skill_cron_job,
                        trigger,
                        id=f"cron_db_{task_id}_{skill_name}",
                        args=[skill_name, instruction],
                        replace_existing=True,
                    )
                    count += 1
                else:
                    logger.warning(
                        f"Invalid crontab format for task {task_id}: {crontab}"
                    )
            except Exception as e:
                logger.error(f"Failed to register DB cron for {skill_name}: {e}")

        logger.info(f"Registered {count} jobs from Database.")

    # Run task loader once
    # We can just run it now since we are in async context when starting services?
    # Or schedule it to run in 1s.

    # But scheduler needs to be running.
    # We will call start() in main.

    scheduler.add_job(
        load_db_tasks,
        "date",
        run_date=datetime.datetime.now() + datetime.timedelta(seconds=1),
    )
