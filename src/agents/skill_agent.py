"""
Skill Agent - æ™ºèƒ½æ‰§è¡Œä»£ç†
"""

import os

import logging
import asyncio
import json
from typing import Optional, Dict, Any, Tuple, AsyncGenerator

from core.config import gemini_client, GEMINI_MODEL
from core.skill_loader import skill_loader
from services.sandbox_executor import sandbox_executor
from core.prompts import SKILL_AGENT_DECISION_PROMPT

logger = logging.getLogger(__name__)


class SkillDelegationRequest:
    """Delegation Request Object"""

    def __init__(self, target_skill: str, instruction: str):
        self.target_skill = target_skill
        self.instruction = instruction

    def __str__(self):
        return f"[Delegation -> {self.target_skill}: {self.instruction}]"


class SkillDecision:
    """Decision made by the Agent"""

    def __init__(
        self,
        action: str,
        content: Any = None,
        execute_type: str = None,
        target_skill: str = None,
        instruction: str = None,
    ):
        self.action = action
        self.content = content
        self.execute_type = execute_type
        self.target_skill = target_skill
        self.instruction = instruction

    def __eq__(self, other):
        if not isinstance(other, SkillDecision):
            return False
        return (
            self.action == other.action
            and self.content == other.content
            and self.execute_type == other.execute_type
            and self.target_skill == other.target_skill
            and self.instruction == other.instruction
        )

    def __str__(self):
        return f"[Decision: {self.action} {self.execute_type or ''} {self.target_skill or ''}]"


class SkillFinalReply:
    """Final Reply Object - marks that the skill has completed all steps"""

    def __init__(self, content: str):
        self.content = content

    def __str__(self):
        return f"[Final Reply: {self.content[:50]}...]"


class SkillAgent:
    """
    Skill Agent
    Replaces SkillExecutor. Uses LLM to decide between EXECUTE, DELEGATE, or REPLY.
    """

    async def execute_skill(
        self,
        skill_name: str,
        user_request: str,
        extra_context: str = "",
        input_files: Dict[str, bytes] = None,
        ctx: Any = None,
        **kwargs,
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]], Any], None]:
        """
        Execute skill logic via Agent thinking.
        Yields: (status_msg, files, result_object)

        result_object can be SkillDelegationRequest.
        """

        # 1. Load context and documentation
        skill_info = skill_loader.get_skill(skill_name)
        if not skill_info:
            yield f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½: {skill_name}", None, None
            return

        skill_content = skill_info.get("skill_md_content", "")
        skill_dir = skill_info.get("skill_dir", "")

        # æ›¿æ¢ skill_content ä¸­çš„éæ•æ„Ÿç¯å¢ƒå˜é‡ä¸ºå®é™…å€¼
        for key, value in os.environ.items():
            if key.startswith("X_"):
                # æ”¯æŒ ${X_VAR} æ ¼å¼
                skill_content = skill_content.replace(f"${{{key}}}", value)
                # æ”¯æŒ $X_VAR æ ¼å¼
                skill_content = skill_content.replace(f"${key}", value)

        logger.debug(f"skill_content: {skill_content}")
        # 2. Think (Decision Making)
        yield f"ğŸ§  SkillAgent ({skill_name}) æ­£åœ¨æ€è€ƒ...", None, None

        decision = await self._think(
            skill_name, skill_content, user_request, extra_context
        )

        action = decision.get("action")
        logger.info(f"SkillAgent Decision: {action} - {decision}")

        # Yield Decision Object for loop detection
        skill_decision = SkillDecision(
            action=action,
            content=decision.get("content"),
            execute_type=decision.get("execute_type"),
            target_skill=decision.get("target_skill"),
            instruction=decision.get("instruction"),
        )
        yield "", None, skill_decision

        # 3. Act based on decision
        if action == "REPLY":
            content = decision.get("content", "")
            # ä½¿ç”¨ SkillFinalReply æ ‡è¯†è¿™æ˜¯æœ€ç»ˆå›å¤
            yield content, None, SkillFinalReply(content)
            return

        elif action == "DELEGATE":
            target = decision.get("target_skill")
            instruction = decision.get("instruction")
            delegation = SkillDelegationRequest(target, instruction)
            yield f"ğŸ‘‰ å§”æ‰˜ç»™ `{target}`...", None, delegation
            return

        elif action == "EXECUTE":
            execute_type = decision.get("execute_type")
            content = decision.get("content")

            if execute_type == "SCRIPT":
                # Run execute.py
                # å¢å¼ºå¯è§æ€§ï¼šæ˜¾ç¤ºè„šæœ¬å‚æ•°
                yield f"ğŸ“œ æ­£åœ¨è¿è¡Œè„šæœ¬ï¼Œå‚æ•°: `{content}`", None, None

                async for msg, files, result_obj in self._run_script(
                    skill_name, skill_dir, content, ctx
                ):
                    yield msg, files, result_obj

            elif execute_type == "COMMAND":
                # Run shell command directly
                # å¢å¼ºå¯è§æ€§ï¼šæ˜¾ç¤ºå…·ä½“å‘½ä»¤
                yield f"âš™ï¸ æˆ‘æ­£åœ¨æ‰§è¡Œ Shell å‘½ä»¤: `{content}`", None, None

                success, output = await sandbox_executor.execute_shell_command(
                    command=content, skill_dir=skill_dir
                )

                if output.strip():
                    yield f"ğŸ“‹ æ‰§è¡Œè¾“å‡º:\n```\n{output}\n```", None, None
                else:
                    yield "âœ… æ‰§è¡Œå®Œæˆ (æ— è¾“å‡º)ã€‚", None, None

                # Return structured result with ğŸ”‡ğŸ”‡ğŸ”‡ prefix to signal task completion
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                result_text = f"ğŸ”‡ğŸ”‡ğŸ”‡âœ… Shell å‘½ä»¤æ‰§è¡Œ{status}ã€‚" + (
                    f" è¾“å‡º: {output[:200]}" if output.strip() else ""
                )
                yield (
                    result_text,
                    None,
                    {"text": result_text, "ui": {}, "success": success},
                )

            elif execute_type == "CODE":
                # Run generated python code
                yield "âš™ï¸ æˆ‘æ­£åœ¨æ‰§è¡Œä»£ç  (CODE)...", None, None

                success, output, output_files = await sandbox_executor.execute_code(
                    code=content, input_files=input_files, skill_dir=skill_dir
                )

                # Build structured result for agent feedback
                file_names = list(output_files.keys()) if output_files else []
                result_summary = []

                if output_files:
                    result_summary.append(
                        f"ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡ä»¶: {', '.join(file_names)}"
                    )
                    # Send files to user
                    yield (
                        f"âœ… æ‰§è¡Œå®Œæˆï¼Œç”Ÿæˆ {len(output_files)} ä¸ªæ–‡ä»¶ã€‚",
                        output_files,
                        None,
                    )

                if output.strip():
                    result_summary.append(f"è¾“å‡º:\n{output[:500]}")
                    yield f"ğŸ“‹ æ‰§è¡Œè¾“å‡º:\n```\n{output}\n```", None, None

                # Return structured result with ğŸ”‡ğŸ”‡ğŸ”‡ prefix to signal task completion
                status = "æˆåŠŸ" if success else "å¤±è´¥"
                result_text = f"ğŸ”‡ğŸ”‡ğŸ”‡âœ… ä»£ç æ‰§è¡Œ{status}ã€‚" + " ".join(result_summary)
                yield (
                    result_text,
                    None,
                    {
                        "text": result_text,
                        "ui": {},
                        "success": success,
                        "files": file_names,
                    },
                )

            else:
                yield f"âŒ æœªçŸ¥æ‰§è¡Œç±»å‹: {execute_type}", None, None

        else:
            yield f"âŒ Agent å†³ç­–æ— æ•ˆ: {action}", None, None

    async def _think(
        self, skill_name, skill_content, user_request, extra_context
    ) -> Dict[str, Any]:
        """Call LLM to decide action"""
        prompt = SKILL_AGENT_DECISION_PROMPT.format(
            skill_content=skill_content[:20000],
            user_request=user_request,
            extra_context=extra_context,
        )
        logger.debug(f"SkillAgent Decision Prompt: {prompt}")

        try:
            response = await gemini_client.aio.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt,
                config={"response_mime_type": "application/json"},
            )
            text = response.text
            logger.info(f"SkillAgent Decision Response: {text}")
            if not text:
                logger.error("Thinking failed: Empty response from AI")
                return {"action": "REPLY", "content": "å†³ç­–ç³»ç»Ÿæ•…éšœ: AI è¿”å›äº†ç©ºå“åº”ã€‚"}

            # Clean markdown code blocks if present (just in case)
            if text.startswith("```"):
                import re

                text = re.sub(r"^```json\s*", "", text)
                text = re.sub(r"^```\s*", "", text)
                text = re.sub(r"\s*```$", "", text)

            data = json.loads(text)

            # Robustness: Handle if LLM returns a list [ {action...} ]
            if isinstance(data, list):
                if len(data) > 0 and isinstance(data[0], dict):
                    data = data[0]
                else:
                    return {
                        "action": "REPLY",
                        "content": f"å†³ç­–æ ¼å¼é”™è¯¯: AI è¿”å›äº†åˆ—è¡¨ä½†æ— æ³•è§£æ: {text[:100]}",
                    }

            if not isinstance(data, dict):
                return {
                    "action": "REPLY",
                    "content": f"å†³ç­–æ ¼å¼é”™è¯¯: AI è¿”å›äº†éå­—å…¸ç±»å‹: {type(data)}",
                }

            return data
        except Exception as e:
            logger.error(
                f"Thinking failed: {e}. Raw response: {response.text if 'response' in locals() else 'N/A'}"
            )
            return {"action": "REPLY", "content": f"å†³ç­–ç³»ç»Ÿæ•…éšœ: {e}"}

    async def _run_script(self, skill_name, skill_dir, params, ctx):
        """Legacy/Standard execute.py runner"""
        import os
        import sys
        import importlib.util

        execute_script = os.path.join(skill_dir, "scripts", "execute.py")
        if not os.path.exists(execute_script):
            yield f"âŒ æ‰¾ä¸åˆ°è„šæœ¬: {execute_script}", None, None
            return

        try:
            spec = importlib.util.spec_from_file_location(
                f"{skill_name}_execute", execute_script
            )
            module = importlib.util.module_from_spec(spec)
            sys.modules[f"{skill_name}_execute"] = module
            spec.loader.exec_module(module)

            if not hasattr(module, "execute"):
                yield "âŒ è„šæœ¬ç¼ºå°‘ execute å‡½æ•°", None, None
                return

            # Execute
            import inspect

            if inspect.isasyncgenfunction(module.execute):
                async for chunk in module.execute(ctx, params):
                    if isinstance(chunk, str):
                        yield chunk, None, None
                    elif isinstance(chunk, dict) and (
                        "text" in chunk or "ui" in chunk or "files" in chunk
                    ):
                        yield chunk.get("text", ""), chunk.get("files"), chunk
                    else:
                        yield f"{chunk}", None, None
                return

            if asyncio.iscoroutinefunction(module.execute):
                result = await module.execute(ctx, params)
            else:
                result = module.execute(ctx, params)

            # logger.info(f"Skill {skill_name} output: {result}")
            if isinstance(result, str):
                yield result, None, None
            elif isinstance(result, dict) and (
                "text" in result or "ui" in result or "files" in result
            ):
                # Structured result (text + ui + files)
                yield result.get("text", ""), result.get("files"), result
            else:
                yield f"âœ… æ‰§è¡Œç»“æœ: {result}", None, None

        except Exception as e:
            logger.error(f"Script execution error: {e}")
            yield f"âŒ æ‰§è¡Œå‡ºé”™: {e}", None, None


# Singleton
skill_agent = SkillAgent()
