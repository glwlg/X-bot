"""
Skill Agent - Êô∫ËÉΩÊâßË°å‰ª£ÁêÜ
"""

import os

import logging
import asyncio
import json
from typing import Optional, Dict, Any, Tuple, AsyncGenerator

from core.config import gemini_client, GEMINI_MODEL
from core.skill_loader import skill_loader
from services.sandbox_executor import sandbox_executor
from core.prompts import SKILL_AGENT_DECISION_PROMPT

logger = logging.getLogger(__name__)


class SkillDelegationRequest:
    """Delegation Request Object"""

    def __init__(self, target_skill: str, instruction: str):
        self.target_skill = target_skill
        self.instruction = instruction

    def __str__(self):
        return f"[Delegation -> {self.target_skill}: {self.instruction}]"


class SkillDecision:
    """Decision made by the Agent"""

    def __init__(
        self,
        action: str,
        content: Any = None,
        execute_type: str = None,
        target_skill: str = None,
        instruction: str = None,
    ):
        self.action = action
        self.content = content
        self.execute_type = execute_type
        self.target_skill = target_skill
        self.instruction = instruction

    def __eq__(self, other):
        if not isinstance(other, SkillDecision):
            return False
        return (
            self.action == other.action
            and self.content == other.content
            and self.execute_type == other.execute_type
            and self.target_skill == other.target_skill
            and self.instruction == other.instruction
        )

    def __str__(self):
        return f"[Decision: {self.action} {self.execute_type or ''} {self.target_skill or ''}]"


class SkillFinalReply:
    """Final Reply Object - marks that the skill has completed all steps"""

    def __init__(self, content: str):
        self.content = content

    def __str__(self):
        return f"[Final Reply: {self.content[:50]}...]"


class SkillAgent:
    """
    Skill Agent
    Replaces SkillExecutor. Uses LLM to decide between EXECUTE, DELEGATE, or REPLY.
    """

    async def execute_skill(
        self,
        skill_name: str,
        user_request: str,
        extra_context: str = "",
        input_files: Dict[str, bytes] = None,
        ctx: Any = None,
        **kwargs,
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]], Any], None]:
        """
        Execute skill logic via Agent thinking.
        Yields: (status_msg, files, result_object)

        result_object can be SkillDelegationRequest.
        """

        # 1. Load context and documentation
        skill_info = skill_loader.get_skill(skill_name)
        if not skill_info:
            yield f"‚ùå Êâæ‰∏çÂà∞ÊäÄËÉΩ: {skill_name}", None, None
            return

        skill_content = skill_info.get("skill_md_content", "")
        skill_dir = skill_info.get("skill_dir", "")

        # ÊõøÊç¢ skill_content ‰∏≠ÁöÑÈùûÊïèÊÑüÁéØÂ¢ÉÂèòÈáè‰∏∫ÂÆûÈôÖÂÄº
        for key, value in os.environ.items():
            if key.startswith("X_"):
                # ÊîØÊåÅ ${X_VAR} Ê†ºÂºè
                skill_content = skill_content.replace(f"${{{key}}}", value)
                # ÊîØÊåÅ $X_VAR Ê†ºÂºè
                skill_content = skill_content.replace(f"${key}", value)

        logger.debug(f"skill_content: {skill_content}")
        # 2. Think (Decision Making)
        yield f"üß† SkillAgent ({skill_name}) Ê≠£Âú®ÊÄùËÄÉ...", None, None

        decision = await self._think(
            skill_name, skill_content, user_request, extra_context
        )

        action = decision.get("action")
        logger.info(f"SkillAgent Decision: {action} - {decision}")

        # Yield Decision Object for loop detection
        skill_decision = SkillDecision(
            action=action,
            content=decision.get("content"),
            execute_type=decision.get("execute_type"),
            target_skill=decision.get("target_skill"),
            instruction=decision.get("instruction"),
        )
        yield "", None, skill_decision

        # 3. Act based on decision
        if action == "REPLY":
            content = decision.get("content", "")
            # ‰ΩøÁî® SkillFinalReply Ê†áËØÜËøôÊòØÊúÄÁªàÂõûÂ§ç
            yield content, None, SkillFinalReply(content)
            return

        elif action == "DELEGATE":
            target = decision.get("target_skill")
            instruction = decision.get("instruction")
            delegation = SkillDelegationRequest(target, instruction)
            yield f"üëâ ÂßîÊâòÁªô `{target}`...", None, delegation
            return

        elif action == "EXECUTE":
            execute_type = decision.get("execute_type")
            content = decision.get("content")

            if execute_type == "SCRIPT":
                # Run execute.py
                # Â¢ûÂº∫ÂèØËßÅÊÄßÔºöÊòæÁ§∫ËÑöÊú¨ÂèÇÊï∞
                yield f"üìú Ê≠£Âú®ËøêË°åËÑöÊú¨ÔºåÂèÇÊï∞: `{content}`", None, None

                async for msg, files, result_obj in self._run_script(
                    skill_name, skill_dir, content, ctx
                ):
                    yield msg, files, result_obj

            elif execute_type == "COMMAND":
                # Run shell command directly
                # Â¢ûÂº∫ÂèØËßÅÊÄßÔºöÊòæÁ§∫ÂÖ∑‰ΩìÂëΩ‰ª§
                yield f"‚öôÔ∏è ÊàëÊ≠£Âú®ÊâßË°å Shell ÂëΩ‰ª§: `{content}`", None, None

                success, output = await sandbox_executor.execute_shell_command(
                    command=content, skill_dir=skill_dir
                )

                if output.strip():
                    yield f"üìã ÊâßË°åËæìÂá∫:\n```\n{output}\n```", None, None
                else:
                    yield "‚úÖ ÊâßË°åÂÆåÊàê (Êó†ËæìÂá∫)„ÄÇ", None, None

                # Return structured result with üîáüîáüîá prefix to signal task completion
                status = "ÊàêÂäü" if success else "Â§±Ë¥•"
                result_text = f"üîáüîáüîá‚úÖ Shell ÂëΩ‰ª§ÊâßË°å{status}„ÄÇ" + (
                    f" ËæìÂá∫: {output[:200]}" if output.strip() else ""
                )
                yield (
                    result_text,
                    None,
                    {"text": result_text, "ui": {}, "success": success},
                )

            elif execute_type == "CODE":
                # Run generated python code
                yield "‚öôÔ∏è ÊàëÊ≠£Âú®ÊâßË°å‰ª£Á†Å (CODE)...", None, None

                success, output, output_files = await sandbox_executor.execute_code(
                    code=content, input_files=input_files, skill_dir=skill_dir
                )

                # Build structured result for agent feedback
                file_names = list(output_files.keys()) if output_files else []
                result_summary = []

                if output_files:
                    result_summary.append(
                        f"ÁîüÊàê‰∫Ü {len(output_files)} ‰∏™Êñá‰ª∂: {', '.join(file_names)}"
                    )
                    # Send files to user
                    yield (
                        f"‚úÖ ÊâßË°åÂÆåÊàêÔºåÁîüÊàê {len(output_files)} ‰∏™Êñá‰ª∂„ÄÇ",
                        output_files,
                        None,
                    )

                if output.strip():
                    result_summary.append(f"ËæìÂá∫:\n{output[:500]}")
                    yield f"üìã ÊâßË°åËæìÂá∫:\n```\n{output}\n```", None, None

                # Return structured result with üîáüîáüîá prefix to signal task completion
                status = "ÊàêÂäü" if success else "Â§±Ë¥•"
                result_text = f"üîáüîáüîá‚úÖ ‰ª£Á†ÅÊâßË°å{status}„ÄÇ" + " ".join(result_summary)
                yield (
                    result_text,
                    None,
                    {
                        "text": result_text,
                        "ui": {},
                        "success": success,
                        "files": file_names,
                    },
                )

            else:
                yield f"‚ùå Êú™Áü•ÊâßË°åÁ±ªÂûã: {execute_type}", None, None

        else:
            yield f"‚ùå Agent ÂÜ≥Á≠ñÊó†Êïà: {action}", None, None

    async def _think(
        self, skill_name, skill_content, user_request, extra_context
    ) -> Dict[str, Any]:
        """Call LLM to decide action"""
        prompt = SKILL_AGENT_DECISION_PROMPT.format(
            skill_content=skill_content[:20000],
            user_request=user_request,
            extra_context=extra_context,
        )
        logger.debug(f"SkillAgent Decision Prompt: {prompt}")

        try:
            response = await gemini_client.aio.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt,
                config={"response_mime_type": "application/json"},
            )
            text = response.text
            logger.info(f"SkillAgent Decision Response: {text}")
            if not text:
                logger.error("Thinking failed: Empty response from AI")
                return {"action": "REPLY", "content": "ÂÜ≥Á≠ñÁ≥ªÁªüÊïÖÈöú: AI ËøîÂõû‰∫ÜÁ©∫ÂìçÂ∫î„ÄÇ"}

            # Clean markdown code blocks if present (just in case)
            if text.startswith("```"):
                import re

                text = re.sub(r"^```json\s*", "", text)
                text = re.sub(r"^```\s*", "", text)
                text = re.sub(r"\s*```$", "", text)

            data = json.loads(text)

            # Robustness: Handle if LLM returns a list [ {action...} ]
            if isinstance(data, list):
                if len(data) > 0 and isinstance(data[0], dict):
                    data = data[0]
                else:
                    return {
                        "action": "REPLY",
                        "content": f"ÂÜ≥Á≠ñÊ†ºÂºèÈîôËØØ: AI ËøîÂõû‰∫ÜÂàóË°®‰ΩÜÊó†Ê≥ïËß£Êûê: {text[:100]}",
                    }

            if not isinstance(data, dict):
                return {
                    "action": "REPLY",
                    "content": f"ÂÜ≥Á≠ñÊ†ºÂºèÈîôËØØ: AI ËøîÂõû‰∫ÜÈùûÂ≠óÂÖ∏Á±ªÂûã: {type(data)}",
                }

            return data
        except Exception as e:
            logger.error(
                f"Thinking failed: {e}. Raw response: {response.text if 'response' in locals() else 'N/A'}"
            )
            return {"action": "REPLY", "content": f"ÂÜ≥Á≠ñÁ≥ªÁªüÊïÖÈöú: {e}"}

    async def _run_script(self, skill_name, skill_dir, params, ctx):
        """Legacy/Standard execute.py runner"""
        import os
        import sys
        import importlib.util

        execute_script = os.path.join(skill_dir, "scripts", "execute.py")
        if not os.path.exists(execute_script):
            yield f"‚ùå Êâæ‰∏çÂà∞ËÑöÊú¨: {execute_script}", None, None
            return

        try:
            spec = importlib.util.spec_from_file_location(
                f"{skill_name}_execute", execute_script
            )
            module = importlib.util.module_from_spec(spec)
            sys.modules[f"{skill_name}_execute"] = module
            spec.loader.exec_module(module)

            if not hasattr(module, "execute"):
                yield "‚ùå ËÑöÊú¨Áº∫Â∞ë execute ÂáΩÊï∞", None, None
                return

            # Execute
            import inspect

            def _supports_runtime(fn) -> bool:
                try:
                    signature = inspect.signature(fn)
                    return len(signature.parameters) >= 3
                except Exception:
                    return False

            runtime_arg = None
            has_runtime = _supports_runtime(module.execute)

            if inspect.isasyncgenfunction(module.execute):
                stream = (
                    module.execute(ctx, params, runtime_arg)
                    if has_runtime
                    else module.execute(ctx, params)
                )
                async for chunk in stream:
                    if isinstance(chunk, str):
                        yield chunk, None, None
                    elif isinstance(chunk, dict) and (
                        "text" in chunk or "ui" in chunk or "files" in chunk
                    ):
                        yield chunk.get("text", ""), chunk.get("files"), chunk
                    else:
                        yield f"{chunk}", None, None
                return

            if asyncio.iscoroutinefunction(module.execute):
                if has_runtime:
                    result = await module.execute(ctx, params, runtime_arg)
                else:
                    result = await module.execute(ctx, params)
            else:
                if has_runtime:
                    result = module.execute(ctx, params, runtime_arg)
                else:
                    result = module.execute(ctx, params)

            # logger.info(f"Skill {skill_name} output: {result}")
            if isinstance(result, str):
                yield result, None, None
            elif isinstance(result, dict) and (
                "text" in result or "ui" in result or "files" in result
            ):
                # Structured result (text + ui + files)
                yield result.get("text", ""), result.get("files"), result
            else:
                yield f"‚úÖ ÊâßË°åÁªìÊûú: {result}", None, None

        except Exception as e:
            logger.error(f"Script execution error: {e}")
            yield f"‚ùå ÊâßË°åÂá∫Èîô: {e}", None, None


# Singleton
skill_agent = SkillAgent()
