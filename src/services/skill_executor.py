"""
Skill æ‰§è¡Œå™¨ - åè°ƒ AI ç†è§£å’Œæ‰§è¡Œæ ‡å‡† Skill
"""
import logging
import asyncio
from typing import Optional, Dict, Any, Tuple, AsyncGenerator

from core.config import gemini_client, GEMINI_MODEL
from core.skill_loader import skill_loader
from services.sandbox_executor import sandbox_executor

logger = logging.getLogger(__name__)

# æ ‡å‡† Skill æ‰§è¡Œçš„ç³»ç»Ÿæç¤º
SKILL_EXECUTION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ã€‚ä½ æ­£åœ¨æ‰§è¡Œä¸€ä¸ªç‰¹å®šçš„æŠ€èƒ½ä»»åŠ¡ã€‚

## ä½ æ‹¥æœ‰çš„èƒ½åŠ› (æ¥è‡ª Skill æ–‡æ¡£)

{skill_content}

## å¯ç”¨çš„è¾…åŠ©è„šæœ¬

{scripts_list}

## ä»»åŠ¡

æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œä½¿ç”¨ä¸Šè¿°æ–‡æ¡£ä¸­çš„çŸ¥è¯†æ¥å®Œæˆä»»åŠ¡ã€‚

å¦‚æœéœ€è¦æ‰§è¡Œä»£ç ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```python
# ä½ çš„ Python ä»£ç 
```

## æ²™ç®±é™åˆ¶ (é‡è¦!)

ä»£ç å°†åœ¨å®‰å…¨æ²™ç®±ä¸­æ‰§è¡Œï¼Œä»¥ä¸‹æ˜¯é™åˆ¶ï¼š

1. **ç¦æ­¢ä½¿ç”¨**: subprocess, os.system, eval, exec, socket, urllib
2. **ç½‘ç»œè¯·æ±‚**: å¿…é¡»ä½¿ç”¨ `httpx` åº“ (å·²å®‰è£…)ï¼Œä¸èƒ½ç”¨ curl æˆ– subprocess
3. **æ–‡ä»¶æ“ä½œ**: åªèƒ½åœ¨å½“å‰ç›®å½•è¯»å†™æ–‡ä»¶

å¦‚æœæ–‡æ¡£ä¸­ä½¿ç”¨äº† curl æˆ– shell å‘½ä»¤ç¤ºä¾‹ï¼Œè¯·å°†å…¶è½¬æ¢ä¸ºç­‰æ•ˆçš„ Python/httpx ä»£ç ã€‚

## ç½‘ç»œå¯é æ€§æç¤º

- **wttr.in å¯èƒ½æœ‰ SSL é—®é¢˜**ï¼Œä¼˜å…ˆä½¿ç”¨ **open-meteo.com** API
- å¯¹äºå¤©æ°”æŸ¥è¯¢ï¼Œæ¨èä½¿ç”¨: `https://api.open-meteo.com/v1/forecast?latitude=LAT&longitude=LON&current_weather=true`
- éœ€è¦å…ˆé€šè¿‡åœ°åè·å–ç»çº¬åº¦ï¼Œå¯ä»¥ç”¨: `https://geocoding-api.open-meteo.com/v1/search?name=åŸå¸‚å&count=1`
- æ‰€æœ‰è¯·æ±‚åŠ ä¸Š `timeout=30`

ç¤ºä¾‹ (å¤©æ°”æŸ¥è¯¢):
```python
import httpx

# 1. è·å–åŸå¸‚åæ ‡
geo = httpx.get("https://geocoding-api.open-meteo.com/v1/search?name=Quzhou&count=1", timeout=30).json()
lat, lon = geo["results"][0]["latitude"], geo["results"][0]["longitude"]

# 2. è·å–å¤©æ°”
weather = httpx.get(f"https://api.open-meteo.com/v1/forecast?latitude={{lat}}&longitude={{lon}}&current_weather=true", timeout=30).json()
print(f"æ¸©åº¦: {{weather['current_weather']['temperature']}}Â°C")
```

## ç”¨æˆ·è¯·æ±‚

{user_request}

## é™„åŠ ä¸Šä¸‹æ–‡

{extra_context}
"""


class SkillExecutor:
    """
    æ ‡å‡† Skill æ‰§è¡Œå™¨
    
    å·¥ä½œæµç¨‹ï¼š
    1. åŠ è½½ SKILL.md å†…å®¹
    2. å°†å†…å®¹æ³¨å…¥åˆ° AI ä¸Šä¸‹æ–‡
    3. AI ç†è§£ä»»åŠ¡å¹¶ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼ˆå¯èƒ½åŒ…å«ä»£ç ï¼‰
    4. å¦‚æœæœ‰ä»£ç ï¼Œåœ¨æ²™ç®±ä¸­æ‰§è¡Œ
    5. è¿”å›ç»“æœ
    """
    
    async def execute_standard_skill(
        self,
        skill_name: str,
        user_request: str,
        extra_context: str = "",
        input_files: Dict[str, bytes] = None,
        **kwargs
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]]], None]:
        """
        æ‰§è¡Œæ ‡å‡† Skill
        
        Yields:
            (status_message, output_files)
        """
        # 1. è·å– Skill ä¿¡æ¯
        skill_info = skill_loader.get_skill(skill_name)
        if not skill_info:
            yield f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½: {skill_name}", None
            return
        
        if skill_info.get("skill_type") != "standard":
            yield f"âŒ {skill_name} ä¸æ˜¯æ ‡å‡†åè®®æŠ€èƒ½", None
            return
        
        skill_content = skill_info.get("skill_md_content", "")
        skill_dir = skill_info.get("skill_dir", "")
        scripts = skill_info.get("scripts", [])
        source = skill_info.get("source", "")
        
        yield f"ğŸ“š æ­£åœ¨ä½¿ç”¨æŠ€èƒ½ **{skill_name}** å¤„ç†æ‚¨çš„è¯·æ±‚...", None
        
        # **å…³é”®ä¼˜åŒ–**: å¦‚æœæœ‰ execute.py, ç›´æ¥å¯¼å…¥å¹¶è°ƒç”¨ (æ”¯æŒ builtin å’Œ learned)
        if "execute.py" in scripts:
            import os
            import sys
            import importlib.util
            
            execute_script = os.path.join(skill_dir, "scripts", "execute.py")
            
            yield "âš™ï¸ æ­£åœ¨æ‰§è¡Œå†…ç½®è„šæœ¬...", None
            
            try:
                # åŠ¨æ€å¯¼å…¥ execute.py
                spec = importlib.util.spec_from_file_location(f"{skill_name}_execute", execute_script)
                module = importlib.util.module_from_spec(spec)
                sys.modules[f"{skill_name}_execute"] = module
                spec.loader.exec_module(module)
                
                # è°ƒç”¨ execute å‡½æ•°
                if not hasattr(module, "execute"):
                    yield f"âŒ {execute_script} ä¸­æ²¡æœ‰ execute å‡½æ•°", None
                    return
                
                # å‡†å¤‡å‚æ•° - ä½¿ç”¨ AI è§£æ
                update = kwargs.get("update")
                context = kwargs.get("context")
                
                # INJECTION: Inject 'run_skill' into context to enable Skill Composition
                # We attach it directly to 'context' (ephemeral) instead of 'bot_data' (persistent)
                # to avoid PickleError (local functions cannot be pickled).
                async def run_skill_helper(target_skill: str, target_params: dict) -> str:
                    """
                    Helper injected into context to allow skills to call other skills.
                    Returns the final text result.
                    """
                    logger.info(f"[SkillComposition] {skill_name} calling {target_skill}...")
                    final_output = []
                    # Reuse the same executor instance (self)
                    async for msg, files in self.execute_skill(target_skill, "", params=target_params, update=update, context=context):
                         if msg: final_output.append(msg)
                    
                    return "\n".join(final_output)

                if context:
                    # Monkey-patch context object for this execution scope
                    # This is not persisted, so it's safe.
                    setattr(context, 'run_skill', run_skill_helper)
                
                # ä½¿ç”¨ AI ä» SKILL.md ä¸­è§£æå‚æ•°
                params = {}
                if user_request:
                    try:
                        from google.genai import types
                        import json
                        import re
                        
                        logger.info(f"[PARAM_EXTRACT] Starting parameter extraction for {skill_name}")
                        logger.info(f"[PARAM_EXTRACT] User request: {user_request}")
                        
                        prompt = (
                            f"Extract parameters for skill '{skill_name}' from the user instruction.\n\n"
                            f"Skill Documentation:\n{skill_content[:2000]}\n\n"
                            f"User Instruction: {user_request}\n\n"
                            "Based on the skill documentation, extract the required parameters from the user instruction.\n"
                            "Return ONLY a JSON object with the extracted parameters."
                        )
                        
                        response = gemini_client.models.generate_content(
                            model=GEMINI_MODEL,
                            contents=prompt,
                            config={
                                "response_mime_type": "application/json",
                            }
                        )
                        response_text = response.text.strip() if response.text else ""
                        logger.info(f"[PARAM_EXTRACT] AI response: {response_text}")
                        
                        # Clean markdown code blocks if present
                        if response_text.startswith("```"):
                            response_text = re.sub(r"^```json\s*", "", response_text)
                            response_text = re.sub(r"^```\s*", "", response_text)
                            response_text = re.sub(r"\s*```$", "", response_text)
                        
                        if response_text:
                            params = json.loads(response_text)
                            logger.info(f"[PARAM_EXTRACT] Extracted params for {skill_name}: {params}")
                        else:
                            logger.warning(f"[PARAM_EXTRACT] Empty response from AI")
                            params = {"instruction": user_request}
                    except Exception as e:
                        logger.error(f"[PARAM_EXTRACT] Param extraction failed: {e}", exc_info=True)
                        params = {"instruction": user_request}
                else:
                    params = {"instruction": user_request}
                
                # Check if params is a list (concurrent execution)
                if isinstance(params, list):
                    logger.info(f"Detected multiple tasks ({len(params)}), executing concurrently...")
                    yield f"ğŸ”„ æ£€æµ‹åˆ° {len(params)} ä¸ªå­ä»»åŠ¡ï¼Œæ­£åœ¨å¹¶å‘æ‰§è¡Œ...", None
                    
                    async def run_single_task(p):
                        try:
                            if asyncio.iscoroutinefunction(module.execute):
                                return await module.execute(update, context, p)
                            else:
                                return module.execute(update, context, p)
                        except Exception as e:
                            logger.error(f"Subtask failed: {e}")
                            return f"âŒ å­ä»»åŠ¡å¤±è´¥: {e}"

                    results = await asyncio.gather(*(run_single_task(p) for p in params))
                    
                    # Merge results
                    final_result = "\n".join([str(r) for r in results if r])
                    yield f"âœ… å¹¶å‘æ‰§è¡Œå®Œæˆ ({len(results)}/{len(results)})", None
                    if final_result:
                         yield final_result, None
                    return

                # Single execution
                if asyncio.iscoroutinefunction(module.execute):
                    result = await module.execute(update, context, params)
                else:
                    result = module.execute(update, context, params)
                
                # è¿”å›ç»“æœ
                if isinstance(result, str):
                    yield result, None
                else:
                    yield f"âœ… æ‰§è¡Œå®Œæˆ: {str(result)}", None
                
                return
                
            except Exception as e:
                logger.error(f"Error executing builtin script: {e}", exc_info=True)
                yield f"âŒ æ‰§è¡Œé”™è¯¯: {e}", None
                
                # --- Self-Healing (Reactive Repair) ---
                try:
                    update_obj = kwargs.get("update")
                    if update_obj and update_obj.effective_user:
                        yield f"ğŸ”§ ç›‘æµ‹åˆ°å¼‚å¸¸ï¼Œæ­£åœ¨å°è¯•ç”Ÿæˆä¿®å¤è¡¥ä¸...", None
                        
                        from services.skill_creator import update_skill
                        user_id = update_obj.effective_user.id
                        
                        repair_req = f"Fix execution error: {str(e)}\nOriginal Request: {user_request}"
                        
                        result = await update_skill(skill_name, repair_req, user_id)
                        
                        if result["success"]:
                            success_msg = (
                                f"âœ… å·²è‡ªåŠ¨ç”Ÿæˆä¿®å¤æ–¹æ¡ˆï¼\n\n"
                                f"è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤æ‰¹å‡†ä¿®æ”¹ç”Ÿæ•ˆï¼š\n"
                                f"`approve_skill {skill_name}`"
                            )
                            yield success_msg, None
                            
                            # Record Success
                            from core.evolution_router import evolution_router
                            await evolution_router.record_evolution(
                                request=f"Fix skill {skill_name}: {str(e)}",
                                strategy="reactive_repair",
                                success=True,
                                details=f"Generated fix for error: {str(e)[:100]}"
                            )
                            
                        else:
                             err_msg = f"âš ï¸ è‡ªåŠ¨ä¿®å¤å°è¯•å¤±è´¥: {result.get('error')}"
                             yield err_msg, None
                             
                             # Record Failure
                             from core.evolution_router import evolution_router
                             await evolution_router.record_evolution(
                                request=f"Fix skill {skill_name}: {str(e)}",
                                strategy="reactive_repair",
                                success=False,
                                details=f"Fix failed: {result.get('error')}"
                            )
                             
                except Exception as he:
                    logger.error(f"Self-healing failed: {he}")
                
                return
        
        # 2. æ„å»ºæç¤º (learned æŠ€èƒ½æˆ–æ²¡æœ‰ execute.py çš„ builtin æŠ€èƒ½)
        scripts_list = "\n".join([f"- {s}" for s in scripts]) if scripts else "æ— "
        
        prompt = SKILL_EXECUTION_PROMPT.format(
            skill_content=skill_content[:8000],  # æˆªæ–­è¿‡é•¿å†…å®¹
            scripts_list=scripts_list,
            user_request=user_request,
            extra_context=extra_context or "æ— ",
        )
        
        # 3. è°ƒç”¨ AI ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        yield "ğŸ¤” æ­£åœ¨åˆ†æä»»åŠ¡...", None
        
        try:
            response = gemini_client.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt,
                config={
                    "system_instruction": "ä½ æ˜¯ä¸€ä¸ªä»£ç æ‰§è¡ŒåŠ©æ‰‹ã€‚æ ¹æ®æŠ€èƒ½æ–‡æ¡£å®Œæˆç”¨æˆ·ä»»åŠ¡ã€‚å¦‚æœéœ€è¦ç”Ÿæˆæ–‡ä»¶ï¼ŒåŠ¡å¿…ä½¿ç”¨ä»£ç å®ç°ã€‚è¯·æ³¨æ„ï¼šä½ è¿”å›çš„æ‰€æœ‰éä»£ç æ–‡æœ¬å†…å®¹å°†ç›´æ¥ä½œä¸º Telegram Bot çš„å›å¤å‘é€ç»™ç”¨æˆ·ï¼Œè¯·ä¿æŒè¯­æ°”å‹å¥½ã€ç®€æ´ï¼Œå¹¶ä½¿ç”¨ Markdown æ ¼å¼ã€‚",
                },
            )
            
            if not response.text:
                yield "âŒ AI æ— æ³•ç”Ÿæˆè§£å†³æ–¹æ¡ˆ", None
                return
            
            ai_response = response.text
            
        except Exception as e:
            logger.error(f"AI generation error: {e}")
            yield f"âŒ AI æœåŠ¡é”™è¯¯: {e}", None
            return
        
        # 4. æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å—
        import re
        code_blocks = re.findall(r"```python\n(.*?)```", ai_response, re.DOTALL)
        
        if code_blocks:
            yield "âš™ï¸ æ­£åœ¨æ‰§è¡Œä»£ç ...", None
            
            # æ‰§è¡Œæ‰€æœ‰ä»£ç å—
            all_output_files = {}
            execution_output = ""
            
            for i, code in enumerate(code_blocks):
                success, output, output_files = await sandbox_executor.execute_code(
                    code=code,
                    input_files=input_files,
                    skill_dir=skill_dir,
                )
                
                execution_output += f"\n[ä»£ç å— {i+1}]\n{output}\n"
                all_output_files.update(output_files)
                
                if not success:
                    yield f"âš ï¸ ä»£ç æ‰§è¡Œå‡ºç°é—®é¢˜:\n```\n{output}\n```", None
            
            # 5. è¿”å›ç»“æœ
            if all_output_files:
                yield f"âœ… æ‰§è¡Œå®Œæˆï¼ç”Ÿæˆäº† {len(all_output_files)} ä¸ªæ–‡ä»¶ã€‚", all_output_files
            else:
                # æ²¡æœ‰ç”Ÿæˆæ–‡ä»¶ï¼Œè¿”å› AI çš„æ–‡å­—å›å¤
                # ç§»é™¤ä»£ç å—ï¼Œåªä¿ç•™è§£é‡Šæ–‡å­—
                clean_response = re.sub(r"```python\n.*?```", "[å·²æ‰§è¡Œ]", ai_response, flags=re.DOTALL)
                yield clean_response, None
                
                if execution_output.strip():
                    yield f"\nğŸ“‹ æ‰§è¡Œè¾“å‡º:\n```\n{execution_output.strip()}\n```", None
        else:
            # æ²¡æœ‰ä»£ç ï¼Œç›´æ¥è¿”å› AI å›å¤
            yield ai_response, None
    
    async def execute_skill(
        self,
        skill_name: str,
        user_request: str,
        **kwargs
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]]], None]:
        """
        ç»Ÿä¸€æ‰§è¡Œå…¥å£ - è‡ªåŠ¨åˆ¤æ–­ Skill ç±»å‹
        """
        skill_info = skill_loader.get_skill(skill_name)
        
        if not skill_info:
            yield f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½: {skill_name}", None
            return
        
        if skill_info.get("skill_type") == "standard":
            async for msg, files in self.execute_standard_skill(skill_name, user_request, **kwargs):
                yield msg, files
        elif skill_info.get("skill_type") == "legacy":
            async for msg, files in self.execute_legacy_skill(skill_name, user_request, **kwargs):
                yield msg, files
        else:
            yield f"âŒ æœªçŸ¥æŠ€èƒ½ç±»å‹: {skill_info.get('skill_type')}", None

    async def execute_legacy_skill(
        self,
        skill_name: str,
        user_request: str,
        **kwargs
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]]], None]:
        """
        æ‰§è¡Œæ—§ç‰ˆ .py Skill (ç›´æ¥åœ¨è¿›ç¨‹å†…è¿è¡Œ)
        Legacy .py skills å¿…é¡»åŒ…å« `execute(update, context, params)` å‡½æ•°
        """
        try:
            # 1. åŠ è½½æ¨¡å—
            module = skill_loader.load_legacy_skill(skill_name)
            if not module:
                yield f"âŒ æ— æ³•åŠ è½½æ—§ç‰ˆæŠ€èƒ½: {skill_name}", None
                return

            # 2. å‡†å¤‡å‚æ•°
            # æ—§ç‰ˆ skill é€šå¸¸æœŸæœ› execute(update, context, params)
            update = kwargs.get("update")
            context = kwargs.get("context")
            
            # ä½¿ç”¨ AI è§£æå‚æ•°
            params = kwargs.get("params", {})
            skill_params_schema = skill_loader.get_skill(skill_name).get("params", {})
            
            if not params and skill_params_schema and user_request:
                # Need to extract params from user_request based on schema
                yield f"ğŸ¤” æ­£åœ¨è§£æå‚æ•°...", None
                try:
                    from google.genai import types
                    # Construct simple extraction prompt
                    prompt = (
                        f"Extract parameters for function '{skill_name}' from the instruction.\n"
                        f"Instruction: {user_request}\n"
                        f"Parameters Schema: {skill_params_schema}\n"
                        "Return ONLY a JSON object."
                    )
                    
                    response = gemini_client.models.generate_content(
                        model=GEMINI_MODEL,
                        contents=prompt,
                        config={
                            "response_mime_type": "application/json",
                        }
                    )
                    import json
                    import re
                    response_text = response.text.strip() if response.text else ""
                    
                    # Clean markdown code blocks if present
                    if response_text.startswith("```"):
                        response_text = re.sub(r"^```json\s*", "", response_text)
                        response_text = re.sub(r"^```\s*", "", response_text)
                        response_text = re.sub(r"\s*```$", "", response_text)
                        
                    if response_text:
                        params = json.loads(response_text)
                    else:
                        logger.warning("AI returned empty response for param extraction")
                        params = {"instruction": user_request}
                    yield f"âœ… è§£æå‚æ•°: {params}", None
                except Exception as e:
                    logger.error(f"Param extraction failed: {e}")
                    # Fallback: pass the raw instruction as a param
                    params = {"instruction": user_request}
                    yield f"âš ï¸ å‚æ•°è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æŒ‡ä»¤ç»§ç»­æ‰§è¡Œ.", None
            
            yield f"âš™ï¸ æ­£åœ¨æ‰§è¡Œ {skill_name}...", None
            
            # 3. æ‰§è¡Œ
            if not asyncio.iscoroutinefunction(module.execute):
                # åŒæ­¥å‡½æ•°
                result = module.execute(update, context, params)
            else:
                # å¼‚æ­¥å‡½æ•°
                result = await module.execute(update, context, params)
            
            # 4. è¿”å›ç»“æœ
            # æ—§ç‰ˆ execute é€šå¸¸è¿”å›å­—ç¬¦ä¸² result
            if isinstance(result, str):
                yield result, None
            else:
                yield f"âœ… æ‰§è¡Œå®Œæˆ: {str(result)}", None
                
        except Exception as e:
            logger.error(f"Error executing legacy skill {skill_name}: {e}", exc_info=True)
            yield f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}", None
            
            # --- Self-Healing (Reactive Repair) ---
            try:
                update_obj = kwargs.get("update")
                if update_obj and update_obj.effective_user:
                    yield f"ğŸ”§ ç›‘æµ‹åˆ°å¼‚å¸¸ï¼Œæ­£åœ¨å°è¯•ç”Ÿæˆä¿®å¤è¡¥ä¸...", None
                    
                    from services.skill_creator import update_skill
                    user_id = update_obj.effective_user.id
                    
                    repair_req = f"Fix execution error: {str(e)}\nOriginal Request: {user_request}"
                    
                    result = await update_skill(skill_name, repair_req, user_id)
                    
                    if result["success"]:
                        yield (
                            f"âœ… å·²è‡ªåŠ¨ç”Ÿæˆä¿®å¤æ–¹æ¡ˆï¼\n\n"
                            f"è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤æ‰¹å‡†ä¿®æ”¹ç”Ÿæ•ˆï¼š\n"
                            f"`approve_skill {skill_name}`"
                        ), None
                    else:
                         yield f"âš ï¸ è‡ªåŠ¨ä¿®å¤å°è¯•å¤±è´¥: {result.get('error')}", None
            except Exception as he:
                logger.error(f"Self-healing failed: {he}")


# å…¨å±€å•ä¾‹
skill_executor = SkillExecutor()
