"""
Skill æ‰§è¡Œå™¨ - åè°ƒ AI ç†è§£å’Œæ‰§è¡Œæ ‡å‡† Skill
"""
import logging
from typing import Optional, Dict, Any, Tuple, AsyncGenerator

from core.config import gemini_client, GEMINI_MODEL
from core.skill_loader import skill_loader
from services.sandbox_executor import sandbox_executor

logger = logging.getLogger(__name__)

# æ ‡å‡† Skill æ‰§è¡Œçš„ç³»ç»Ÿæç¤º
SKILL_EXECUTION_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åŠ©æ‰‹ã€‚ä½ æ­£åœ¨æ‰§è¡Œä¸€ä¸ªç‰¹å®šçš„æŠ€èƒ½ä»»åŠ¡ã€‚

## ä½ æ‹¥æœ‰çš„èƒ½åŠ› (æ¥è‡ª Skill æ–‡æ¡£)

{skill_content}

## å¯ç”¨çš„è¾…åŠ©è„šæœ¬

{scripts_list}

## ä»»åŠ¡

æ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ï¼Œä½¿ç”¨ä¸Šè¿°æ–‡æ¡£ä¸­çš„çŸ¥è¯†æ¥å®Œæˆä»»åŠ¡ã€‚

å¦‚æœéœ€è¦æ‰§è¡Œä»£ç ï¼Œè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```python
# ä½ çš„ Python ä»£ç 
```

## æ²™ç®±é™åˆ¶ (é‡è¦!)

ä»£ç å°†åœ¨å®‰å…¨æ²™ç®±ä¸­æ‰§è¡Œï¼Œä»¥ä¸‹æ˜¯é™åˆ¶ï¼š

1. **ç¦æ­¢ä½¿ç”¨**: subprocess, os.system, eval, exec, socket, urllib
2. **ç½‘ç»œè¯·æ±‚**: å¿…é¡»ä½¿ç”¨ `httpx` åº“ (å·²å®‰è£…)ï¼Œä¸èƒ½ç”¨ curl æˆ– subprocess
3. **æ–‡ä»¶æ“ä½œ**: åªèƒ½åœ¨å½“å‰ç›®å½•è¯»å†™æ–‡ä»¶

å¦‚æœæ–‡æ¡£ä¸­ä½¿ç”¨äº† curl æˆ– shell å‘½ä»¤ç¤ºä¾‹ï¼Œè¯·å°†å…¶è½¬æ¢ä¸ºç­‰æ•ˆçš„ Python/httpx ä»£ç ã€‚

## ç½‘ç»œå¯é æ€§æç¤º

- **wttr.in å¯èƒ½æœ‰ SSL é—®é¢˜**ï¼Œä¼˜å…ˆä½¿ç”¨ **open-meteo.com** API
- å¯¹äºå¤©æ°”æŸ¥è¯¢ï¼Œæ¨èä½¿ç”¨: `https://api.open-meteo.com/v1/forecast?latitude=LAT&longitude=LON&current_weather=true`
- éœ€è¦å…ˆé€šè¿‡åœ°åè·å–ç»çº¬åº¦ï¼Œå¯ä»¥ç”¨: `https://geocoding-api.open-meteo.com/v1/search?name=åŸå¸‚å&count=1`
- æ‰€æœ‰è¯·æ±‚åŠ ä¸Š `timeout=30`

ç¤ºä¾‹ (å¤©æ°”æŸ¥è¯¢):
```python
import httpx

# 1. è·å–åŸå¸‚åæ ‡
geo = httpx.get("https://geocoding-api.open-meteo.com/v1/search?name=Quzhou&count=1", timeout=30).json()
lat, lon = geo["results"][0]["latitude"], geo["results"][0]["longitude"]

# 2. è·å–å¤©æ°”
weather = httpx.get(f"https://api.open-meteo.com/v1/forecast?latitude={{lat}}&longitude={{lon}}&current_weather=true", timeout=30).json()
print(f"æ¸©åº¦: {{weather['current_weather']['temperature']}}Â°C")
```

## ç”¨æˆ·è¯·æ±‚

{user_request}

## é™„åŠ ä¸Šä¸‹æ–‡

{extra_context}
"""


class SkillExecutor:
    """
    æ ‡å‡† Skill æ‰§è¡Œå™¨
    
    å·¥ä½œæµç¨‹ï¼š
    1. åŠ è½½ SKILL.md å†…å®¹
    2. å°†å†…å®¹æ³¨å…¥åˆ° AI ä¸Šä¸‹æ–‡
    3. AI ç†è§£ä»»åŠ¡å¹¶ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼ˆå¯èƒ½åŒ…å«ä»£ç ï¼‰
    4. å¦‚æœæœ‰ä»£ç ï¼Œåœ¨æ²™ç®±ä¸­æ‰§è¡Œ
    5. è¿”å›ç»“æœ
    """
    
    async def execute_standard_skill(
        self,
        skill_name: str,
        user_request: str,
        extra_context: str = "",
        input_files: Dict[str, bytes] = None,
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]]], None]:
        """
        æ‰§è¡Œæ ‡å‡† Skill
        
        Yields:
            (status_message, output_files)
        """
        # 1. è·å– Skill ä¿¡æ¯
        skill_info = skill_loader.get_skill(skill_name)
        if not skill_info:
            yield f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½: {skill_name}", None
            return
        
        if skill_info.get("skill_type") != "standard":
            yield f"âŒ {skill_name} ä¸æ˜¯æ ‡å‡†åè®®æŠ€èƒ½", None
            return
        
        skill_content = skill_info.get("skill_md_content", "")
        skill_dir = skill_info.get("skill_dir", "")
        scripts = skill_info.get("scripts", [])
        
        yield f"ğŸ“š æ­£åœ¨ä½¿ç”¨æŠ€èƒ½ **{skill_name}** å¤„ç†æ‚¨çš„è¯·æ±‚...", None
        
        # 2. æ„å»ºæç¤º
        scripts_list = "\n".join([f"- {s}" for s in scripts]) if scripts else "æ— "
        
        prompt = SKILL_EXECUTION_PROMPT.format(
            skill_content=skill_content[:8000],  # æˆªæ–­è¿‡é•¿å†…å®¹
            scripts_list=scripts_list,
            user_request=user_request,
            extra_context=extra_context or "æ— ",
        )
        
        # 3. è°ƒç”¨ AI ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
        yield "ğŸ¤” æ­£åœ¨åˆ†æä»»åŠ¡...", None
        
        try:
            response = gemini_client.models.generate_content(
                model=GEMINI_MODEL,
                contents=prompt,
                config={
                    "system_instruction": "ä½ æ˜¯ä¸€ä¸ªä»£ç æ‰§è¡ŒåŠ©æ‰‹ã€‚æ ¹æ®æŠ€èƒ½æ–‡æ¡£å®Œæˆç”¨æˆ·ä»»åŠ¡ã€‚å¦‚æœéœ€è¦ç”Ÿæˆæ–‡ä»¶ï¼ŒåŠ¡å¿…ä½¿ç”¨ä»£ç å®ç°ã€‚è¯·æ³¨æ„ï¼šä½ è¿”å›çš„æ‰€æœ‰éä»£ç æ–‡æœ¬å†…å®¹å°†ç›´æ¥ä½œä¸º Telegram Bot çš„å›å¤å‘é€ç»™ç”¨æˆ·ï¼Œè¯·ä¿æŒè¯­æ°”å‹å¥½ã€ç®€æ´ï¼Œå¹¶ä½¿ç”¨ Markdown æ ¼å¼ã€‚",
                },
            )
            
            if not response.text:
                yield "âŒ AI æ— æ³•ç”Ÿæˆè§£å†³æ–¹æ¡ˆ", None
                return
            
            ai_response = response.text
            
        except Exception as e:
            logger.error(f"AI generation error: {e}")
            yield f"âŒ AI æœåŠ¡é”™è¯¯: {e}", None
            return
        
        # 4. æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç å—
        import re
        code_blocks = re.findall(r"```python\n(.*?)```", ai_response, re.DOTALL)
        
        if code_blocks:
            yield "âš™ï¸ æ­£åœ¨æ‰§è¡Œä»£ç ...", None
            
            # æ‰§è¡Œæ‰€æœ‰ä»£ç å—
            all_output_files = {}
            execution_output = ""
            
            for i, code in enumerate(code_blocks):
                success, output, output_files = await sandbox_executor.execute_code(
                    code=code,
                    input_files=input_files,
                    skill_dir=skill_dir,
                )
                
                execution_output += f"\n[ä»£ç å— {i+1}]\n{output}\n"
                all_output_files.update(output_files)
                
                if not success:
                    yield f"âš ï¸ ä»£ç æ‰§è¡Œå‡ºç°é—®é¢˜:\n```\n{output}\n```", None
            
            # 5. è¿”å›ç»“æœ
            if all_output_files:
                yield f"âœ… æ‰§è¡Œå®Œæˆï¼ç”Ÿæˆäº† {len(all_output_files)} ä¸ªæ–‡ä»¶ã€‚", all_output_files
            else:
                # æ²¡æœ‰ç”Ÿæˆæ–‡ä»¶ï¼Œè¿”å› AI çš„æ–‡å­—å›å¤
                # ç§»é™¤ä»£ç å—ï¼Œåªä¿ç•™è§£é‡Šæ–‡å­—
                clean_response = re.sub(r"```python\n.*?```", "[å·²æ‰§è¡Œ]", ai_response, flags=re.DOTALL)
                yield clean_response, None
                
                if execution_output.strip():
                    yield f"\nğŸ“‹ æ‰§è¡Œè¾“å‡º:\n```\n{execution_output.strip()}\n```", None
        else:
            # æ²¡æœ‰ä»£ç ï¼Œç›´æ¥è¿”å› AI å›å¤
            yield ai_response, None
    
    async def execute_skill(
        self,
        skill_name: str,
        user_request: str,
        **kwargs
    ) -> AsyncGenerator[Tuple[str, Optional[Dict[str, bytes]]], None]:
        """
        ç»Ÿä¸€æ‰§è¡Œå…¥å£ - è‡ªåŠ¨åˆ¤æ–­ Skill ç±»å‹
        """
        skill_info = skill_loader.get_skill(skill_name)
        
        if not skill_info:
            yield f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½: {skill_name}", None
            return
        
        if skill_info.get("skill_type") == "standard":
            async for msg, files in self.execute_standard_skill(skill_name, user_request, **kwargs):
                yield msg, files
        else:
            # æ—§ç‰ˆ skill ä¸åœ¨è¿™é‡Œå¤„ç†ï¼Œåº”è¯¥åœ¨ handler å±‚ç›´æ¥è°ƒç”¨ module.execute()
            yield f"âš ï¸ {skill_name} æ˜¯æ—§ç‰ˆæŠ€èƒ½ï¼Œéœ€è¦ä½¿ç”¨ legacy executor", None


# å…¨å±€å•ä¾‹
skill_executor = SkillExecutor()
