"""
è¯­éŸ³æ¶ˆæ¯å¤„ç†æ¨¡å— - æ™ºèƒ½è·¯ç”±ç‰ˆ

çŸ­è¯­éŸ³ï¼ˆâ‰¤60sï¼‰: è½¬æ–‡å­—åèµ°æ™ºèƒ½è·¯ç”±ï¼ˆä¸æ–‡æœ¬æ¶ˆæ¯ä¸€è‡´ï¼‰
é•¿è¯­éŸ³ï¼ˆ>60sï¼‰: ç›´æ¥è½¬å†™è¾“å‡º
"""

import logging
import base64
import re
from telegram.error import BadRequest

from core.config import gemini_client, GEMINI_MODEL, is_user_allowed
from core.platform.exceptions import MediaProcessingError
from user_context import add_message, get_user_context
from core.platform.models import MessageType, UnifiedContext
from .media_utils import extract_media_input

logger = logging.getLogger(__name__)

# è¯­éŸ³æ—¶é•¿é˜ˆå€¼ï¼ˆç§’ï¼‰
SHORT_VOICE_THRESHOLD = 60


def _normalize_transcribed_text(raw_text: str) -> str:
    text = str(raw_text or "").strip()
    if not text:
        return ""

    # Remove common wrapper labels.
    for prefix in ("è½¬å†™ï¼š", "è½¬å†™ç»“æœï¼š", "è¯†åˆ«ç»“æœï¼š", "æ–‡æœ¬ï¼š"):
        if text.startswith(prefix):
            text = text[len(prefix) :].strip()

    # Strip symmetrical quote wrappers repeatedly.
    pairs = (
        ('"', '"'),
        ("'", "'"),
        ("`", "`"),
        ("â€œ", "â€"),
        ("â€˜", "â€™"),
    )
    changed = True
    while changed and len(text) >= 2:
        changed = False
        for left, right in pairs:
            if text.startswith(left) and text.endswith(right):
                text = text[len(left) : len(text) - len(right)].strip()
                changed = True
                break

    # Quote/punctuation only output means model produced no usable transcript.
    if re.fullmatch(r'[\s"`\'â€œâ€â€˜â€™.,ï¼Œã€‚!?ï¼ï¼Ÿ:ï¼š;ï¼›\-\(\)\[\]\{\}â€¦]+', text or ""):
        return ""
    return text


def _extract_model_text(response) -> str:
    if response is None:
        return ""

    try:
        direct_text = getattr(response, "text", None)
    except Exception:
        direct_text = None
    if direct_text is not None:
        text = str(direct_text).strip()
        if text:
            return text

    candidates = getattr(response, "candidates", None) or []
    for candidate in candidates:
        content = getattr(candidate, "content", None)
        parts = getattr(content, "parts", None) or []
        chunks = []
        for part in parts:
            part_text = getattr(part, "text", None)
            if part_text:
                chunks.append(str(part_text))
        merged = "\n".join(chunks).strip()
        if merged:
            return merged
    return ""


def _audio_mime_candidates(mime_type: str) -> list[str]:
    raw = str(mime_type or "").strip()
    base = raw.split(";", 1)[0].strip().lower() if raw else ""
    candidates: list[str] = []

    def add(item: str) -> None:
        value = str(item or "").strip()
        if value and value not in candidates:
            candidates.append(value)

    add(raw)
    add(base)

    if base in {"audio/ogg", "audio/opus", "audio/x-opus", "application/ogg"}:
        add("audio/ogg")
        add("audio/ogg; codecs=opus")
        add("audio/opus")
    if base in {"audio/mp3", "audio/mpeg"}:
        add("audio/mpeg")
        add("audio/mp3")

    add("audio/ogg")
    add("audio/ogg; codecs=opus")
    add("audio/webm")
    add("audio/mpeg")
    add("audio/mp4")
    add("audio/wav")
    return candidates


def _build_audio_contents(
    prompt: str, voice_bytes: bytes, mime_type: str
) -> list[dict]:
    return [
        {
            "role": "user",
            "parts": [
                {"text": prompt},
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64.b64encode(bytes(voice_bytes)).decode("utf-8"),
                    }
                },
            ],
        }
    ]


async def _run_audio_prompt(prompt: str, voice_bytes: bytes, mime_type: str) -> str:
    last_error: Exception | None = None
    for candidate_mime in _audio_mime_candidates(mime_type):
        try:
            response = await gemini_client.aio.models.generate_content(
                model=GEMINI_MODEL,
                contents=_build_audio_contents(prompt, voice_bytes, candidate_mime),
            )
        except Exception as exc:
            last_error = exc
            logger.warning(
                "Voice model call failed with mime=%s err=%s",
                candidate_mime,
                exc,
            )
            continue

        text = _extract_model_text(response)
        if text:
            return text

    if last_error is not None:
        logger.error("Voice model call failed after mime retries: %s", last_error)
    return ""


async def transcribe_voice(voice_bytes: bytes, mime_type: str) -> str | None:
    """
    ä½¿ç”¨ Gemini è½¬å†™è¯­éŸ³ä¸ºæ–‡å­—

    Returns:
        è½¬å†™åçš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
    """
    if not voice_bytes:
        logger.warning("Voice transcription skipped: empty audio payload.")
        return None

    try:
        prompt = (
            "è¯·å°†è¿™æ®µè¯­éŸ³è½¬å†™ä¸ºæ–‡å­—ã€‚"
            "åªè¾“å‡ºè¯­éŸ³ä¸­è¯´çš„åŸè¯ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å›å¤ã€‚"
            "å¦‚æœæ— æ³•è¯†åˆ«ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"
        )
        text = _normalize_transcribed_text(
            await _run_audio_prompt(prompt, voice_bytes, mime_type)
        )
        if text:
            return text

        # Retry once with a stricter instruction to avoid placeholder outputs like """".
        strict_prompt = (
            "è¯·å°†è¿™æ®µè¯­éŸ³å‡†ç¡®è½¬å†™ä¸ºæ–‡å­—ã€‚"
            "åªè¾“å‡ºåŸè¯ï¼Œä¸è¦è¾“å‡ºå¼•å·ã€å ä½ç¬¦æˆ–è§£é‡Šã€‚"
            "å¦‚æœå¬ä¸æ¸…ï¼Œå¿…é¡»è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚"
        )
        retry_text = _normalize_transcribed_text(
            await _run_audio_prompt(strict_prompt, voice_bytes, mime_type)
        )
        if retry_text:
            return retry_text
        return None
    except Exception as e:
        logger.error(f"Voice transcription error: {e}")
        return None


async def transcribe_and_translate_voice(
    voice_bytes: bytes, mime_type: str
) -> dict | None:
    """
    è½¬å†™è¯­éŸ³å¹¶ç¿»è¯‘ä¸ºåŒè¯­å¯¹ç…§

    Returns:
        {"original": "åŸæ–‡", "original_lang": "è¯­è¨€", "translated": "è¯‘æ–‡"} æˆ– None
    """
    if not voice_bytes:
        logger.warning("Voice translation skipped: empty audio payload.")
        return None

    try:
        prompt = (
            "è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n"
            "1. å°†è¯­éŸ³è½¬å†™ä¸ºæ–‡å­—\n"
            "2. è¯†åˆ«è¯­éŸ³çš„è¯­è¨€\n"
            "3. å¦‚æœæ˜¯ä¸­æ–‡ï¼Œç¿»è¯‘ä¸ºè‹±æ–‡ï¼›å¦‚æœæ˜¯å…¶ä»–è¯­è¨€ï¼Œç¿»è¯‘ä¸ºä¸­æ–‡\n\n"
            "è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä¸è¦æ·»åŠ å…¶ä»–å†…å®¹ï¼‰ï¼š\n"
            "åŸæ–‡è¯­è¨€ï¼š[è¯­è¨€åç§°]\n"
            "åŸæ–‡ï¼š[è½¬å†™çš„åŸæ–‡]\n"
            "è¯‘æ–‡ï¼š[ç¿»è¯‘åçš„æ–‡å­—]"
        )

        text = await _run_audio_prompt(prompt, voice_bytes, mime_type)
        if not text:
            return None

        # è§£æç»“æœ
        text = text.strip()
        result = {}

        for line in text.split("\n"):
            if line.startswith("åŸæ–‡è¯­è¨€ï¼š"):
                result["original_lang"] = line.replace("åŸæ–‡è¯­è¨€ï¼š", "").strip()
            elif line.startswith("åŸæ–‡ï¼š"):
                result["original"] = line.replace("åŸæ–‡ï¼š", "").strip()
            elif line.startswith("è¯‘æ–‡ï¼š"):
                result["translated"] = line.replace("è¯‘æ–‡ï¼š", "").strip()

        if result.get("original") and result.get("translated"):
            return result
        return None

    except Exception as e:
        logger.error(f"Voice translation error: {e}")
        return None


async def handle_voice_message(ctx: UnifiedContext) -> None:
    """
    å¤„ç†è¯­éŸ³æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ voice å’Œ audio ç±»å‹ï¼‰

    ç¿»è¯‘æ¨¡å¼å¼€å¯: è½¬å†™ + ç¿»è¯‘ â†’ åŒè¯­å¯¹ç…§è¾“å‡º
    æ­£å¸¸æ¨¡å¼:
        çŸ­è¯­éŸ³: è½¬æ–‡å­— â†’ æ™ºèƒ½è·¯ç”±
        é•¿è¯­éŸ³: ç›´æ¥è½¬å†™è¾“å‡º
    """
    from core.state_store import get_user_settings

    user_id = ctx.message.user.id

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    if not await is_user_allowed(user_id):
        await ctx.reply("â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚")
        return

    try:
        media = await extract_media_input(
            ctx,
            expected_types={MessageType.VOICE, MessageType.AUDIO},
            auto_download=True,
        )
    except MediaProcessingError as exc:
        if exc.error_code == "unsupported_media_on_platform":
            await ctx.reply("âŒ å½“å‰å¹³å°æš‚ä¸æ”¯æŒè¯¥è¯­éŸ³/éŸ³é¢‘æ ¼å¼ã€‚")
        else:
            await ctx.reply("âŒ å½“å‰å¹³å°æš‚æ—¶æ— æ³•ä¸‹è½½è¯­éŸ³/éŸ³é¢‘å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
        return

    mime_type = media.mime_type or "audio/ogg"
    duration = int(media.meta.get("duration") or (SHORT_VOICE_THRESHOLD + 1))
    user_instruction = (
        media.caption.strip()
        if media.caption
        else (ctx.message.text or "").strip() or None
    )

    # æ£€æŸ¥æ˜¯å¦å¼€å¯ç¿»è¯‘æ¨¡å¼
    settings = await get_user_settings(user_id)
    translate_mode = settings.get("auto_translate", 0)

    # å‘é€å¤„ç†ä¸­æç¤º
    if translate_mode:
        thinking_msg = await ctx.reply("ğŸŒ æ­£åœ¨ç¿»è¯‘è¯­éŸ³å†…å®¹...")
    else:
        thinking_msg = await ctx.reply("ğŸ¤ æ­£åœ¨è¯†åˆ«è¯­éŸ³å†…å®¹...")

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    try:
        logger.info("Voice payload loaded: mime=%s duration=%s", mime_type, duration)
        voice_bytes = media.content or b""
        if not voice_bytes:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "âŒ æœªèƒ½è¯»å–è¯­éŸ³æ•°æ®ï¼Œè¯·é‡è¯•ã€‚")
            return

        # ç¿»è¯‘æ¨¡å¼ï¼šåŒè¯­å¯¹ç…§è¾“å‡º
        if translate_mode:
            result = await transcribe_and_translate_voice(voice_bytes, mime_type)

            if not result:
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                await ctx.edit_message(msg_id, "âŒ æ— æ³•è¯†åˆ«æˆ–ç¿»è¯‘è¯­éŸ³å†…å®¹ï¼Œè¯·é‡è¯•ã€‚")
                return

            original_lang = result.get("original_lang", "æœªçŸ¥")
            original = result.get("original", "")
            translated = result.get("translated", "")

            output = (
                f"ğŸ¤ **è¯­éŸ³ç¿»è¯‘**\n\n"
                f"ğŸ“ **åŸæ–‡** ({original_lang}):\n"
                f"ã€Œ{original}ã€\n\n"
                f"ğŸŒ **è¯‘æ–‡**:\n"
                f"ã€Œ{translated}ã€"
            )

            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, output)

            # è®°å½•ç»Ÿè®¡
            from stats import increment_stat

            await increment_stat(user_id, "translations_count")
            return

        # æ­£å¸¸æ¨¡å¼ï¼šè½¬å†™è¯­éŸ³
        transcribed_text = await transcribe_voice(voice_bytes, mime_type)

        if not transcribed_text:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id, "âŒ æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹ï¼Œè¯·é‡è¯•æˆ–å‘é€æ–‡å­—æ¶ˆæ¯ã€‚"
            )
            return

        logger.info(f"Voice transcribed: {transcribed_text[:50]}...")

        # å¦‚æœç”¨æˆ·é™„å¸¦äº†æ–‡å­—è¯´æ˜ï¼ˆCaptionï¼‰ï¼Œå°†å…¶ä½œä¸ºæŒ‡ä»¤è¿½åŠ åˆ°å†…å®¹å‰
        final_text = transcribed_text
        if user_instruction:
            final_text = f"{user_instruction}\n\nã€è¯­éŸ³å†…å®¹ã€‘ï¼š\n{transcribed_text}"
            # æœ‰æŒ‡ä»¤æ—¶ï¼Œè§†ä¸ºçŸ­è¯­éŸ³é€»è¾‘å¤„ç†ï¼ˆèµ°æ™ºèƒ½è·¯ç”±ï¼‰
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id, f'ğŸ¤ å·²è¯†åˆ«è¯­éŸ³å†…å®¹ï¼Œæ­£åœ¨æ‰§è¡ŒæŒ‡ä»¤: **"{user_instruction}"**...'
            )
            await process_as_text_message(ctx, final_text, thinking_msg)
            return

        # æ ¹æ®è¯­éŸ³æ—¶é•¿å†³å®šå¤„ç†ç­–ç•¥ï¼ˆè‹¥æ—  duration å±æ€§åˆ™é»˜è®¤ä¸ºé•¿è¯­éŸ³ï¼‰
        # duration variable is already set above
        if duration <= SHORT_VOICE_THRESHOLD:
            # çŸ­è¯­éŸ³ï¼šèµ°æ™ºèƒ½è·¯ç”±ï¼ˆä¸æ–‡æœ¬æ¶ˆæ¯ä¸€è‡´ï¼‰
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id,
                f'ğŸ¤ è¯­éŸ³è½¬å†™å†…å®¹ä¸º: **"{transcribed_text}"**\n\nğŸ¤” æ­£åœ¨æ€è€ƒä¸­...',
            )

            # è°ƒç”¨æ–‡æœ¬æ¶ˆæ¯å¤„ç†é€»è¾‘
            await process_as_text_message(ctx, transcribed_text, thinking_msg)
        else:
            # é•¿è¯­éŸ³ï¼šç›´æ¥è¾“å‡ºè½¬å†™ç»“æœ
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id, f"ğŸ¤ **è¯­éŸ³è½¬å†™ç»“æœï¼š**\n\n{transcribed_text}"
            )

            # è®°å½•åˆ°ä¸Šä¸‹æ–‡
            await add_message(
                ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€æ®µé•¿è¯­éŸ³ã€‘{transcribed_text}"
            )

            # è®°å½•ç»Ÿè®¡
            from stats import increment_stat

            await increment_stat(user_id, "voice_chats")

    except BadRequest as e:
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        if "File is too big" in str(e):
            await ctx.edit_message(
                msg_id,
                "âš ï¸ **éŸ³é¢‘æ–‡ä»¶è¿‡å¤§**\n\n"
                "æŠ±æ­‰ï¼ŒTelegram é™åˆ¶ Bot åªèƒ½ä¸‹è½½ **20MB** ä»¥å†…çš„æ–‡ä»¶ï¼Œæˆ‘æ— æ³•è·å–è¿™æ®µéŸ³é¢‘ã€‚\n\n"
                "ğŸ’¡ **å»ºè®®æ–¹æ¡ˆ**ï¼š\n"
                "1. ä½¿ç”¨éŸ³é¢‘å‹ç¼©è½¯ä»¶å‡å°ä½“ç§¯åé‡å‘\n"
                "2. è¿™æ˜¯ä¸€ä¸ª Telegram å®˜æ–¹é™åˆ¶ï¼Œæ— æ³•åœ¨æœåŠ¡ç«¯åˆ‡å‰²ï¼ˆå› ä¸ºæ ¹æœ¬ä¸‹è½½ä¸åˆ°ï¼‰",
            )
        else:
            logger.error(f"Voice processing BadRequest: {e}")
            await ctx.edit_message(msg_id, "âŒ å¤„ç†å¤±è´¥ï¼šæ–‡ä»¶æ ¼å¼æˆ–å†…å®¹å—é™ã€‚")

    except Exception as e:
        logger.error(f"Voice processing error: {e}")
        try:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id,
                "âŒ è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n"
                "å¯èƒ½çš„åŸå› ï¼š\n"
                "â€¢ è¯­éŸ³æ ¼å¼ä¸æ”¯æŒ\n"
                "â€¢ è¯­éŸ³å†…å®¹æ— æ³•è¯†åˆ«\n"
                "â€¢ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
            )
        except BadRequest:
            pass


async def process_as_text_message(ctx: UnifiedContext, text: str, thinking_msg) -> None:
    """
    å°†è½¬å†™åçš„æ–‡æœ¬æŒ‰æ™®é€šæ–‡æœ¬æ¶ˆæ¯é€»è¾‘å¤„ç†ï¼ˆä»£ç†ç»™ Agent Orchestratorï¼‰
    """
    import time
    from core.agent_orchestrator import agent_orchestrator
    from stats import increment_stat

    # Legacy fallbacks
    update = ctx.platform_event

    user_id = ctx.message.user.id

    # è®°å½•ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    await add_message(ctx, user_id, "user", text)

    # æ„å»ºä¸Šä¸‹æ–‡
    context_messages = await get_user_context(ctx, user_id)
    context_messages.append({"role": "user", "parts": [{"text": text}]})

    msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))

    # ä»£ç†ç»™ Agent Orchestrator
    try:
        final_text_response = ""
        last_update_time = 0

        async for chunk_text in agent_orchestrator.handle_message(
            ctx, context_messages
        ):
            final_text_response += chunk_text

            now = time.time()
            if now - last_update_time > 0.8:
                await ctx.edit_message(msg_id, final_text_response)
                last_update_time = now

        # å‘é€æœ€ç»ˆå›å¤
        if final_text_response:
            await ctx.edit_message(msg_id, final_text_response)
            await add_message(ctx, user_id, "model", final_text_response)
            await increment_stat(user_id, "voice_chats")
        else:
            await ctx.edit_message(msg_id, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚")

    except Exception as e:
        logger.error(f"Voice Agent error: {e}")
        await ctx.edit_message(msg_id, f"âŒ Agent è¿è¡Œå‡ºé”™ï¼š{e}")
