"""
åŠŸèƒ½éœ€æ±‚æ”¶é›† handlers
"""

import os
import re
import logging
import datetime
from core.platform.models import UnifiedContext
from .base_handlers import check_permission_unified, CONVERSATION_END
from core.config import (
    WAITING_FOR_FEATURE_INPUT,
)

logger = logging.getLogger(__name__)

FEATURE_STATE_KEY = "feature_request"


async def feature_command(ctx: UnifiedContext) -> int:
    """å¤„ç† /feature å‘½ä»¤ï¼Œæ”¶é›†åŠŸèƒ½éœ€æ±‚"""
    if not await check_permission_unified(ctx):
        return CONVERSATION_END

    if not ctx.platform_ctx:
        return CONVERSATION_END

    ctx.user_data.pop(FEATURE_STATE_KEY, None)

    args = ctx.platform_ctx.args
    if args:
        return await process_feature_request(ctx, " ".join(args))

    await ctx.reply(
        "ğŸ’¡ **æäº¤åŠŸèƒ½éœ€æ±‚**\n\nè¯·æè¿°æ‚¨å¸Œæœ› Bot æ‹¥æœ‰çš„æ–°åŠŸèƒ½ã€‚\n\nå‘é€ /cancel å–æ¶ˆã€‚"
    )
    return WAITING_FOR_FEATURE_INPUT


async def handle_feature_input(ctx: UnifiedContext) -> int:
    """å¤„ç†éœ€æ±‚çš„äº¤äº’å¼è¾“å…¥ï¼ˆæ”¯æŒå¤šè½®è¡¥å……ï¼‰"""
    text = ctx.message.text
    if not text:
        await ctx.reply("è¯·å‘é€æœ‰æ•ˆæ–‡æœ¬ã€‚")
        return WAITING_FOR_FEATURE_INPUT

    if not ctx.platform_ctx:
        return CONVERSATION_END

    state = ctx.user_data.get(FEATURE_STATE_KEY)
    if state and state.get("filepath"):
        return await append_feature_supplement(ctx, text)
    else:
        return await process_feature_request(ctx, text)


async def save_feature_command(ctx: UnifiedContext) -> int:
    """ä¿å­˜éœ€æ±‚å¹¶ç»“æŸå¯¹è¯"""
    if not ctx.platform_ctx:
        return CONVERSATION_END

    state = ctx.user_data.pop(FEATURE_STATE_KEY, None)

    if state and state.get("filename"):
        await ctx.reply(f"âœ… éœ€æ±‚ `{state['filename']}` å·²ä¿å­˜ï¼")
    else:
        await ctx.reply("âœ… éœ€æ±‚æ”¶é›†å·²ç»“æŸã€‚")

    return CONVERSATION_END


async def process_feature_request(ctx: UnifiedContext, description: str) -> int:
    """æ•´ç†ç”¨æˆ·éœ€æ±‚å¹¶ä¿å­˜"""
    from core.config import (
        openai_async_client,
        GEMINI_MODEL,
        DATA_DIR,
    )  # lazy import to avoid top level issues if moved
    from services.openai_adapter import generate_text

    msg = await ctx.reply("ğŸ¤” æ­£åœ¨æ•´ç†æ‚¨çš„éœ€æ±‚...")

    prompt = f"""ç”¨æˆ·æå‡ºäº†ä¸€ä¸ªåŠŸèƒ½éœ€æ±‚ï¼Œè¯·æ•´ç†æˆç®€æ´çš„éœ€æ±‚æè¿°ã€‚

ç”¨æˆ·åŸè¯ï¼š{description}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆMarkdownï¼‰ï¼Œä¿æŒç®€æ´ï¼š

# [2-6ä¸ªå­—çš„æ ‡é¢˜]

## éœ€æ±‚æè¿°
1-2 å¥è¯æè¿°ç”¨æˆ·æƒ³è¦ä»€ä¹ˆ

## åŠŸèƒ½è¦ç‚¹
- è¦ç‚¹1
- è¦ç‚¹2ï¼ˆå¦‚æœ‰ï¼‰
"""

    try:
        if openai_async_client is None:
            raise RuntimeError("OpenAI async client is not initialized")
        doc_content = await generate_text(
            async_client=openai_async_client,
            model=GEMINI_MODEL,
            contents=prompt,
        )
        doc_content = str(doc_content or "").strip()

        title_match = re.search(r"^#\s*(.+)$", doc_content, re.MULTILINE)
        title = title_match.group(1).strip()[:15] if title_match else "éœ€æ±‚"
        title_safe = re.sub(r'[\\/*?:"<>|]', "", title).replace(" ", "_")

        timestamp = datetime.datetime.now()
        meta = f"\n\n---\n*æäº¤æ—¶é—´ï¼š{timestamp.strftime('%Y-%m-%d %H:%M')} | ç”¨æˆ·ï¼š{ctx.message.user.id}*"
        doc_content += meta

        feature_dir = os.path.join(DATA_DIR, "feature_requests")
        os.makedirs(feature_dir, exist_ok=True)

        date_str = timestamp.strftime("%Y%m%d")
        existing = [f for f in os.listdir(feature_dir) if f.startswith(date_str)]
        seq = len(existing) + 1
        filename = f"{date_str}_{seq:02d}_{title_safe}.md"
        filepath = os.path.join(feature_dir, filename)

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(doc_content)

        if ctx.platform_ctx:
            ctx.user_data[FEATURE_STATE_KEY] = {
                "filepath": filepath,
                "filename": filename,
            }

        await ctx.edit_message(
            getattr(msg, "message_id", getattr(msg, "id", None)),
            f"ğŸ“ **éœ€æ±‚å·²è®°å½•**\n\n"
            f"ğŸ“„ `{filename}`\n\n"
            f"{doc_content}\n\n"
            "---\nç»§ç»­è¡¥å……è¯´æ˜ï¼Œæˆ–ç‚¹å‡» /save_feature ä¿å­˜ç»“æŸã€‚",
        )
        return WAITING_FOR_FEATURE_INPUT

    except Exception as e:
        logger.error(f"Feature request error: {e}")
        await ctx.edit_message(
            getattr(msg, "message_id", getattr(msg, "id", None)), f"âŒ å¤„ç†å¤±è´¥ï¼š{e}"
        )
        return CONVERSATION_END


async def append_feature_supplement(ctx: UnifiedContext, supplement: str) -> int:
    """è¿½åŠ ç”¨æˆ·è¡¥å……ä¿¡æ¯åˆ°éœ€æ±‚æ–‡æ¡£"""
    state = ctx.user_data.get(FEATURE_STATE_KEY, {}) if ctx.platform_ctx else {}
    filepath = state.get("filepath")
    filename = state.get("filename")

    if not filepath:
        return CONVERSATION_END

    msg = await ctx.reply("ğŸ“ æ­£åœ¨æ›´æ–°éœ€æ±‚...")

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()

        timestamp = datetime.datetime.now().strftime("%H:%M")
        supplement_section = f"\n\n## è¡¥å……è¯´æ˜ ({timestamp})\n{supplement}"

        if "---\n*æäº¤æ—¶é—´" in content:
            parts = content.rsplit("---\n*æäº¤æ—¶é—´", 1)
            content = (
                parts[0].rstrip() + supplement_section + "\n\n---\n*æäº¤æ—¶é—´" + parts[1]
            )
        else:
            content += supplement_section

        with open(filepath, "w", encoding="utf-8") as f:
            f.write(content)

        await ctx.edit_message(
            getattr(msg, "message_id", getattr(msg, "id", None)),
            f"âœ… **è¡¥å……å·²æ·»åŠ **\n\n"
            f"ğŸ“„ `{filename}`\n\n"
            "ç»§ç»­è¡¥å……è¯´æ˜ï¼Œæˆ–ç‚¹å‡» /save_feature ä¿å­˜ç»“æŸã€‚",
        )
        return WAITING_FOR_FEATURE_INPUT

    except Exception as e:
        logger.error(f"Append feature error: {e}")
        await ctx.edit_message(
            getattr(msg, "message_id", getattr(msg, "id", None)), f"âŒ æ›´æ–°å¤±è´¥ï¼š{e}"
        )
        return CONVERSATION_END
