import time
import asyncio
import logging
import base64
import os
import re
from datetime import datetime
from typing import Any
from core.platform.models import UnifiedContext, MessageType
import random
from core.markdown_memory_store import markdown_memory_store

from core.config import (
    GEMINI_MODEL,
    openai_async_client,
)
from core.platform.exceptions import MediaProcessingError, MessageSendError
from services.openai_adapter import generate_text

from user_context import get_user_context, add_message
from core.state_store import get_user_settings
from stats import increment_stat
from core.prompt_composer import prompt_composer
from .media_utils import extract_media_input
from .message_utils import process_and_send_code_files

logger = logging.getLogger(__name__)

LONG_RESPONSE_FILE_THRESHOLD = 9000


def _env_int(name: str, default: int, minimum: int) -> int:
    try:
        value = int(os.getenv(name, str(default)))
    except Exception:
        value = default
    return max(minimum, value)


def _env_float(name: str, default: float, minimum: float) -> float:
    try:
        value = float(os.getenv(name, str(default)))
    except Exception:
        value = default
    return max(minimum, value)


def _stream_cut_index(text: str, max_chars: int) -> int:
    if not text:
        return 0
    if len(text) <= max_chars:
        return len(text)
    head = text[:max_chars]
    candidates = (
        "\n\n",
        "\n",
        "ã€‚",
        "ï¼",
        "ï¼Ÿ",
        ". ",
        "! ",
        "? ",
        "ï¼›",
        ";",
    )
    best = -1
    for marker in candidates:
        idx = head.rfind(marker)
        if idx > best:
            best = idx + len(marker)
    if best >= int(max_chars * 0.35):
        return best
    return max_chars


def _extract_history_text(item: Any) -> tuple[str, str]:
    role = ""
    parts = []
    if isinstance(item, dict):
        role = str(item.get("role") or "").strip().lower()
        parts = item.get("parts") or []
    else:
        role = str(getattr(item, "role", "") or "").strip().lower()
        parts = getattr(item, "parts", []) or []
    texts: list[str] = []
    for part in parts:
        if isinstance(part, dict):
            text = str(part.get("text") or "").strip()
            if text:
                texts.append(text)
        else:
            text = str(getattr(part, "text", "") or "").strip()
            if text:
                texts.append(text)
    return role, "\n".join(texts).strip()


def _compact_text(text: str, limit: int = 220) -> str:
    raw = " ".join(str(text or "").split())
    if len(raw) <= limit:
        return raw
    return raw[:limit].rstrip() + "..."


def _pop_pending_ui_payload(user_data: dict[str, Any]) -> dict[str, Any] | None:
    if not isinstance(user_data, dict):
        return None
    pending_ui = user_data.pop("pending_ui", None)
    if not pending_ui:
        return None

    if isinstance(pending_ui, dict):
        actions = pending_ui.get("actions")
        return {"actions": actions} if isinstance(actions, list) and actions else None

    if not isinstance(pending_ui, list):
        return None

    merged_actions: list[Any] = []
    for ui_block in pending_ui:
        if not isinstance(ui_block, dict):
            continue
        block_actions = ui_block.get("actions")
        if isinstance(block_actions, list):
            merged_actions.extend(block_actions)

    if not merged_actions:
        return None
    return {"actions": merged_actions}


async def _should_include_memory_summary_for_task(
    user_message: str, dialog_context: str
) -> bool:
    request = str(user_message or "").strip()
    if not request:
        return False
    if len(request) <= 6:
        return True
    joined = f"{request}\n{str(dialog_context or '').strip()}".lower()
    memory_cues = (
        "æˆ‘",
        "æˆ‘çš„",
        "ä½",
        "åŸå¸‚",
        "åœ°å€",
        "åå¥½",
        "ä¹ æƒ¯",
        "å–œæ¬¢",
        "ä¸å–œæ¬¢",
        "ç”Ÿæ—¥",
        "èº«ä»½",
        "timezone",
        "time zone",
        "where i",
        "my ",
        "preference",
        "profile",
        "remember",
        "è®°ä½",
        "è®°å¿†",
    )
    task_cues = (
        "éƒ¨ç½²",
        "deploy",
        "echo ",
        "bash",
        "shell",
        "docker",
        "git ",
        "ä»£ç ",
        "è„šæœ¬",
        "æµ‹è¯•",
        "test ",
    )
    if any(token in joined for token in memory_cues):
        return True
    if any(token in joined for token in task_cues):
        return False
    return len(request) <= 18


def _is_private_memory_session(ctx: UnifiedContext) -> bool:
    try:
        chat_type = str(getattr(getattr(ctx.message, "chat", None), "type", "") or "")
        normalized = chat_type.strip().lower()
        if normalized:
            if normalized in {"private", "group", "supergroup", "channel"}:
                return normalized == "private"
    except Exception:
        pass
    return True


async def _collect_recent_dialog_context(
    ctx: UnifiedContext,
    *,
    user_id: str,
    current_user_message: str,
    max_messages: int = 6,
    max_chars: int = 1200,
) -> str:
    try:
        history = await get_user_context(ctx, user_id)
    except Exception:
        return ""
    if not history:
        return ""

    current_norm = " ".join(str(current_user_message or "").split())
    skipped_current = False
    lines: list[str] = []
    for item in reversed(history):
        role, text = _extract_history_text(item)
        if not text:
            continue
        text_norm = " ".join(text.split())
        if not skipped_current and role == "user" and text_norm == current_norm:
            skipped_current = True
            continue
        role_label = "ç”¨æˆ·" if role == "user" else "åŠ©æ‰‹"
        lines.append(f"- {role_label}: {_compact_text(text)}")
        if len(lines) >= max_messages:
            break

    if not lines:
        return ""
    lines.reverse()
    joined = "\n".join(lines)
    if len(joined) > max_chars:
        joined = joined[-max_chars:]
    return joined.strip()


async def _build_worker_instruction_with_context(
    ctx: UnifiedContext,
    *,
    user_id: str,
    user_message: str,
    worker_has_memory: bool,
) -> tuple[str, dict[str, Any]]:
    private_session = _is_private_memory_session(ctx)
    dialog_context = await _collect_recent_dialog_context(
        ctx,
        user_id=user_id,
        current_user_message=user_message,
    )
    wants_memory_summary = (
        private_session
        and await _should_include_memory_summary_for_task(
            user_message,
            dialog_context,
        )
    )
    memory_snapshot = ""
    if wants_memory_summary and not worker_has_memory:
        memory_snapshot = await _fetch_user_memory_snapshot(user_id)

    # SIMPLIFIED: Core Manager no longer micromanages the prompt.
    # The Worker's identity and tools are defined in its SOUL.MD.
    # We only pass the Request and Context.
    sections: list[str] = [
        f"ã€å½“å‰ç”¨æˆ·è¯·æ±‚ã€‘\n{str(user_message or '').strip()}",
    ]
    if dialog_context:
        sections.append(f"ã€è¿‘æœŸå¯¹è¯ä¸Šä¸‹æ–‡ã€‘\n{dialog_context}")
    if memory_snapshot:
        sections.append(f"ã€ç”¨æˆ·è®°å¿†æ‘˜è¦ï¼ˆç”± Manager æä¾›ï¼‰ã€‘\n{memory_snapshot}")
    sections.append(
        "ã€äº¤ä»˜è¦æ±‚ã€‘\n"
        "- ç›´æ¥ç»™å‡ºå¯æ‰§è¡Œç»“æœæˆ–ç»“è®ºã€‚\n"
        "- ä¸è¦é‡å¤ç³»ç»Ÿè¾¹ç•Œè¯´æ˜ã€‚\n"
        "- è¾“å‡ºåº”å¯è¢« Manager ç›´æ¥è½¬è¿°ç»™ç”¨æˆ·ã€‚"
    )
    instruction = "\n\n".join([item for item in sections if str(item).strip()]).strip()
    if len(instruction) > 6000:
        instruction = instruction[:6000]
    return instruction, {
        "worker_has_memory": worker_has_memory,
        "private_session": private_session,
        "dialog_context_included": bool(dialog_context),
        "memory_summary_included": bool(memory_snapshot),
        "memory_summary_requested": bool(wants_memory_summary),
    }


def _is_message_too_long_error(exc: Exception) -> bool:
    text = str(exc or "").lower()
    return "too_long" in text or "too long" in text or "message is too long" in text


async def _send_response_as_markdown_file(
    ctx: UnifiedContext, content: str, prefix: str = "agent_response"
):
    if not content:
        return None
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{stamp}.md"
    return await ctx.reply_document(
        document=content.encode("utf-8"),
        filename=filename,
        caption="ğŸ“ å†…å®¹è¾ƒé•¿ï¼Œå·²è½¬ä¸º Markdown æ–‡ä»¶å‘é€ã€‚",
    )


async def _fetch_user_memory_snapshot(user_id: str) -> str:
    try:
        return markdown_memory_store.load_snapshot(
            str(user_id),
            include_daily=True,
            max_chars=2400,
        )
    except Exception:
        return ""


async def _try_handle_waiting_confirmation(
    ctx: UnifiedContext, user_message: str
) -> bool:
    text = (user_message or "").strip().lower()
    if not text:
        return False

    continue_cues = {"ç»§ç»­", "ç»§ç»­æ‰§è¡Œ", "ç»§ç»­é‡éƒ¨ç½²", "resume", "continue"}
    stop_cues = {"åœæ­¢", "å–æ¶ˆ", "åœæ­¢ä»»åŠ¡", "stop", "cancel"}
    intent_continue = text in continue_cues
    intent_stop = text in stop_cues
    if not intent_continue and not intent_stop:
        return False

    from core.heartbeat_store import heartbeat_store

    user_id = str(ctx.message.user.id)
    active_task = await heartbeat_store.get_session_active_task(user_id)
    if not active_task or active_task.get("status") != "waiting_user":
        return False

    task_id = str(active_task.get("id"))
    if intent_continue:
        await heartbeat_store.update_session_active_task(
            user_id,
            status="running",
            needs_confirmation=False,
            confirmation_deadline="",
        )
        await heartbeat_store.release_lock(user_id)
        await heartbeat_store.append_session_event(
            user_id, f"user_continue_by_text:{task_id}"
        )
        await ctx.reply("âœ… å·²ç¡®è®¤ç»§ç»­æ‰§è¡Œï¼Œæ­£åœ¨ç»§ç»­å¤„ç†ã€‚")
        # Let the current message continue through normal chat handling.
        return False
    else:
        await heartbeat_store.update_session_active_task(
            user_id,
            status="cancelled",
            needs_confirmation=False,
            confirmation_deadline="",
            clear_active=True,
            result_summary="Cancelled by user confirmation text.",
        )
        await heartbeat_store.release_lock(user_id)
        await heartbeat_store.append_session_event(
            user_id, f"user_stop_by_text:{task_id}"
        )
        await ctx.reply("ğŸ›‘ å·²åœæ­¢è¯¥ä»»åŠ¡ã€‚")
        return True


async def _try_handle_memory_commands(ctx: UnifiedContext, user_message: str) -> bool:
    text = str(user_message or "").strip()
    if not text:
        return False
    user_id = str(ctx.message.user.id)
    private_session = _is_private_memory_session(ctx)

    explicit_patterns = (
        r"^(?:è¯·è®°ä½|è®°ä½|è®°ä¸€ä¸‹)\s*[:ï¼š]?\s*(.+)$",
        r"^remember\s+(.*)$",
    )

    async def _write_user_memory(content: str) -> tuple[bool, str]:
        return markdown_memory_store.remember(
            user_id,
            content,
            source="user_explicit",
        )

    if text.lower() in {"memory list", "memory user", "æŸ¥çœ‹è®°å¿†", "æˆ‘çš„è®°å¿†"}:
        if not private_session:
            await ctx.reply("âš ï¸ ç¾¤èŠåœºæ™¯ä¸å±•ç¤ºä¸ªäºº MEMORY.mdã€‚è¯·åœ¨ç§èŠä¸­ä½¿ç”¨ã€‚")
            return True
        try:
            rendered = (await _fetch_user_memory_snapshot(user_id)).strip()
            if not rendered:
                rendered = "æš‚æœªæ£€ç´¢åˆ°ç”¨æˆ·è®°å¿†ã€‚"
            await ctx.reply(f"ğŸ§  ç”¨æˆ·è®°å¿†\n\n{rendered}")
        except Exception as exc:
            await ctx.reply(f"âš ï¸ è¯»å–è®°å¿†å¤±è´¥ï¼š{exc}")
        return True

    for pattern in explicit_patterns:
        match = re.match(pattern, text, flags=re.IGNORECASE)
        if not match:
            continue
        if not private_session:
            await ctx.reply("âš ï¸ ä»…æ”¯æŒåœ¨ç§èŠä¸­å†™å…¥ä¸ªäºº MEMORY.mdã€‚")
            return True
        content = str(match.group(1) or "").strip()
        if not content:
            break
        ok, detail = await _write_user_memory(content)
        if ok:
            await ctx.reply(f"ğŸ§  å·²å†™å…¥ MEMORY.mdã€‚\n- æå–åˆ°ï¼š{detail}")
        else:
            await ctx.reply(f"âš ï¸ å†™å…¥è®°å¿†å¤±è´¥ï¼š{detail}")
        return True

    return False


async def handle_ai_chat(ctx: UnifiedContext) -> None:
    """
    å¤„ç†æ™®é€šæ–‡æœ¬æ¶ˆæ¯ï¼Œä½¿ç”¨å¯¹è¯æ¨¡å‹ç”Ÿæˆå›å¤
    æ”¯æŒå¼•ç”¨ï¼ˆå›å¤ï¼‰åŒ…å«å›¾ç‰‡æˆ–è§†é¢‘çš„æ¶ˆæ¯
    """
    user_message = ctx.message.text
    # Legacy fallbacks
    update = ctx.platform_event
    context = ctx.platform_ctx

    chat_id = ctx.message.chat.id
    user_id = ctx.message.user.id
    platform_name = ctx.message.platform

    if not user_message:
        return

    # Keep heartbeat proactive delivery target aligned with the latest active chat.
    try:
        from core.heartbeat_store import heartbeat_store

        await heartbeat_store.set_delivery_target(
            str(user_id), str(platform_name), str(chat_id)
        )
    except Exception:
        logger.debug("Failed to update heartbeat delivery target.", exc_info=True)

    # 0. Save user message immediately to ensure persistence even if we return early
    # Note: We save the raw user message here.
    # If using history later, we might want to avoid saving duplicates if we constructed a complex prmopt.
    # But for "chat record", raw input is best.
    await add_message(ctx, user_id, "user", user_message)

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(
            f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI å¯¹è¯åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`\n\n"
        )
        return

    if await _try_handle_waiting_confirmation(ctx, user_message):
        return

    if await _try_handle_memory_commands(ctx, user_message):
        return

    # 0.5 Fast-track: Detected video URL -> Show Options (Download vs Summarize)
    from utils import extract_video_url

    video_url = extract_video_url(user_message)
    if video_url:
        logger.info(f"Detected video URL: {video_url}, presenting options")

        # Save URL to context for callback access
        if context:
            ctx.user_data["pending_video_url"] = video_url
            logger.info(f"[AIHandler] Set pending_video_url for {user_id}: {video_url}")

        await ctx.reply(
            {
                "text": "ğŸ”— **å·²è¯†åˆ«è§†é¢‘é“¾æ¥**\n\næ‚¨å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ“ä½œï¼š",
                "ui": {
                    "actions": [
                        [
                            {
                                "text": "ğŸ“¹ ä¸‹è½½è§†é¢‘",
                                "callback_data": "action_download_video",
                            },
                            {
                                "text": "ğŸ“ ç”Ÿæˆæ‘˜è¦",
                                "callback_data": "action_summarize_video",
                            },
                        ]
                    ]
                },
            }
        )
        return

    # æ£€æŸ¥æ˜¯å¦å¼€å¯äº†æ²‰æµ¸å¼ç¿»è¯‘
    settings = await get_user_settings(user_id)
    if settings.get("auto_translate", 0):
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€€å‡ºæŒ‡ä»¤
        if user_message.strip().lower() in [
            "/cancel",
            "é€€å‡º",
            "å…³é—­ç¿»è¯‘",
            "é€€å‡ºç¿»è¯‘",
            "cancel",
        ]:
            from core.state_store import set_translation_mode

            await set_translation_mode(user_id, False)
            await ctx.reply("ğŸš« å·²é€€å‡ºæ²‰æµ¸å¼ç¿»è¯‘æ¨¡å¼ã€‚")
            return

        # ç¿»è¯‘æ¨¡å¼å¼€å¯
        thinking_msg = await ctx.reply("ğŸŒ ç¿»è¯‘ä¸­...")
        await ctx.send_chat_action(action="typing")

        try:
            system_instruction = prompt_composer.compose_base(
                runtime_user_id=str(user_id),
                tools=[],
                runtime_policy_ctx={
                    "agent_kind": "core-manager",
                    "policy": {"tools": {"allow": [], "deny": []}},
                },
                mode="translate",
            )
            translation_request = (
                "è¯·æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ã€‚\n"
                "- å¦‚æœè¾“å…¥æ˜¯ä¸­æ–‡ï¼Œç¿»è¯‘æˆè‹±æ–‡ã€‚\n"
                "- å¦‚æœè¾“å…¥æ˜¯å…¶ä»–è¯­è¨€ï¼Œç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚\n"
                "- åªè¾“å‡ºè¯‘æ–‡ï¼Œä¸è¦è§£é‡Šã€‚\n\n"
                f"è¾“å…¥ï¼š{user_message}"
            )
            if openai_async_client is None:
                raise RuntimeError("OpenAI async client is not initialized")
            translated = await generate_text(
                async_client=openai_async_client,
                model=GEMINI_MODEL,
                contents=translation_request,
                config={"system_instruction": system_instruction},
            )
            translated = str(translated or "").strip()
            if translated:
                translation_text = f"ğŸŒ **è¯‘æ–‡**\n\n{translated}"
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                await ctx.edit_message(msg_id, translation_text)
                await add_message(ctx, user_id, "model", translation_text)
                # ç»Ÿè®¡
                await increment_stat(user_id, "translations_count")
            else:
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                await ctx.edit_message(msg_id, "âŒ æ— æ³•ç¿»è¯‘ã€‚")
        except Exception as e:
            logger.error(f"Translation error: {e}")
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "âŒ ç¿»è¯‘æœåŠ¡å‡ºé”™ã€‚")
        return

    memory_snapshot = ""

    # --- Agent Orchestration ---
    from core.agent_orchestrator import agent_orchestrator

    # 1. æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ¶ˆæ¯ (Reply Context)
    from .message_utils import process_reply_message

    extra_context = ""
    has_media, reply_extra_context, media_data, mime_type = await process_reply_message(
        ctx
    )

    if reply_extra_context:
        extra_context += reply_extra_context

    # Check if we should abort (e.g. file too big)
    if ctx.message.reply_to_message:
        r = ctx.message.reply_to_message
        is_media = r.type in [MessageType.VIDEO, MessageType.AUDIO, MessageType.VOICE]
        if is_media and not has_media:
            return

    # URL é€»è¾‘å·²ç§»äº¤ç»™ Agent (skill: web_browser, download_video)
    # ä¸å†è¿›è¡Œç¡¬ç¼–ç é¢„åŠ è½½æˆ–å¼¹çª—

    # éšæœºé€‰æ‹©ä¸€ç§"æ¶ˆæ¯å·²æ”¶åˆ°"çš„æç¤º
    RECEIVED_PHRASES = [
        "ğŸ“¨ æ”¶åˆ°ï¼å¤§è„‘æ€¥é€Ÿè¿è½¬ä¸­...",
        "âš¡ ä¿¡å·å·²æ¥æ”¶ï¼Œå¼€å§‹è§£æ...",
        "ğŸª Bip Bip! æ¶ˆæ¯ç›´è¾¾æ ¸å¿ƒ...",
        "ğŸ“¡ ç¥ç»è¿æ¥å»ºç«‹ä¸­...",
        "ğŸ’­ æ­£åœ¨è°ƒå–ç›¸å…³è®°å¿†...",
        "ğŸŒ ç¨å¾®æœ‰ç‚¹å µè½¦ï¼Œé©¬ä¸Šå°±å¥½...",
        "âœ¨ æŒ‡ä»¤å·²ç¡®è®¤ï¼Œå‡†å¤‡æ–½æ³•...",
    ]

    if not has_media:
        thinking_msg = await ctx.reply(random.choice(RECEIVED_PHRASES))
    else:
        thinking_msg = await ctx.reply("ğŸ¤” è®©æˆ‘çœ‹çœ‹å¼•ç”¨å…·ä½“å†…å®¹...")

    # 3. æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡ (History)
    final_user_message = user_message
    if extra_context:
        final_user_message = extra_context + "ç”¨æˆ·è¯·æ±‚ï¼š" + user_message
    if memory_snapshot:
        final_user_message = (
            "ã€å·²æ£€ç´¢åˆ°ç”¨æˆ·è®°å¿†ã€‘\n"
            f"{memory_snapshot}\n\n"
            "è¯·å…ˆåŸºäºä¸Šè¿°è®°å¿†å›ç­”ç”¨æˆ·æœ¬äººç›¸å…³é—®é¢˜ï¼›å¦‚æœè®°å¿†ä¸­æ²¡æœ‰å¯¹åº”ä¿¡æ¯ï¼Œå†æ˜ç¡®è¯´æ˜æœªçŸ¥ã€‚\n"
            "å›ç­”æ—¶ä¼˜å…ˆä½¿ç”¨å·²æ£€ç´¢åˆ°çš„äº‹å®ï¼Œä¸è¦ç¼–é€ æœªç»™å‡ºçš„ä¿¡æ¯ã€‚\n\n"
            f"ç”¨æˆ·è¯·æ±‚ï¼š{user_message}"
        )

    # User message already saved at start of function.
    # await add_message(context, user_id, "user", final_user_message)

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    # åŠ¨æ€åŠ è½½è¯åº“
    LOADING_PHRASES = [
        "ğŸ¤– è°ƒç”¨èµ›åšç®—åŠ›ä¸­...",
        "ğŸ’­ æ­¤é—®é¢˜ç¨æ˜¾æ·±å¥¥...",
        "ğŸ› é¡ºæ‰‹æ¸…æ´—ä¸‹æ•°æ®ç®¡é“...",
        "ğŸ“¡ æ­£åœ¨å°è¯•è¿æ¥ç«æ˜Ÿé€šè®¯...",
        "ğŸª å…ˆç»™ AI å–‚å—é¥¼å¹²è¡¥å……ä½“åŠ›...",
        "ğŸŒ ç¨ç­‰ï¼Œå‰é¢æœ‰ç‚¹å µ...",
        "ğŸ“š ç¿»é˜…ç™¾ç§‘å…¨ä¹¦ä¸­...",
        "ğŸ”¨ æ­£åœ¨ç‹‚æ•²ä»£ç å®ç°éœ€æ±‚...",
        "ğŸŒŒ è¯•å›¾ç©¿è¶Šè™«æ´å¯»æ‰¾ç­”æ¡ˆ...",
        "ğŸ§¹ æ¸…ç†ä¸€ä¸‹å†…å­˜ç¢ç‰‡...",
        "ğŸ”Œ æ£€æŸ¥ä¸‹ç½‘çº¿æ¥å¥½æ²¡...",
        "ğŸ¨ æ­£åœ¨ä¸ºæ‚¨ç»˜åˆ¶æ€ç»´å¯¼å›¾...",
        "ğŸ• åƒå£æŠ«è¨ï¼Œé©¬ä¸Šå›æ¥...",
        "ğŸ§˜ æ•°å­—å†¥æƒ³ä¸­...",
        "ğŸƒ å…¨åŠ›å†²åˆºä¸­...",
    ]

    # å…±äº«çŠ¶æ€
    state = {"last_update_time": time.time(), "final_text": "", "running": True}

    async def loading_animation():
        """
        åå°åŠ¨ç”»ä»»åŠ¡ï¼šæ¯éš”å‡ ç§’æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹ã€‚
        å¦‚æœå¡ä½äº†ï¼ˆæ¯”å¦‚åœ¨è°ƒç”¨ Toolsï¼‰ï¼Œé€šè¿‡ä¿®æ”¹æ¶ˆæ¯æ¥â€œå–èŒâ€ã€‚
        """
        while state["running"]:
            await asyncio.sleep(4)  # Check every 4s
            if not state["running"]:
                break

            now = time.time()
            # å¦‚æœè¶…è¿‡ 5 ç§’æ²¡æœ‰æ›´æ–°æ–‡æœ¬ï¼ˆè¯´æ˜å¡åœ¨ Tool æˆ–è€…ç”Ÿæˆæ…¢ï¼‰
            if now - state["last_update_time"] > 5:
                phrase = random.choice(LOADING_PHRASES)

                # å¦‚æœå·²ç»æœ‰ä¸€éƒ¨åˆ†æ–‡æœ¬äº†ï¼Œé™„åœ¨åé¢ï¼›å¦‚æœæ˜¯ç©ºçš„ï¼Œç›´æ¥æ˜¾ç¤º
                display_text = state["final_text"]
                if display_text:
                    display_text += f"\n\nâ³ {phrase}"
                else:
                    display_text = phrase

                try:
                    msg_id = getattr(
                        thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                    )
                    await ctx.edit_message(msg_id, display_text)
                except Exception as e:
                    logger.debug(f"Animation edit failed: {e}")

                # Update time to avoid spamming edits (waiting another cycle)
                state["last_update_time"] = time.time()

    # Default to True for backward compatibility or if adapter missing
    can_update = getattr(ctx._adapter, "can_update_message", True)
    stream_segment_enabled = (
        os.getenv("AI_SEGMENT_STREAM_ENABLED", "true").lower() == "true"
        and str(platform_name or "").lower() in {"telegram", "discord"}
        and not has_media
    )
    stream_min_chars = _env_int("AI_SEGMENT_STREAM_MIN_CHARS", 220, 40)
    stream_max_chars = _env_int("AI_SEGMENT_STREAM_MAX_CHARS", 1200, 160)
    stream_flush_sec = _env_float("AI_SEGMENT_STREAM_FLUSH_SEC", 1.0, 0.2)
    stream_buffer = ""
    stream_chunks_seen = 0
    stream_chunks_sent = 0
    stream_last_sent_ts = 0.0
    stream_locked = False
    thinking_deleted = False

    async def _flush_stream_buffer(*, force: bool = False) -> None:
        nonlocal \
            stream_buffer, \
            stream_chunks_sent, \
            stream_last_sent_ts, \
            thinking_deleted
        if not stream_segment_enabled or stream_locked:
            return
        if not stream_buffer:
            return
        now = time.time()
        if not force and now - stream_last_sent_ts < stream_flush_sec:
            return

        while stream_buffer:
            cut = _stream_cut_index(stream_buffer, stream_max_chars)
            if cut <= 0:
                return
            if (
                not force
                and cut < stream_min_chars
                and len(stream_buffer) < stream_max_chars
            ):
                return
            segment = stream_buffer[:cut].strip()
            stream_buffer = stream_buffer[cut:].lstrip()
            if not segment:
                continue
            await ctx.reply(segment)
            stream_chunks_sent += 1
            stream_last_sent_ts = time.time()
            if can_update and not thinking_deleted:
                try:
                    await thinking_msg.delete()
                    thinking_deleted = True
                except Exception:
                    pass
            if not force:
                return

    # å¯åŠ¨åŠ¨ç”»ä»»åŠ¡ (ä»…å½“æ”¯æŒæ¶ˆæ¯æ›´æ–°æ—¶ï¼Œä¹Ÿå°±æ˜¯é DingTalk)
    animation_task = None
    if can_update:
        animation_task = asyncio.create_task(loading_animation())

    # --- Task Registration ---
    from core.task_manager import task_manager

    current_task = asyncio.current_task()
    await task_manager.register_task(user_id, current_task, description="AI å¯¹è¯")

    try:
        message_history = []

        # æ„å»ºå½“å‰æ¶ˆæ¯
        current_msg_parts = []
        current_msg_parts.append({"text": final_user_message})

        if has_media and media_data:
            current_msg_parts.append(
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64.b64encode(bytes(media_data)).decode("utf-8"),
                    }
                }
            )

        # è·å–å†å²ä¸Šä¸‹æ–‡
        # HACK: Because 'add_message' only saves TEXT to DB, we lose the media info if we just fetch from DB.
        # So we need to:
        # 1. Fetch history from DB (which now includes the latest text-only message)
        # 2. POP the last message from history (which is our text-only version)
        # 3. Append our rich 'current_msg_parts' (with Text + Media)

        history = await get_user_context(ctx, user_id)  # Returns list of dicts

        if history and len(history) > 0 and history[-1]["role"] == "user":
            # Check if the last DB message matches our current text (sanity check)
            last_db_text = history[-1]["parts"][0]["text"]
            if last_db_text == final_user_message:
                # Remove it, so we can replace it with the Rich version
                history.pop()

        # æ‹¼æ¥: History + Current Rich Message
        message_history.extend(history)
        message_history.append({"role": "user", "parts": current_msg_parts})

        # B. è°ƒç”¨ Agent Orchestrator
        final_text_response = ""
        last_stream_update = 0

        async for chunk_text in agent_orchestrator.handle_message(ctx, message_history):
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆï¼ˆè™½ç„¶ await ä¼šæŠ›å‡º CancelledErrorï¼Œä½†ä¸»åŠ¨æ£€æŸ¥æ›´å®‰å…¨ï¼‰
            if task_manager.is_cancelled(user_id):
                logger.info(f"Task cancelled check hit for user {user_id}")
                raise asyncio.CancelledError()

            chunk_text = str(chunk_text or "")
            final_text_response += chunk_text
            state["final_text"] = final_text_response
            state["last_update_time"] = time.time()

            stream_chunks_seen += 1
            if stream_segment_enabled:
                if "```" in chunk_text and stream_chunks_sent == 0:
                    stream_locked = True
                if not stream_locked:
                    stream_buffer += chunk_text
                    if stream_chunks_seen >= 2:
                        await _flush_stream_buffer(force=False)

            # Update UI (Standard Stream) - ONLY if supported
            if can_update and (stream_chunks_sent == 0 or stream_locked):
                now = time.time()
                if now - last_stream_update > 1.0:  # Reduce frequency slightly
                    msg_id = getattr(
                        thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                    )
                    try:
                        await ctx.edit_message(msg_id, final_text_response)
                    except MessageSendError as edit_err:
                        # Long stream content is handled by preview-truncation in UnifiedContext;
                        # if platform still rejects, just skip this tick and continue.
                        if not _is_message_too_long_error(edit_err):
                            raise
                    last_stream_update = now

        # åœæ­¢åŠ¨ç”»
        state["running"] = False
        if animation_task:
            animation_task.cancel()  # Ensure it stops immediately

        # 5. å‘é€æœ€ç»ˆå›å¤å¹¶å…¥åº“
        if final_text_response:
            ui_payload = _pop_pending_ui_payload(ctx.user_data)
            streamed_delivery = (
                stream_segment_enabled
                and stream_chunks_sent > 0
                and not stream_locked
                and not ui_payload
            )

            if streamed_delivery:
                await _flush_stream_buffer(force=True)
                tail = stream_buffer.strip()
                if tail:
                    await ctx.reply(tail)
                if can_update and not thinking_deleted:
                    try:
                        await thinking_msg.delete()
                    except Exception as del_e:
                        logger.warning(f"Failed to delete thinking_msg: {del_e}")
            else:
                rendered_response = await process_and_send_code_files(
                    ctx, final_text_response
                )

                try:
                    if len(final_text_response) > LONG_RESPONSE_FILE_THRESHOLD:
                        preview_text = rendered_response.strip()
                        if len(preview_text) > 1200:
                            preview_text = (
                                preview_text[:1200].rstrip()
                                + "\n\n...ï¼ˆå†…å®¹è¾ƒé•¿ï¼Œå®Œæ•´ç»“æœè§é™„ä»¶ï¼‰"
                            )
                        sent_msg = None
                        if preview_text:
                            payload = {"text": preview_text}
                            if ui_payload:
                                payload["ui"] = ui_payload
                            sent_msg = await ctx.reply(payload)
                        await ctx.reply(
                            "ğŸ“ å†…å®¹è¾ƒé•¿ï¼Œå®Œæ•´ç»“æœå·²è½¬ä¸º Markdown æ–‡ä»¶å‘é€ã€‚"
                        )
                        sent_msg = await _send_response_as_markdown_file(
                            ctx, final_text_response
                        )
                    else:
                        payload = {"text": rendered_response}
                        if ui_payload:
                            payload["ui"] = ui_payload
                        sent_msg = await ctx.reply(payload)
                except MessageSendError as send_err:
                    if not _is_message_too_long_error(send_err):
                        raise
                    await ctx.reply("âš ï¸ æ–‡æœ¬è¿‡é•¿ï¼Œæ­£åœ¨è½¬æ¢ä¸ºæ–‡ä»¶å‘é€...")
                    sent_msg = await _send_response_as_markdown_file(
                        ctx, final_text_response
                    )

                if sent_msg and can_update:
                    try:
                        await thinking_msg.delete()
                    except Exception as del_e:
                        logger.warning(f"Failed to delete thinking_msg: {del_e}")
                elif not sent_msg and can_update:
                    msg_id = getattr(
                        thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                    )
                    sent_msg = await ctx.edit_message(msg_id, rendered_response)

            # è®°å½•æ¨¡å‹å›å¤åˆ°ä¸Šä¸‹æ–‡ (Explicitly save final response)
            await add_message(ctx, user_id, "model", final_text_response)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "ai_chats")

    except asyncio.CancelledError:
        logger.info(f"AI chat task cancelled for user {user_id}")
        state["running"] = False
        if animation_task:
            animation_task.cancel()
        # ä¸å‘é€é”™è¯¯æ¶ˆæ¯ï¼Œå› ä¸º /stop å·²ç»å›å¤äº†
        raise

    except Exception as e:
        state["running"] = False
        if animation_task:
            animation_task.cancel()
        logger.error(f"Agent error: {e}", exc_info=True)

        if str(e) == "Message is not modified":
            pass
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id, f"âŒ Agent è¿è¡Œå‡ºé”™ï¼š{e}\n\nè¯·å°è¯• /new é‡ç½®å¯¹è¯ã€‚"
            )
    finally:
        task_manager.unregister_task(user_id)


async def handle_ai_photo(ctx: UnifiedContext) -> None:
    """
    å¤„ç†å›¾ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨å¯¹è¯æ¨¡å‹åˆ†æå›¾ç‰‡
    """
    user_id = ctx.message.user.id

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`")
        return

    try:
        media = await extract_media_input(
            ctx,
            expected_types={MessageType.IMAGE},
            auto_download=True,
        )
    except MediaProcessingError as exc:
        if exc.error_code == "unsupported_media_on_platform":
            await ctx.reply("âŒ å½“å‰å¹³å°æš‚ä¸æ”¯æŒè¯¥å›¾ç‰‡æ¶ˆæ¯æ ¼å¼ï¼Œè¯·æ”¹ä¸ºå‘é€æ™®é€šå›¾ç‰‡ã€‚")
        else:
            await ctx.reply(
                "âŒ å½“å‰å¹³å°æš‚æ—¶æ— æ³•ä¸‹è½½å›¾ç‰‡å†…å®¹ã€‚è¯·ç¨åé‡è¯•ï¼Œæˆ–é™„å¸¦æ–‡å­—è¯´æ˜åå†å‘é€ã€‚"
            )
        return

    if not media.content:
        await ctx.reply("âŒ æ— æ³•è·å–å›¾ç‰‡æ•°æ®ï¼Œè¯·é‡æ–°å‘é€ã€‚")
        return

    caption = media.caption or "è¯·æè¿°è¿™å¼ å›¾ç‰‡"

    # Save to history immediately
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€å¼ å›¾ç‰‡ã€‘ {caption}")

    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await ctx.reply("ğŸ” è®©æˆ‘ä»”ç»†çœ‹çœ‹è¿™å¼ å›¾...")

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    try:
        # æ„å»ºå¸¦å›¾ç‰‡çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": media.mime_type or "image/jpeg",
                            "data": base64.b64encode(bytes(media.content)).decode(
                                "utf-8"
                            ),
                        }
                    },
                ]
            }
        ]

        if openai_async_client is None:
            raise RuntimeError("OpenAI async client is not initialized")
        analysis = await generate_text(
            async_client=openai_async_client,
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": prompt_composer.compose_base(
                    runtime_user_id=str(user_id),
                    tools=[],
                    runtime_policy_ctx={
                        "agent_kind": "core-manager",
                        "policy": {"tools": {"allow": [], "deny": []}},
                    },
                    mode="media_image",
                )
            },
        )
        analysis = str(analysis or "").strip()

        if analysis:
            # æ›´æ–°æ¶ˆæ¯
            # æ›´æ–°æ¶ˆæ¯
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, analysis)

            # Save model response to history
            await add_message(ctx, user_id, "model", analysis)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "photo_analyses")

        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™å¼ å›¾ç‰‡ã€‚è¯·ç¨åå†è¯•ã€‚")

    except Exception as e:
        logger.error(f"AI photo analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(msg_id, "âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")


async def handle_ai_video(ctx: UnifiedContext) -> None:
    """
    å¤„ç†è§†é¢‘æ¶ˆæ¯ï¼Œä½¿ç”¨å¯¹è¯æ¨¡å‹åˆ†æè§†é¢‘
    """
    user_id = ctx.message.user.id

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`")
        return

    try:
        media = await extract_media_input(
            ctx,
            expected_types={MessageType.VIDEO},
            auto_download=True,
        )
    except MediaProcessingError as exc:
        if exc.error_code == "unsupported_media_on_platform":
            await ctx.reply(
                "âŒ å½“å‰å¹³å°æš‚ä¸æ”¯æŒè¯¥è§†é¢‘æ¶ˆæ¯æ ¼å¼ï¼Œè¯·æ”¹ä¸ºå‘é€æ ‡å‡†è§†é¢‘æ–‡ä»¶ã€‚"
            )
        else:
            await ctx.reply("âŒ å½“å‰å¹³å°æš‚æ—¶æ— æ³•ä¸‹è½½è§†é¢‘å†…å®¹ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return

    if not media.content:
        await ctx.reply("âŒ æ— æ³•è·å–è§†é¢‘æ•°æ®ï¼Œè¯·é‡æ–°å‘é€ã€‚")
        return

    caption = media.caption or "è¯·åˆ†æè¿™ä¸ªè§†é¢‘çš„å†…å®¹"

    # Save to history immediately
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè§†é¢‘ã€‘ {caption}")

    if media.file_size and media.file_size > 20 * 1024 * 1024:  # 20MB é™åˆ¶
        await ctx.reply(
            "âš ï¸ è§†é¢‘æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡ 20MBï¼‰ï¼Œæ— æ³•åˆ†æã€‚\n\nè¯·å°è¯•å‘é€è¾ƒçŸ­çš„è§†é¢‘ç‰‡æ®µã€‚"
        )
        return

    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await ctx.reply("ğŸ¬ è§†é¢‘åˆ†æä¸­ï¼Œè¯·ç¨å€™ç‰‡åˆ»...")

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    try:
        # è·å– MIME ç±»å‹
        mime_type = media.mime_type or "video/mp4"

        # æ„å»ºå¸¦è§†é¢‘çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(media.content)).decode(
                                "utf-8"
                            ),
                        }
                    },
                ]
            }
        ]

        if openai_async_client is None:
            raise RuntimeError("OpenAI async client is not initialized")
        analysis = await generate_text(
            async_client=openai_async_client,
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": prompt_composer.compose_base(
                    runtime_user_id=str(user_id),
                    tools=[],
                    runtime_policy_ctx={
                        "agent_kind": "core-manager",
                        "policy": {"tools": {"allow": [], "deny": []}},
                    },
                    mode="media_video",
                )
            },
        )
        analysis = str(analysis or "").strip()

        if analysis:
            # Update the thinking message with the model response
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, analysis)

            # Save model response to history
            await add_message(ctx, user_id, "model", analysis)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "video_analyses")
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™ä¸ªè§†é¢‘ã€‚è¯·ç¨åå†è¯•ã€‚")

    except Exception as e:
        logger.error(f"AI video analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(
            msg_id,
            "âŒ è§†é¢‘åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n"
            "å¯èƒ½çš„åŸå› ï¼š\n"
            "â€¢ è§†é¢‘æ ¼å¼ä¸æ”¯æŒ\n"
            "â€¢ è§†é¢‘æ—¶é•¿è¿‡é•¿\n"
            "â€¢ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
        )


async def handle_sticker_message(ctx: UnifiedContext) -> None:
    """
    å¤„ç†è¡¨æƒ…åŒ…æ¶ˆæ¯ï¼Œå°†å…¶è½¬æ¢ä¸ºå›¾ç‰‡è¿›è¡Œåˆ†æ
    """
    user_id = ctx.message.user.id

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        return  # Silent ignore for stickers if unauthorized? Or reply?

    try:
        media = await extract_media_input(
            ctx,
            expected_types={MessageType.STICKER, MessageType.ANIMATION},
            auto_download=True,
        )
    except MediaProcessingError:
        return

    if not media.content:
        return

    # Check if animated or video sticker (might be harder to handle)
    is_animated = bool(media.meta.get("is_animated"))
    is_video = bool(media.meta.get("is_video"))

    caption = "è¯·æè¿°è¿™ä¸ªè¡¨æƒ…åŒ…çš„æƒ…æ„Ÿå’Œå†…å®¹"

    # Save to history
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè¡¨æƒ…åŒ…ã€‘")

    thinking_msg = await ctx.reply("ğŸ¤” è¿™ä¸ªè¡¨æƒ…åŒ…æœ‰ç‚¹æ„æ€...")
    await ctx.send_chat_action(action="typing")

    try:
        # Download
        mime_type = media.mime_type or "image/webp"
        if is_animated:
            # TGS format (lottie). API might not support it directly as image.
            # Maybe treat as document? Or skip?
            # Start with supporting static webp and video webm
            pass
        if is_video:
            mime_type = "video/webm"

        # æ„å»ºå†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(media.content)).decode(
                                "utf-8"
                            ),
                        }
                    },
                ]
            }
        ]

        if openai_async_client is None:
            raise RuntimeError("OpenAI async client is not initialized")
        analysis = await generate_text(
            async_client=openai_async_client,
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": prompt_composer.compose_base(
                    runtime_user_id=str(user_id),
                    tools=[],
                    runtime_policy_ctx={
                        "agent_kind": "core-manager",
                        "policy": {"tools": {"allow": [], "deny": []}},
                    },
                    mode="media_meme",
                )
            },
        )
        analysis = str(analysis or "").strip()

        if analysis:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, analysis)
            await add_message(ctx, user_id, "model", analysis)
            await increment_stat(user_id, "photo_analyses")  # Count as photo
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "ğŸ˜µ æ²¡çœ‹æ‡‚è¿™ä¸ªè¡¨æƒ…åŒ…...")

    except Exception as e:
        logger.error(f"Sticker analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(msg_id, "âŒ è¡¨æƒ…åŒ…åˆ†æå¤±è´¥")
