import time
import logging
import base64
from telegram import Update
from telegram.ext import ContextTypes
from telegram.error import BadRequest

from core.config import gemini_client, GEMINI_MODEL
from services.web_summary_service import extract_urls, summarize_webpage, is_video_platform, fetch_webpage_content
from user_context import get_user_context, add_message
from repositories import get_user_settings, get_video_cache
from utils import smart_edit_text, smart_reply_text
from stats import increment_stat

logger = logging.getLogger(__name__)

# æ€è€ƒæç¤ºæ¶ˆæ¯
THINKING_MESSAGE = "ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."


async def handle_ai_chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    å¤„ç†æ™®é€šæ–‡æœ¬æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI ç”Ÿæˆå›å¤
    æ”¯æŒå¼•ç”¨ï¼ˆå›å¤ï¼‰åŒ…å«å›¾ç‰‡æˆ–è§†é¢‘çš„æ¶ˆæ¯
    """
    user_message = update.message.text
    chat_id = update.message.chat_id
    user_id = update.message.from_user.id

    if not user_message:
        return

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed
    if not await is_user_allowed(user_id):
        await smart_reply_text(update,
            "â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI å¯¹è¯åŠŸèƒ½çš„æƒé™ã€‚\n\n"
            "å¦‚éœ€ä¸‹è½½è§†é¢‘ï¼Œè¯·ä½¿ç”¨ /download å‘½ä»¤ã€‚"
        )
        return

    # æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å« URLï¼ˆè‡ªåŠ¨ç”Ÿæˆç½‘é¡µæ‘˜è¦ï¼‰
    urls = extract_urls(user_message)
    
    # å¦‚æœåªæ˜¯ä¸€ä¸ª URL ä¸”æ²¡æœ‰å…¶ä»–å†…å®¹
    if urls and user_message.strip() in urls:
        url = urls[0]
        
        # æ™ºèƒ½é€»è¾‘ï¼šå¦‚æœæ˜¯è§†é¢‘å¹³å°é“¾æ¥ï¼Œè¯¢é—®ç”¨æˆ·æ„å›¾
        if is_video_platform(url):
            context.user_data['pending_video_url'] = url
            
            from telegram import InlineKeyboardButton, InlineKeyboardMarkup
            keyboard = [
                [
                    InlineKeyboardButton("ğŸ“¹ ä¸‹è½½è§†é¢‘", callback_data="action_download_video"),
                    InlineKeyboardButton("ğŸ“ AI æ‘˜è¦", callback_data="action_summarize_video"),
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await smart_reply_text(update,
                "ğŸ¤” æ£€æµ‹åˆ°è§†é¢‘é“¾æ¥ï¼Œæ‚¨æƒ³è¦åšä»€ä¹ˆï¼Ÿ",
                reply_markup=reply_markup
            )
            return

        # æ™®é€šç½‘é¡µï¼Œç›´æ¥ç”Ÿæˆæ‘˜è¦
        thinking_msg = await smart_reply_text(update, "ğŸ“„ æ­£åœ¨è·å–ç½‘é¡µå†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦...")
        await context.bot.send_chat_action(chat_id=chat_id, action="typing")
        
        summary = await summarize_webpage(url)
        # Use smart_edit_text which handles Markdown conversion and fallbacks
        await smart_edit_text(thinking_msg, summary)
        
        # è®°å½•ç»Ÿè®¡
        await increment_stat(user_id, "ai_chats")
        return

    # æ£€æŸ¥æ˜¯å¦å¼€å¯äº†æ²‰æµ¸å¼ç¿»è¯‘
    settings = await get_user_settings(user_id)
    if settings.get("auto_translate", 0):
        # ç¿»è¯‘æ¨¡å¼å¼€å¯
        thinking_msg = await smart_reply_text(update, "ğŸŒ ç¿»è¯‘ä¸­...")
        await context.bot.send_chat_action(chat_id=chat_id, action="typing")
        
        try:
            response = gemini_client.models.generate_content(
                model=GEMINI_MODEL,
                contents=user_message,
                config={
                    "system_instruction": (
                        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§„åˆ™è¿›è¡Œç¿»è¯‘ï¼š\n"
                        "1. å¦‚æœè¾“å…¥æ˜¯ä¸­æ–‡ï¼Œè¯·ç¿»è¯‘æˆè‹±æ–‡ã€‚\n"
                        "2. å¦‚æœè¾“å…¥æ˜¯å…¶ä»–è¯­è¨€ï¼Œè¯·ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚\n"
                        "3. åªè¾“å‡ºè¯‘æ–‡ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–çš„æ–‡æœ¬ã€‚\n"
                        "4. ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œæ ¼å¼ã€‚"
                    ),
                },
            )
            if response.text:
                await smart_edit_text(thinking_msg, f"ğŸŒ **è¯‘æ–‡**\n\n{response.text}")
                # ç»Ÿè®¡
                await increment_stat(user_id, "translations_count")
            if response.text:
                await smart_edit_text(thinking_msg, f"ğŸŒ **è¯‘æ–‡**\n\n{response.text}")
                # ç»Ÿè®¡
                await increment_stat(user_id, "translations_count")
            else:
                await smart_edit_text(thinking_msg, "âŒ æ— æ³•ç¿»è¯‘ã€‚")
        except Exception as e:
            logger.error(f"Translation error: {e}")
            await smart_edit_text(thinking_msg, "âŒ ç¿»è¯‘æœåŠ¡å‡ºé”™ã€‚")
        return

    # --- Agent Orchestration ---
    from core.agent_orchestrator import agent_orchestrator
    
    # 1. æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ¶ˆæ¯ (Reply Context)
    from .message_utils import process_reply_message, process_and_send_code_files
    
    extra_context = "" 
    has_media, reply_extra_context, media_data, mime_type = await process_reply_message(update, context)
    
    if reply_extra_context:
        extra_context += reply_extra_context
    
    # Check if we should abort (e.g. file too big)
    if update.message.reply_to_message:
         r = update.message.reply_to_message
         if (r.video or r.audio or r.voice) and not has_media:
             return
    
    # 2. æ£€æŸ¥å½“å‰æ¶ˆæ¯ä¸­æ˜¯å¦æœ‰ URL (æ··åˆæ–‡æœ¬æƒ…å†µ)
    # å¦‚æœ extra_context ä¸ºç©ºï¼Œä¸” urls ä¸ä¸ºç©ºï¼Œè¯´æ˜å¯èƒ½æ˜¯ "Look at this https://..."
    if not extra_context and urls:
        status_msg = await smart_reply_text(update, "ğŸ“„ æ­£åœ¨è·å–ç½‘é¡µå†…å®¹...")
        await context.bot.send_chat_action(chat_id=chat_id, action="typing")
        
        try:
            web_content = await fetch_webpage_content(urls[0])
            if web_content:
                extra_context = f"ã€ç½‘é¡µå†…å®¹ã€‘\n{web_content}\n\n"
            else:
                extra_context = "ã€ç³»ç»Ÿæç¤ºã€‘æ£€æµ‹åˆ°é“¾æ¥ï¼Œæ— æ³•è¯»å–è¯¦æƒ…ã€‚\n\n"
            
        except Exception as e:
            logger.error(f"Error fetching mixed URL: {e}")
        
        try:
            await status_msg.delete()
        except:
            pass

    if not has_media:
        thinking_msg = await smart_reply_text(update, THINKING_MESSAGE)
    else:
        thinking_msg = await smart_reply_text(update, "ğŸ¤” æ­£åœ¨åˆ†æå¼•ç”¨å†…å®¹...")
    
    # 3. æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡ (History)
    # å°†ç½‘é¡µä¸Šä¸‹æ–‡åˆå¹¶åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
    final_user_message = user_message
    if extra_context:
        final_user_message = extra_context + "ç”¨æˆ·è¯·æ±‚ï¼š" + user_message

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")

    try:
        # A. å¸¦åª’ä½“çš„è¯·æ±‚ (Gemini Vision) - æš‚æ—¶ä¸èµ° Agent Loop (Vision model function calling support is limited/tricky)
        # æˆ–è€…æˆ‘ä»¬æŠŠ Vision ä¹Ÿåšæˆ Agent çš„è¾“å…¥ï¼Ÿ
        # ç›®å‰ Gemini 2.0 Flash æ”¯æŒå¤šæ¨¡æ€ + Toolsã€‚
        # è®©æˆ‘ä»¬å°è¯•æŠŠ Media æ”¾å…¥ history ä¼ ç»™ Agentï¼
        
        message_history = []
        
        # æ„å»ºå½“å‰æ¶ˆæ¯
        current_msg_parts = []
        current_msg_parts.append({"text": final_user_message})
        
        if has_media and media_data:
             current_msg_parts.append({
                "inline_data": {
                    "mime_type": mime_type,
                    "data": base64.b64encode(bytes(media_data)).decode("utf-8"),
                }
            })
            
        # è·å–å†å²ä¸Šä¸‹æ–‡
        history = get_user_context(context) # Returns list of dicts
        
        # æ‹¼æ¥: History + Current
        message_history.extend(history)
        message_history.append({
            "role": "user",
            "parts": current_msg_parts
        })
        
        # B. è°ƒç”¨ Agent Orchestrator
        final_text_response = ""
        last_update_time = 0
        
        async for chunk_text in agent_orchestrator.handle_message(update, context, message_history):
            final_text_response += chunk_text
            
            # Update UI
            now = time.time()
            if now - last_update_time > 0.8:
                await smart_edit_text(thinking_msg, final_text_response)
                last_update_time = now

        # 5. å‘é€æœ€ç»ˆå›å¤å¹¶å…¥åº“
        if final_text_response:
            sent_msg = await smart_edit_text(thinking_msg, final_text_response)
            
            # è®°å½•æ¨¡å‹å›å¤åˆ°ä¸Šä¸‹æ–‡
            add_message(context, "model", final_text_response)
            
            # Try to extract code blocks
            final_display_text = await process_and_send_code_files(update, context, final_text_response)
            
            if sent_msg and final_display_text != final_text_response:
                 await smart_edit_text(sent_msg, final_display_text)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "ai_chats")
        else:
            await smart_edit_text(thinking_msg, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ (æ— è¾“å‡º)ã€‚")

    except Exception as e:
        logger.error(f"Agent error: {e}", exc_info=True)
        await smart_edit_text(thinking_msg,
            f"âŒ Agent è¿è¡Œå‡ºé”™ï¼š{e}\n\nè¯·å°è¯• /new é‡ç½®å¯¹è¯ã€‚"
        )


async def handle_ai_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    å¤„ç†å›¾ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI åˆ†æå›¾ç‰‡
    """
    chat_id = update.message.chat_id
    user_id = update.message.from_user.id
    
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed
    if not await is_user_allowed(user_id):
        await smart_reply_text(update,
            "â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚"
        )
        return
    
    # è·å–å›¾ç‰‡ï¼ˆé€‰æ‹©æœ€å¤§åˆ†è¾¨ç‡ï¼‰
    photo = update.message.photo[-1]
    caption = update.message.caption or "è¯·æè¿°è¿™å¼ å›¾ç‰‡"

    # Save to history immediately
    add_message(context, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€å¼ å›¾ç‰‡ã€‘ {caption}")
    
    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await smart_reply_text(update, "ğŸ” æ­£åœ¨åˆ†æå›¾ç‰‡...")
    
    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    
    try:
        # ä¸‹è½½å›¾ç‰‡
        file = await context.bot.get_file(photo.file_id)
        image_bytes = await file.download_as_bytearray()
        
        # æ„å»ºå¸¦å›¾ç‰‡çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": base64.b64encode(bytes(image_bytes)).decode("utf-8"),
                        }
                    },
                ]
            }
        ]
        
        # è°ƒç”¨ Gemini API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå¯ä»¥åˆ†æå›¾ç‰‡å¹¶å›ç­”é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚",
            },
        )
        
        if response.text:
            # Try to extract code blocks, send files, and get cleaned text
            from .message_utils import process_and_send_code_files
            display_text = await process_and_send_code_files(update, context, response.text)
            
            # æ›´æ–°æ¶ˆæ¯
            await smart_edit_text(thinking_msg, display_text)
            
            # Save model response to history
            add_message(context, "model", response.text)
            
            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "photo_analyses")

        else:
            await smart_edit_text(thinking_msg, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™å¼ å›¾ç‰‡ã€‚è¯·ç¨åå†è¯•ã€‚")
        
    except Exception as e:
        logger.error(f"AI photo analysis error: {e}")
        await smart_edit_text(thinking_msg, "âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")


async def handle_ai_video(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    å¤„ç†è§†é¢‘æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI åˆ†æè§†é¢‘
    """
    chat_id = update.message.chat_id
    user_id = update.message.from_user.id
    
    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed
    if not await is_user_allowed(user_id):
        await smart_reply_text(update,
            "â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚"
        )
        return
    
    # è·å–è§†é¢‘
    video = update.message.video
    if not video:
        return
    
    caption = update.message.caption or "è¯·åˆ†æè¿™ä¸ªè§†é¢‘çš„å†…å®¹"
    
    # æ£€æŸ¥è§†é¢‘å¤§å°ï¼ˆGemini æœ‰é™åˆ¶ï¼‰
    # æ£€æŸ¥è§†é¢‘å¤§å°ï¼ˆGemini æœ‰é™åˆ¶ï¼‰
    if video.file_size and video.file_size > 20 * 1024 * 1024:  # 20MB é™åˆ¶
        await smart_reply_text(update,
            "âš ï¸ è§†é¢‘æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡ 20MBï¼‰ï¼Œæ— æ³•åˆ†æã€‚\n\n"
            "è¯·å°è¯•å‘é€è¾ƒçŸ­çš„è§†é¢‘ç‰‡æ®µã€‚"
        )
        return
    
    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await smart_reply_text(update, "ğŸ¬ æ­£åœ¨åˆ†æè§†é¢‘ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    
    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    
    try:
        # ä¸‹è½½è§†é¢‘
        file = await context.bot.get_file(video.file_id)
        video_bytes = await file.download_as_bytearray()
        
        # è·å– MIME ç±»å‹
        mime_type = video.mime_type or "video/mp4"
        
        # æ„å»ºå¸¦è§†é¢‘çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(video_bytes)).decode("utf-8"),
                        }
                    },
                ]
            }
        ]
        
        # è°ƒç”¨ Gemini API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå¯ä»¥åˆ†æè§†é¢‘å†…å®¹å¹¶å›ç­”é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚",
            },
        )
        
        if response.text:
            # Try to extract code blocks, send files, and get cleaned text
            from .message_utils import process_and_send_code_files
            display_text = await process_and_send_code_files(update, context, response.text)
            
            # Update the thinking message with the cleaned text
            await smart_edit_text(thinking_msg, display_text)
            
            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "video_analyses")
        else:
            await smart_edit_text(thinking_msg, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™ä¸ªè§†é¢‘ã€‚è¯·ç¨åå†è¯•ã€‚")
        
    except Exception as e:
        logger.error(f"AI video analysis error: {e}")
        await smart_edit_text(thinking_msg,
            "âŒ è§†é¢‘åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n"
            "å¯èƒ½çš„åŸå› ï¼š\n"
            "â€¢ è§†é¢‘æ ¼å¼ä¸æ”¯æŒ\n"
            "â€¢ è§†é¢‘æ—¶é•¿è¿‡é•¿\n"
            "â€¢ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        )
