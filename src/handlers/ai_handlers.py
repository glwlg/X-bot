import time
import logging
import base64
from core.platform.models import UnifiedContext, MessageType
import random

from core.config import gemini_client, GEMINI_MODEL

from user_context import get_user_context, add_message
from repositories import get_user_settings
from stats import increment_stat

logger = logging.getLogger(__name__)

# æ€è€ƒæç¤ºæ¶ˆæ¯
THINKING_MESSAGE = "ğŸ¤” è®©æˆ‘æƒ³æƒ³..."


async def handle_ai_chat(ctx: UnifiedContext) -> None:
    """
    å¤„ç†æ™®é€šæ–‡æœ¬æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI ç”Ÿæˆå›å¤
    æ”¯æŒå¼•ç”¨ï¼ˆå›å¤ï¼‰åŒ…å«å›¾ç‰‡æˆ–è§†é¢‘çš„æ¶ˆæ¯
    """
    user_message = ctx.message.text
    # Legacy fallbacks
    update = ctx.platform_event
    context = ctx.platform_ctx

    chat_id = ctx.message.chat.id
    user_id = ctx.message.user.id

    if not user_message:
        return

    # 0. Save user message immediately to ensure persistence even if we return early
    # Note: We save the raw user message here.
    # If using history later, we might want to avoid saving duplicates if we constructed a complex prmopt.
    # But for "chat record", raw input is best.
    await add_message(ctx, user_id, "user", user_message)

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(
            f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI å¯¹è¯åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`\n\n"
        )
        return

    # 0.5 Fast-track: Detected video URL -> Show Options (Download vs Summarize)
    from utils import extract_video_url

    video_url = extract_video_url(user_message)
    if video_url:
        logger.info(f"Detected video URL: {video_url}, presenting options")

        # Save URL to context for callback access
        if context:
            ctx.user_data["pending_video_url"] = video_url
            logger.info(f"[AIHandler] Set pending_video_url for {user_id}: {video_url}")

        # Create Inline Keyboard with options
        from telegram import InlineKeyboardButton, InlineKeyboardMarkup

        keyboard = [
            [
                InlineKeyboardButton(
                    "ğŸ“¹ ä¸‹è½½è§†é¢‘", callback_data="action_download_video"
                ),
                InlineKeyboardButton(
                    "ğŸ“ ç”Ÿæˆæ‘˜è¦", callback_data="action_summarize_video"
                ),
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await ctx.reply(
            f"ğŸ”— **å·²è¯†åˆ«è§†é¢‘é“¾æ¥**\n\næ‚¨å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ“ä½œï¼š", reply_markup=reply_markup
        )
        return

    # æ£€æŸ¥æ˜¯å¦å¼€å¯äº†æ²‰æµ¸å¼ç¿»è¯‘
    settings = await get_user_settings(user_id)
    if settings.get("auto_translate", 0):
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€€å‡ºæŒ‡ä»¤
        if user_message.strip().lower() in [
            "/cancel",
            "é€€å‡º",
            "å…³é—­ç¿»è¯‘",
            "é€€å‡ºç¿»è¯‘",
            "cancel",
        ]:
            from repositories import set_translation_mode

            await set_translation_mode(user_id, False)
            await ctx.reply("ğŸš« å·²é€€å‡ºæ²‰æµ¸å¼ç¿»è¯‘æ¨¡å¼ã€‚")
            return

        # ç¿»è¯‘æ¨¡å¼å¼€å¯
        thinking_msg = await ctx.reply("ğŸŒ ç¿»è¯‘ä¸­...")
        await ctx.send_chat_action(action="typing")

        try:
            response = gemini_client.models.generate_content(
                model=GEMINI_MODEL,
                contents=user_message,
                config={
                    "system_instruction": (
                        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§„åˆ™è¿›è¡Œç¿»è¯‘ï¼š\n"
                        "1. å¦‚æœè¾“å…¥æ˜¯ä¸­æ–‡ï¼Œè¯·ç¿»è¯‘æˆè‹±æ–‡ã€‚\n"
                        "2. å¦‚æœè¾“å…¥æ˜¯å…¶ä»–è¯­è¨€ï¼Œè¯·ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚\n"
                        "3. åªè¾“å‡ºè¯‘æ–‡ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–çš„æ–‡æœ¬ã€‚\n"
                        "4. ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œæ ¼å¼ã€‚"
                    ),
                },
            )
            if response.text:
                translation_text = f"ğŸŒ **è¯‘æ–‡**\n\n{response.text}"
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                await ctx.edit_message(msg_id, translation_text)
                await add_message(ctx, user_id, "model", translation_text)
                # ç»Ÿè®¡
                await increment_stat(user_id, "translations_count")
            else:
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                await ctx.edit_message(msg_id, "âŒ æ— æ³•ç¿»è¯‘ã€‚")
        except Exception as e:
            logger.error(f"Translation error: {e}")
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "âŒ ç¿»è¯‘æœåŠ¡å‡ºé”™ã€‚")
        return

    # --- Agent Orchestration ---
    from core.agent_orchestrator import agent_orchestrator

    # 1. æ£€æŸ¥æ˜¯å¦å¼•ç”¨äº†æ¶ˆæ¯ (Reply Context)
    from .message_utils import process_reply_message, process_and_send_code_files

    extra_context = ""
    has_media, reply_extra_context, media_data, mime_type = await process_reply_message(
        ctx
    )

    if reply_extra_context:
        extra_context += reply_extra_context

    # Check if we should abort (e.g. file too big)
    if ctx.message.reply_to_message:
        r = ctx.message.reply_to_message
        is_media = r.type in [MessageType.VIDEO, MessageType.AUDIO, MessageType.VOICE]
        if is_media and not has_media:
            return

    # URL é€»è¾‘å·²ç§»äº¤ç»™ Agent (skill: web_browser, download_video)
    # ä¸å†è¿›è¡Œç¡¬ç¼–ç é¢„åŠ è½½æˆ–å¼¹çª—

    # éšæœºé€‰æ‹©ä¸€ç§"æ¶ˆæ¯å·²æ”¶åˆ°"çš„æç¤º
    RECEIVED_PHRASES = [
        "ğŸ“¨ æ”¶åˆ°ï¼å¤§è„‘æ€¥é€Ÿè¿è½¬ä¸­...",
        "âš¡ ä¿¡å·å·²æ¥æ”¶ï¼Œå¼€å§‹è§£æ...",
        "ğŸª Bip Bip! æ¶ˆæ¯ç›´è¾¾æ ¸å¿ƒ...",
        "ğŸ“¡ ç¥ç»è¿æ¥å»ºç«‹ä¸­...",
        "ğŸ’­ æ­£åœ¨è°ƒå–ç›¸å…³è®°å¿†...",
        "ğŸŒ ç¨å¾®æœ‰ç‚¹å µè½¦ï¼Œé©¬ä¸Šå°±å¥½...",
        "âœ¨ æŒ‡ä»¤å·²ç¡®è®¤ï¼Œå‡†å¤‡æ–½æ³•...",
    ]

    if not has_media:
        thinking_msg = await ctx.reply(random.choice(RECEIVED_PHRASES))
    else:
        thinking_msg = await ctx.reply("ğŸ¤” è®©æˆ‘çœ‹çœ‹å¼•ç”¨å…·ä½“å†…å®¹...")

    # 3. æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡ (History)
    final_user_message = user_message
    if extra_context:
        final_user_message = extra_context + "ç”¨æˆ·è¯·æ±‚ï¼š" + user_message

    # User message already saved at start of function.
    # await add_message(context, user_id, "user", final_user_message)

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    import asyncio

    # åŠ¨æ€åŠ è½½è¯åº“
    LOADING_PHRASES = [
        "ğŸ¤– è°ƒç”¨èµ›åšç®—åŠ›ä¸­...",
        "ğŸ’­ æ­¤é—®é¢˜ç¨æ˜¾æ·±å¥¥...",
        "ğŸ› é¡ºæ‰‹æ¸…æ´—ä¸‹æ•°æ®ç®¡é“...",
        "ğŸ“¡ æ­£åœ¨å°è¯•è¿æ¥ç«æ˜Ÿé€šè®¯...",
        "ğŸª å…ˆç»™ AI å–‚å—é¥¼å¹²è¡¥å……ä½“åŠ›...",
        "ğŸŒ ç¨ç­‰ï¼Œå‰é¢æœ‰ç‚¹å µ...",
        "ğŸ“š ç¿»é˜…ç™¾ç§‘å…¨ä¹¦ä¸­...",
        "ğŸ”¨ æ­£åœ¨ç‹‚æ•²ä»£ç å®ç°éœ€æ±‚...",
        "ğŸŒŒ è¯•å›¾ç©¿è¶Šè™«æ´å¯»æ‰¾ç­”æ¡ˆ...",
        "ğŸ§¹ æ¸…ç†ä¸€ä¸‹å†…å­˜ç¢ç‰‡...",
        "ğŸ”Œ æ£€æŸ¥ä¸‹ç½‘çº¿æ¥å¥½æ²¡...",
        "ğŸ¨ æ­£åœ¨ä¸ºæ‚¨ç»˜åˆ¶æ€ç»´å¯¼å›¾...",
        "ğŸ• åƒå£æŠ«è¨ï¼Œé©¬ä¸Šå›æ¥...",
        "ğŸ§˜ æ•°å­—å†¥æƒ³ä¸­...",
        "ğŸƒ å…¨åŠ›å†²åˆºä¸­...",
    ]

    # å…±äº«çŠ¶æ€
    state = {"last_update_time": time.time(), "final_text": "", "running": True}

    async def loading_animation():
        """
        åå°åŠ¨ç”»ä»»åŠ¡ï¼šæ¯éš”å‡ ç§’æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹ã€‚
        å¦‚æœå¡ä½äº†ï¼ˆæ¯”å¦‚åœ¨è°ƒç”¨ Toolsï¼‰ï¼Œé€šè¿‡ä¿®æ”¹æ¶ˆæ¯æ¥â€œå–èŒâ€ã€‚
        """
        while state["running"]:
            await asyncio.sleep(4)  # Check every 4s
            if not state["running"]:
                break

            now = time.time()
            # å¦‚æœè¶…è¿‡ 5 ç§’æ²¡æœ‰æ›´æ–°æ–‡æœ¬ï¼ˆè¯´æ˜å¡åœ¨ Tool æˆ–è€…ç”Ÿæˆæ…¢ï¼‰
            if now - state["last_update_time"] > 5:
                phrase = random.choice(LOADING_PHRASES)

                # å¦‚æœå·²ç»æœ‰ä¸€éƒ¨åˆ†æ–‡æœ¬äº†ï¼Œé™„åœ¨åé¢ï¼›å¦‚æœæ˜¯ç©ºçš„ï¼Œç›´æ¥æ˜¾ç¤º
                display_text = state["final_text"]
                if display_text:
                    display_text += f"\n\nâ³ {phrase}"
                else:
                    display_text = phrase

                try:
                    msg_id = getattr(
                        thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                    )
                    await ctx.edit_message(msg_id, display_text)
                except Exception as e:
                    logger.debug(f"Animation edit failed: {e}")

                # Update time to avoid spamming edits (waiting another cycle)
                state["last_update_time"] = time.time()

    # Default to True for backward compatibility or if adapter missing
    can_update = getattr(ctx._adapter, "can_update_message", True)

    # å¯åŠ¨åŠ¨ç”»ä»»åŠ¡ (ä»…å½“æ”¯æŒæ¶ˆæ¯æ›´æ–°æ—¶ï¼Œä¹Ÿå°±æ˜¯é DingTalk)
    animation_task = None
    if can_update:
        animation_task = asyncio.create_task(loading_animation())

    try:
        message_history = []

        # æ„å»ºå½“å‰æ¶ˆæ¯
        current_msg_parts = []
        current_msg_parts.append({"text": final_user_message})

        if has_media and media_data:
            current_msg_parts.append(
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": base64.b64encode(bytes(media_data)).decode("utf-8"),
                    }
                }
            )

        # è·å–å†å²ä¸Šä¸‹æ–‡
        # HACK: Because 'add_message' only saves TEXT to DB, we lose the media info if we just fetch from DB.
        # So we need to:
        # 1. Fetch history from DB (which now includes the latest text-only message)
        # 2. POP the last message from history (which is our text-only version)
        # 3. Append our rich 'current_msg_parts' (with Text + Media)

        history = await get_user_context(ctx, user_id)  # Returns list of dicts

        if history and len(history) > 0 and history[-1]["role"] == "user":
            # Check if the last DB message matches our current text (sanity check)
            last_db_text = history[-1]["parts"][0]["text"]
            if last_db_text == final_user_message:
                # Remove it, so we can replace it with the Rich version
                history.pop()

        # æ‹¼æ¥: History + Current Rich Message
        message_history.extend(history)
        message_history.append({"role": "user", "parts": current_msg_parts})

        # B. è°ƒç”¨ Agent Orchestrator
        final_text_response = ""
        last_stream_update = 0

        async for chunk_text in agent_orchestrator.handle_message(ctx, message_history):
            final_text_response += chunk_text
            state["final_text"] = final_text_response
            state["last_update_time"] = time.time()

            # Update UI (Standard Stream) - ONLY if supported
            if can_update:
                now = time.time()
                if now - last_stream_update > 1.0:  # Reduce frequency slightly
                    msg_id = getattr(
                        thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                    )
                    await ctx.edit_message(msg_id, final_text_response)
                    last_stream_update = now

        # åœæ­¢åŠ¨ç”»
        state["running"] = False
        if animation_task:
            animation_task.cancel()  # Ensure it stops immediately

        # 5. å‘é€æœ€ç»ˆå›å¤å¹¶å…¥åº“
        if final_text_response:
            # ç”¨æˆ·ä½“éªŒä¼˜åŒ–ï¼šä¸ºäº†é¿å…å·¥å…·äº§ç”Ÿçš„ä¸­é—´æ¶ˆæ¯å¯¼è‡´æœ€ç»ˆç»“æœè¢«é¡¶ä¸Šå»éœ€è¦ç¿»é¡µï¼Œ
            # è¿™é‡Œæ”¹ä¸ºå‘é€ä¸€æ¡æ–°æ¶ˆæ¯ä½œä¸ºæœ€ç»ˆç»“æœï¼Œå¹¶åˆ é™¤åŸæœ¬çš„"æ€è€ƒä¸­"æ¶ˆæ¯ã€‚

            # 1. æ£€æŸ¥æ˜¯å¦æœ‰ Skill è¿”å›çš„ UI ç»„ä»¶/æŒ‰é’®
            reply_markup = None
            pending_ui = ctx.user_data.pop("pending_ui", None)
            if pending_ui:
                from telegram import InlineKeyboardButton, InlineKeyboardMarkup

                keyboard = []
                for ui_block in pending_ui:
                    if "actions" in ui_block:
                        # actions should be list of lists (rows)
                        for row in ui_block["actions"]:
                            current_row = []
                            for btn in row:
                                # Start with supporting dict (JSON) format
                                if isinstance(btn, dict):
                                    current_row.append(
                                        InlineKeyboardButton(
                                            text=btn["text"],
                                            callback_data=btn.get("callback_data"),
                                            url=btn.get("url"),
                                        )
                                    )
                                else:
                                    # Fallback for raw objects if mixed
                                    current_row.append(btn)
                            keyboard.append(current_row)

                if keyboard:
                    reply_markup = InlineKeyboardMarkup(keyboard)

            # 2. å‘é€æ–°æ¶ˆæ¯
            sent_msg = await ctx.reply(final_text_response, reply_markup=reply_markup)

            # 2. å°è¯•åˆ é™¤æ—§çš„æ€è€ƒæ¶ˆæ¯ (å¦‚æœå‘é€æˆåŠŸ)
            # å¦‚æœæ”¯æŒç¼–è¾‘ï¼ˆTelegram/Discordï¼‰ï¼Œå°è¯•åˆ é™¤æ€è€ƒä¸­æ¶ˆæ¯
            # å¦‚æœä¸æ”¯æŒï¼ˆDingTalkï¼‰ï¼Œæ€è€ƒä¸­æ¶ˆæ¯å¯èƒ½ä¼šç•™ç€ï¼Œæˆ–è€…å°è¯•åˆ é™¤ï¼ˆè¿”å› Falseï¼‰
            if sent_msg and can_update:
                try:
                    await thinking_msg.delete()
                except Exception as del_e:
                    logger.warning(f"Failed to delete thinking_msg: {del_e}")
            elif not sent_msg and can_update:  # Fallback edit
                # å¦‚æœå‘é€å¤±è´¥ï¼ˆæå°‘è§ï¼‰ï¼Œåˆ™é™çº§ä¸ºç¼–è¾‘æ—§æ¶ˆæ¯
                msg_id = getattr(
                    thinking_msg, "message_id", getattr(thinking_msg, "id", None)
                )
                sent_msg = await ctx.edit_message(msg_id, final_text_response)

            # è®°å½•æ¨¡å‹å›å¤åˆ°ä¸Šä¸‹æ–‡ (Explicitly save final response)
            await add_message(ctx, user_id, "model", final_text_response)

            # Try to extract code blocks
            final_display_text = await process_and_send_code_files(
                ctx, final_text_response
            )

            if sent_msg and final_display_text != final_text_response and can_update:
                # Only update again if supported
                msg_id = getattr(sent_msg, "message_id", getattr(sent_msg, "id", None))
                await ctx.edit_message(msg_id, final_display_text)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "ai_chats")
    except Exception as e:
        state["running"] = False
        if animation_task:
            animation_task.cancel()
        logger.error(f"Agent error: {e}", exc_info=True)

        if str(e) == "Message is not modified":
            pass
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(
                msg_id, f"âŒ Agent è¿è¡Œå‡ºé”™ï¼š{e}\n\nè¯·å°è¯• /new é‡ç½®å¯¹è¯ã€‚"
            )


async def handle_ai_photo(ctx: UnifiedContext) -> None:
    """
    å¤„ç†å›¾ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI åˆ†æå›¾ç‰‡
    """
    chat_id = ctx.message.chat.id
    user_id = ctx.message.user.id

    # Legacy fallback
    update = ctx.platform_event
    context = ctx.platform_ctx

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`")
        return

    # è·å–å›¾ç‰‡ï¼ˆé€‰æ‹©æœ€å¤§åˆ†è¾¨ç‡ï¼‰
    # Use fallback to access raw photo object for now
    if not update.message.photo:
        return
    photo = update.message.photo[-1]
    caption = ctx.message.caption or "è¯·æè¿°è¿™å¼ å›¾ç‰‡"

    # Save to history immediately
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€å¼ å›¾ç‰‡ã€‘ {caption}")

    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await ctx.reply("ğŸ” è®©æˆ‘ä»”ç»†çœ‹çœ‹è¿™å¼ å›¾...")

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    try:
        # ä¸‹è½½å›¾ç‰‡
        image_bytes = await ctx.download_file(photo.file_id)

        # æ„å»ºå¸¦å›¾ç‰‡çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": "image/jpeg",
                            "data": base64.b64encode(bytes(image_bytes)).decode(
                                "utf-8"
                            ),
                        }
                    },
                ]
            }
        ]

        # è°ƒç”¨ Gemini API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå¯ä»¥åˆ†æå›¾ç‰‡å¹¶å›ç­”é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚",
            },
        )

        if response.text:
            # Try to extract code blocks, send files, and get cleaned text
            from .message_utils import process_and_send_code_files

            display_text = await process_and_send_code_files(ctx, response.text)

            # æ›´æ–°æ¶ˆæ¯
            # æ›´æ–°æ¶ˆæ¯
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, display_text)

            # Save model response to history
            await add_message(ctx, user_id, "model", response.text)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "photo_analyses")

        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™å¼ å›¾ç‰‡ã€‚è¯·ç¨åå†è¯•ã€‚")

    except Exception as e:
        logger.error(f"AI photo analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(msg_id, "âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚")


async def handle_ai_video(ctx: UnifiedContext) -> None:
    """
    å¤„ç†è§†é¢‘æ¶ˆæ¯ï¼Œä½¿ç”¨ Gemini AI åˆ†æè§†é¢‘
    """
    chat_id = ctx.message.chat.id
    user_id = ctx.message.user.id

    # Legacy fallback
    update = ctx.platform_event
    context = ctx.platform_ctx

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        await ctx.reply(f"â›” æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™ã€‚\næ‚¨çš„ ID æ˜¯: `{user_id}`")
        return

    # è·å–è§†é¢‘
    video = update.message.video
    if not video:
        return

    caption = ctx.message.caption or "è¯·åˆ†æè¿™ä¸ªè§†é¢‘çš„å†…å®¹"

    # Save to history immediately
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè§†é¢‘ã€‘ {caption}")

    # æ£€æŸ¥è§†é¢‘å¤§å°ï¼ˆGemini æœ‰é™åˆ¶ï¼‰
    # æ£€æŸ¥è§†é¢‘å¤§å°ï¼ˆGemini æœ‰é™åˆ¶ï¼‰
    # æ£€æŸ¥è§†é¢‘å¤§å°ï¼ˆGemini æœ‰é™åˆ¶ï¼‰
    if video.file_size and video.file_size > 20 * 1024 * 1024:  # 20MB é™åˆ¶
        await ctx.reply(
            "âš ï¸ è§†é¢‘æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡ 20MBï¼‰ï¼Œæ— æ³•åˆ†æã€‚\n\nè¯·å°è¯•å‘é€è¾ƒçŸ­çš„è§†é¢‘ç‰‡æ®µã€‚"
        )
        return

    # ç«‹å³å‘é€"æ­£åœ¨åˆ†æ"æç¤º
    thinking_msg = await ctx.reply("ğŸ¬ è§†é¢‘åˆ†æä¸­ï¼Œè¯·ç¨å€™ç‰‡åˆ»...")

    # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
    await ctx.send_chat_action(action="typing")

    try:
        # ä¸‹è½½è§†é¢‘
        video_bytes = await ctx.download_file(video.file_id)

        # è·å– MIME ç±»å‹
        mime_type = video.mime_type or "video/mp4"

        # æ„å»ºå¸¦è§†é¢‘çš„å†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(video_bytes)).decode(
                                "utf-8"
                            ),
                        }
                    },
                ]
            }
        ]

        # è°ƒç”¨ Gemini API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œå¯ä»¥åˆ†æè§†é¢‘å†…å®¹å¹¶å›ç­”é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚",
            },
        )

        if response.text:
            # Try to extract code blocks, send files, and get cleaned text
            from .message_utils import process_and_send_code_files

            display_text = await process_and_send_code_files(ctx, response.text)

            # Update the thinking message with the cleaned text
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, display_text)

            # Save model response to history
            await add_message(ctx, user_id, "model", response.text)

            # è®°å½•ç»Ÿè®¡
            await increment_stat(user_id, "video_analyses")
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åˆ†æè¿™ä¸ªè§†é¢‘ã€‚è¯·ç¨åå†è¯•ã€‚")

    except Exception as e:
        logger.error(f"AI video analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(
            msg_id,
            "âŒ è§†é¢‘åˆ†æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•ã€‚\n\n"
            "å¯èƒ½çš„åŸå› ï¼š\n"
            "â€¢ è§†é¢‘æ ¼å¼ä¸æ”¯æŒ\n"
            "â€¢ è§†é¢‘æ—¶é•¿è¿‡é•¿\n"
            "â€¢ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
        )


async def handle_sticker_message(ctx: UnifiedContext) -> None:
    """
    å¤„ç†è¡¨æƒ…åŒ…æ¶ˆæ¯ï¼Œå°†å…¶è½¬æ¢ä¸ºå›¾ç‰‡è¿›è¡Œåˆ†æ
    """
    user_id = ctx.message.user.id
    update = ctx.platform_event

    # æ£€æŸ¥ç”¨æˆ·æƒé™
    from core.config import is_user_allowed

    if not await is_user_allowed(user_id):
        return  # Silent ignore for stickers if unauthorized? Or reply?

    sticker = update.message.sticker
    if not sticker:
        return

    # Check if animated or video sticker (might be harder to handle)
    is_animated = getattr(sticker, "is_animated", False)
    is_video = getattr(sticker, "is_video", False)

    caption = "è¯·æè¿°è¿™ä¸ªè¡¨æƒ…åŒ…çš„æƒ…æ„Ÿå’Œå†…å®¹"

    # Save to history
    await add_message(ctx, user_id, "user", f"ã€ç”¨æˆ·å‘é€äº†ä¸€ä¸ªè¡¨æƒ…åŒ…ã€‘")

    thinking_msg = await ctx.reply("ğŸ¤” è¿™ä¸ªè¡¨æƒ…åŒ…æœ‰ç‚¹æ„æ€...")
    await ctx.send_chat_action(action="typing")

    try:
        # Download
        file_bytes = await ctx.download_file(sticker.file_id)

        mime_type = "image/webp"
        if is_animated:
            # TGS format (lottie). API might not support it directly as image.
            # Maybe treat as document? Or skip?
            # Start with supporting static webp and video webm
            pass
        if is_video:
            mime_type = "video/webm"

        # æ„å»ºå†…å®¹
        contents = [
            {
                "parts": [
                    {"text": caption},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": base64.b64encode(bytes(file_bytes)).decode("utf-8"),
                        }
                    },
                ]
            }
        ]

        # Call API
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=contents,
            config={
                "system_instruction": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„åŠ©æ‰‹ï¼Œè¯·åˆ†æè¿™ä¸ªè¡¨æƒ…åŒ…çš„å†…å®¹å’Œæƒ…æ„Ÿã€‚è¯·ç”¨ç®€çŸ­æœ‰è¶£çš„ä¸­æ–‡å›å¤ã€‚",
            },
        )

        if response.text:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, response.text)
            await add_message(ctx, user_id, "model", response.text)
            await increment_stat(user_id, "photo_analyses")  # Count as photo
        else:
            msg_id = getattr(
                thinking_msg, "message_id", getattr(thinking_msg, "id", None)
            )
            await ctx.edit_message(msg_id, "ğŸ˜µ æ²¡çœ‹æ‡‚è¿™ä¸ªè¡¨æƒ…åŒ…...")

    except Exception as e:
        logger.error(f"Sticker analysis error: {e}")
        msg_id = getattr(thinking_msg, "message_id", getattr(thinking_msg, "id", None))
        await ctx.edit_message(msg_id, "âŒ è¡¨æƒ…åŒ…åˆ†æå¤±è´¥")
