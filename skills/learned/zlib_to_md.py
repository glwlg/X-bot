"""
Z-Library ä¹¦ç±ä¸‹è½½ä¸è½¬æ¢ Skill
æ”¯æŒè¾“å…¥ç›´æ¥ä¸‹è½½é“¾æ¥æˆ–æœç´¢æŸ¥è¯¢ï¼ˆé€šè¿‡é•œåƒï¼‰ï¼Œè‡ªåŠ¨ä¸‹è½½ epub/txt å¹¶è½¬æ¢ä¸º markdown
"""
import os
import re
import httpx
import zipfile
import html
from telegram import Update
from telegram.ext import ContextTypes
from utils import smart_reply_text, smart_edit_text

SKILL_META = {
    "name": "zlib_to_md",
    "description": "ä¸‹è½½ Z-Library ä¹¦ç±å¹¶è½¬æ¢ä¸º Markdown æ ¼å¼ (ç›®å‰ä¸»è¦æ”¯æŒ EPUB è½¬æ¢)",
    "triggers": ["zlib", "ä¸‹è½½ä¹¦ç±", "æ‰¾ä¹¦", "book"],
    "params": {
        "query": {
            "type": "str",
            "description": "ä¹¦ç±åç§°ã€ISBN æˆ– Z-Library çš„ä¸‹è½½é“¾æ¥"
        }
    },
    "version": "1.0.1",
    "author": "X-Bot-Generator"
}

# ä¼ªè£… Header
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
}

def clean_html_to_md(html_content: str) -> str:
    """
    ç®€æ˜“çš„ HTML è½¬ Markdown å‡½æ•°ï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“
    """
    # è§£ç  HTML å®ä½“
    text = html.unescape(html_content)
    
    # ç§»é™¤ head, script, style
    text = re.sub(r'<head.*?>.*?</head>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<script.*?>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)
    text = re.sub(r'<style.*?>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # è½¬æ¢æ ‡é¢˜
    text = re.sub(r'<h1.*?>(.*?)</h1>', r'# \1\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<h2.*?>(.*?)</h2>', r'## \1\n', text, flags=re.IGNORECASE)
    text = re.sub(r'<h3.*?>(.*?)</h3>', r'### \1\n', text, flags=re.IGNORECASE)
    
    # è½¬æ¢æ®µè½
    text = re.sub(r'<p.*?>(.*?)</p>', r'\1\n\n', text, flags=re.IGNORECASE)
    
    # è½¬æ¢åŠ ç²—/æ–œä½“
    text = re.sub(r'<b.*?>(.*?)</b>', r'**\1**', text, flags=re.IGNORECASE)
    text = re.sub(r'<strong.*?>(.*?)</strong>', r'**\1**', text, flags=re.IGNORECASE)
    text = re.sub(r'<i.*?>(.*?)</i>', r'*\1*', text, flags=re.IGNORECASE)
    text = re.sub(r'<em.*?>(.*?)</em>', r'*\1*', text, flags=re.IGNORECASE)
    
    # ç§»é™¤å‰©ä½™æ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)
    
    # å¤„ç†å¤šä½™ç©ºè¡Œ
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()

def convert_epub_to_md(epub_path: str, output_path: str):
    """
    è§£å‹ EPUB å¹¶åˆå¹¶å…¶ä¸­çš„ HTML è½¬æ¢ä¸º Markdown
    """
    md_content = []
    
    try:
        with zipfile.ZipFile(epub_path, 'r') as z:
            # è¯»å– container.xml å¯»æ‰¾ rootfile (OPF)
            # ç®€åŒ–å¤„ç†ï¼šéå†æ‰€æœ‰ html/xhtml æ–‡ä»¶
            file_list = z.namelist()
            html_files = [f for f in file_list if f.endswith(('.html', '.xhtml', '.htm'))]
            
            # ç®€å•æ’åºï¼Œå°è¯•æŒ‰ç« èŠ‚é¡ºåºï¼ˆé€šå¸¸æ–‡ä»¶åæœ‰æ•°å­—ç´¢å¼•ï¼‰
            html_files.sort()
            
            for html_file in html_files:
                with z.open(html_file) as f:
                    content = f.read().decode('utf-8', errors='ignore')
                    md_chunk = clean_html_to_md(content)
                    if md_chunk:
                        md_content.append(md_chunk)
                        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {os.path.basename(epub_path)}\n\n")
            f.write("\n\n---\n\n".join(md_content))
            
        return True
    except Exception as e:
        print(f"Conversion error: {e}")
        return False

async def search_annas_archive(query: str, client: httpx.AsyncClient) -> dict:
    """
    ä½¿ç”¨ Anna's Archive (Z-Lib èšåˆé•œåƒ) æœç´¢
    """
    base_url = "https://annas-archive.org/search"
    params = {"q": query, "filetype": "epub"} # ä¼˜å…ˆæœ epub æ–¹ä¾¿è½¬æ¢
    
    try:
        resp = await client.get(base_url, params=params, follow_redirects=True)
        if resp.status_code == 200:
            # è¿™é‡Œéœ€è¦æ­£åˆ™æå–ç¬¬ä¸€ä¸ªç»“æœï¼Œå®é™…åœºæ™¯å»ºè®®ä½¿ç”¨ API æˆ–æ›´å¤æ‚çš„è§£æ
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¨¡æ‹Ÿé€»è¾‘ï¼Œæå–ç¬¬ä¸€ä¸ªå¯èƒ½çš„è¯¦æƒ…é¡µé“¾æ¥
            match = re.search(r'href="(/md5/[a-f0-9]{32})"', resp.text)
            if match:
                return {"title": query, "url": f"https://annas-archive.org{match.group(1)}"}
    except Exception:
        pass
    return None

async def execute(update: Update, context: ContextTypes.DEFAULT_TYPE, params: dict) -> None:
    user_id = update.effective_user.id
    query = params.get("query", "").strip()
    
    if not query:
        await smart_reply_text(update, "âŒ è¯·æä¾›ä¹¦ç±åç§°æˆ– Z-Library ä¸‹è½½é“¾æ¥ã€‚")
        return

    msg = await smart_reply_text(update, f"ğŸ” æ­£åœ¨æœç´¢/å¤„ç†: {query} ...")
    
    # å‡†å¤‡å·¥ä½œç›®å½•
    work_dir = os.path.join("data", str(user_id), "books")
    os.makedirs(work_dir, exist_ok=True)
    
    target_url = ""
    is_direct_url = query.startswith("http")
    
    async with httpx.AsyncClient(headers=HEADERS, timeout=30.0) as client:
        # 1. ç¡®å®šä¸‹è½½é“¾æ¥
        if is_direct_url:
            target_url = query
        else:
            # å°è¯•æœç´¢
            result = await search_annas_archive(query, client)
            if result:
                target_url = result['url']
                await smart_edit_text(msg, f"ğŸ“š æ‰¾åˆ°ç›¸å…³ä¹¦ç±ï¼Œå°è¯•è·å–å†…å®¹...\né“¾æ¥: {target_url}")
                # æ³¨æ„ï¼šAnna's Archive è¯¦æƒ…é¡µè¿˜éœ€è¦è§£æå‡ºå…·ä½“ä¸‹è½½é“¾æ¥ï¼Œè¿™é‡Œç®€åŒ–ä¸ºæç¤ºç”¨æˆ·
                # å®é™…è‡ªåŠ¨åŒ–ä¸‹è½½ Anna/Zlib éœ€è¦ç»•è¿‡ Cloudflareï¼Œé€šå¸¸å»ºè®®ç”¨æˆ·ç›´æ¥ç»™ç›´é“¾
                await smart_edit_text(msg, "âš ï¸ è‡ªåŠ¨ä¸‹è½½å—é™ï¼Œè¯·å¤åˆ¶ä¸Šé¢çš„é“¾æ¥åˆ°æµè§ˆå™¨ä¸‹è½½ï¼Œæˆ–å‘é€ç›´æ¥çš„æ–‡ä»¶ä¸‹è½½é“¾æ¥ã€‚")
                return
            else:
                await smart_edit_text(msg, "âŒ æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±ï¼Œè¯·å°è¯•æä¾›ç²¾ç¡®åç§°æˆ–ç›´æ¥é“¾æ¥ã€‚")
                return

        # 2. ä¸‹è½½æ–‡ä»¶ (å‡è®¾æ˜¯ç›´é“¾)
        file_name = "downloaded_book.epub"
        file_path = os.path.join(work_dir, file_name)
        
        try:
            await smart_edit_text(msg, "â¬‡ï¸ æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
            async with client.stream("GET", target_url) as response:
                if response.status_code != 200:
                    await smart_edit_text(msg, f"âŒ ä¸‹è½½å¤±è´¥ï¼ŒHTTP {response.status_code}")
                    return
                with open(file_path, "wb") as f:
                    async for chunk in response.aiter_bytes():
                        f.write(chunk)
        except Exception as e:
            await smart_edit_text(msg, f"âŒ ä¸‹è½½å‡ºé”™: {str(e)}")
            return

        # 3. è½¬æ¢ä¸º Markdown
        await smart_edit_text(msg, "ğŸ”„ æ­£åœ¨è½¬æ¢ä¸º Markdown...")
        md_filename = f"{os.path.splitext(os.path.basename(query) if is_direct_url else query)[0]}.md"
        # æ¸…ç†æ–‡ä»¶å
        md_filename = re.sub(r'[\\/*?:"<>|]', "", md_filename) or "book.md"
        md_path = os.path.join(work_dir, md_filename)

        # åˆ¤æ–­æ–‡ä»¶ç±»å‹å¹¶è½¬æ¢
        # è¿™é‡Œç®€å•åˆ¤æ–­æ˜¯å¦ä¸º zip (epub)
        if zipfile.is_zipfile(file_path):
            success = convert_epub_to_md(file_path, md_path)
        else:
            # å‡è®¾æ˜¯çº¯æ–‡æœ¬
            try:
                os.rename(file_path, md_path)
                success = True
            except:
                success = False

        if success and os.path.exists(md_path):
            await smart_edit_text(msg, "âœ… è½¬æ¢å®Œæˆï¼Œæ­£åœ¨ä¸Šä¼ ...")
            await update.message.reply_document(document=open(md_path, 'rb'), filename=md_filename)
            # æ¸…ç†æ–‡ä»¶
            try:
                os.remove(file_path)
                os.remove(md_path)
            except:
                pass
        else:
            await smart_edit_text(msg, "âŒ è½¬æ¢å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ EPUB æ ¼å¼ã€‚")